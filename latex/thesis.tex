%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                            %%
%% thesistemplate.tex version 4.00 (2023/02/09)                               %%
%% The LaTeX template file to be used with the aaltothesis.sty (version 4.00) %%
%% style file.                                                                %%
%% This package requires pdfx.sty v. 1.5.84 (2017/05/18) or newer.            %%
%%                                                                            %%
%% This is licensed under the terms of the MIT license below.                 %%
%%                                                                            %%
%% Written by Luis R.J. Costa.                                                %%
%% Currently developed at Teacher services, Learning Services of Aalto        %%
%% University by Luis R.J. Costa since May 2019.                              %%
%%                                                                            %%
%% Copyright 2017-2021 aaltothesis.cls by Luis R.J. Costa,                    %%
%% luis.costa@aalto.fi.                                                       %%
%% Copyright 2017-2018 Swedish translations in aaltothesis.cls by Elisabeth   %%
%% Nyberg and Henrik Wallén henrik.wallen@aalto.fi.                           %%
%% Finnish documentation in the template opinnatepohja.tex translated from    %%
%% the English template documentation.                                        %%
%% Copyright 2021 English template thesistemplate.tex by Luis R.J. Costa,     %%
%% Maurice Forget, Henrik Wallén.                                             %%
%% Copyright 2018-2022 Swedish template kandidatarbetsbotten.tex by Henrik    %%
%% Wallen.                                                                    %%
%%                                                                            %%
%% Permission is hereby granted, free of charge, to any person obtaining a    %%
%% copy of this software and associated documentation files (the "Software"), %%
%% to deal in the Software without restriction, including without limitation  %%
%% the rights to use, copy, modify, merge, publish, distribute, sublicense,   %%
%% and/or sell copies of the Software, and to permit persons to whom the      %%
%% Software is furnished to do so, subject to the following conditions:       %%
%% The above copyright notice and this permission notice shall be included in %%
%% all copies or substantial portions of the Software.                        %%
%% THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR %%
%% IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,   %%
%% FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL    %%
%% THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER %%
%% LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING    %%
%% FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER        %%
%% DEALINGS IN THE SOFTWARE.                                                  %%
%%                                                                            %%
%%                                                                            %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                            %%
%%                                                                            %%
%% An example for writting your thesis using LaTeX                            %%
%% Original version and development work by Luis Costa, changes to the text   %% 
%% in the Finnish template by Perttu Puska.                                   %%
%% Support for Swedish added 15092014                                         %%
%% PDF/A-b support added on 15092017                                          %%
%% PDF/A-2 support added on 24042018                                          %%
%% Layout design and typesettin changed 15072021                              %%
%%                                                                            %%
%% This example consists of the files                                         %%
%%       thesistemplate.tex (version 4.00) (for text in English)              %%
%%       opinnaytepohja.tex (version 4.00) (for text in Finnish)              %%
%%       kandidatarbetsbotten.tex (version 1.10) (for text in Swedish)        %%
%%       aaltothesis.cls                                                      %%
%%       linediagram.pdf (graphics file)                                      %%
%%       curves.pdf      (graphics file)                                      %%
%%       ledspole.jpg    (graphics file)                                      %%
%%                                                                            %%
%%                                                                            %%
%% Typeset in Linux with                                                      %%
%% pdflatex: (recommended method)                                             %%
%%             $ pdflatex thesistemplate                                      %%
%%             $ pdflatex thesistemplate                                      %%
%%                                                                            %%
%%   The result is the file thesistemplate.pdf that is PDF/A compliant, if    %%
%%   you have chosen the proper \documenclass options (see comments below)    %%
%%   and your included graphics files have no problems.                       %%
%%                                                                            %%
%%                                                                            %%
%% Explanatory comments in this example begin with the characters %%, and     %%
%% changes that the user can make with the character %                        %%
%%                                                                            %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% WHAT is PDF/A
%%
%% PDF/A is the ISO-standardized version of the pdf. The standard's goal is to
%% ensure that he file is reproducable even after a long time. PDF/A differs
%% from pdf in that it allows only those pdf features that support long-term
%% archiving of a file. For example, PDF/A requires that all used fonts are
%% embedded in the file, whereas a normal pdf can contain only a link to the
%% fonts in the system of the reader of the file. PDF/A also requires, among
%% other things, data on colour definition and the encryption used.
%% Currently three PDF/A standards exist:
%% PDF/A-1: based on PDF 1.4, standard ISO19005-1, published in 2005.
%%          Includes all the requirements essential for long-term archiving.
%% PDF/A-2: based on PDF 1.7, standard ISO19005-2, published in 2011.
%%          In addition to the above, it supports embedding of OpenType fonts,
%%          transparency in the colour definition and digital signatures.
%% PDF/A-3: based on PDF 1.7, standard ISO19005-3, published in 2012.
%%          Differs from the above only in that it allows embedding of files in
%%          any format (e.g., xml, csv, cad, spreadsheet or wordprocessing
%%          formats) into the pdf file.
%% PDF/A-4: based on PDF 2.0, standard ISO19005-4, published in November 2020.
%%
%% PDF/A-1 files are not necessarily PDF/A-2 -compatible and PDF/A-2 are not
%% necessarily PDF/A-1 -compatible.
%% Standards PDF/A-1, PDF/A-2 and PDF/A-3 have two levels:
%% b: (basic) requires that the visual appearance of the document is reliably
%%    reproduceable.
%% a (accessible) in addition to the b-level requirements, specifies how
%%   accessible the pdf file is to assistive software, say, for the physically
%%   impaired.
%% The PDF/A-4 standard does not have additional levels like in the earlier
%% standards.
%% For more details on PDF/A, see, e.g., 
%% https://www.loc.gov/preservation/digital/formats/fdd/fdd000318.shtml or
%% https://www.pdfa.org/resource/iso-19005-pdfa/
%%
%%
%% WHICH PDF/A standard should my thesis conform to?
%%
%% Either to the PDF/A-1b or the PDF/A-2b standard. If all the figures and
%% graphs used in thesis work do not require transparency features, use either
%% PDF/A-1b or PFDF/A-2b. If you have figures with transparency
%% characteristics, use the PDF/A-2b standard. However, drawing applications
%% often use the transparency parameter, setting it to zero, to specify opacity
%% and get the basic 2-D visualisation. As a result, validation of PDF/A-1b
%% will fail. Use PDF/A-2b if PDF/A-1b validation fails.
%% Do not use the PDF/A-3b standard for your thesis.
%% The font to be used are specified in this templatenand they should not be
%% changed. In addition to not adhering to Aalto's visual guidelines, you may
%% have difficulties in producing a PDF/A-compliant PDF.
%%
%%
%% Validate your PDF/A file at https://www.pdf-online.com/osa/validate.aspx
%%
%%
%% WHAT graphics format can I use to produce my PDF/A compliant file?
%%
%% When using pdflatex to compile your work, favour the use of pdf, but you can
%% use the jpg or png format especially for photographs. You will have PDF/A 
%% compliance problems with figures in pdf if the fonts are not embedded in the
%% pdf file.
%% If you choose to use latex to compile your work, the only acceptable file
%% format for your figure is eps. DO NOT use the ps format for your figures.

%% USE one of the following three \documentclass set-ups:
%% * the first when using pdflatex to directly typeset your document in the
%%   chosen pdf/a format for online publishing (centred page layout),
%% * the second for one-sided printing your thesis with the layout (wide left 
%%   margin), or
%% * the third for two-sided printing.
%%
\documentclass[english, 12pt, a4paper, sci, utf8, a-2b, online]{aaltothesis}
%\documentclass[english, 12pt, a4paper, elec, utf8, a-2b, print]{aaltothesis}
%\documentclass[english, 12pt, a4paper, elec, utf8, a-2b, print, twoside]{aaltothesis}

%% Use the following options in the \documentclass macro above:
%% your school: arts, biz, chem, elec, eng, sci
%% the character encoding scheme used by your editor: utf8, latin1
%% thesis language: english, finnish, swedish
%% make an archiveable PDF/A-1b or PDF/A-2b compliant file: a-1b, a-2b
%%                    (with pdflatex, a normal pdf containing metadata is
%%                     produced without the a-*b option)
%% typset for online document or print on paper: online, print
%%        online: typeset in symmetric layout and blue hypertext for online
%%                publishing
%%        print: typeset in a symmetric layout and black hypertext for printing
%%               on paper
%%          two-side printing: twoside (default is one-sided printing)
%%               typeset in a wide margin on the binding side of the page and
%%               black hypertext. Use with print only.
%%

%% Use one of these if you write in Finnish (or use the Finnish template
%% opinnaytepohja.tex)
%\documentclass[finnish, 12pt, a4paper, elec, utf8, a-1b, online]{aaltothesis}
%\documentclass[finnish, 12pt, a4paper, elec, utf8, a-1b, print]{aaltothesis}
%\documentclass[finnish, 12pt, a4paper, elec, utf8, a-1b, print, twoside]{aaltothesis}

%% Use one of these if you write in Swedish (or use the Swedish template
%% kandidatarbetsbotten.tex)
%\documentclass[swedish, 12pt, a4paper, elec, utf8, a-2b, online]{aaltothesis}
%\documentclass[swedish, 12pt, a4paper, elec, utf8, a-2b]{aaltothesis}
%\documentclass[swedish, 12pt, a4paper, elec, dvips, online]{aaltothesis}

%% FOR USERS OF AMS PACKAGES:
%% * newtxmath used in this template loads amsmath, so
%%   you needn't load it. If you want to use options in amsmath, load it here, 
%%   before \setupthesisfonts below to pass the options to amsmath.
%% * If you want to use amsthm, load it here before \setupthesisfonts to avoid
%%   a clash with newtxmath.
%% * If using amsmath with options and you want to use amsthm, load amsthms
%%   after amsmath, as described in the amsthm documentation.
%% * Don't use amsbsym or amsfonts. The symbols [and macros] there are defined in
%%   newtxmath and so clash if used.
%\usepackage[options]{amsmath}
\usepackage{amsthm}

%% DO NOT MOVE OR REMOVE \setupthesisfonts
\setupthesisfonts

%%
%% Add here the packges you need
%%
\usepackage{graphicx}

\usepackage{mathtools}
\usepackage[shortlabels]{enumitem}
\usepackage{tikz}

\allowdisplaybreaks

%% For tables that span multiple pages; used to split a paraphrasing example in
%% the appendix. If you don't need it, remove it.
\usepackage{longtable}

%% A package for generating Creative Commons copyright terms. If you don't use
%% the CC copyright terms, remove it, since otherwise undesired information may
%% be added to this document's metadata.
\usepackage[type={CC}, modifier={by-nc-sa}, version={4.0}]{doclicense}
%% Find below three examples for typesetting the CC license notice.


%% Edit to conform to your degree programme
%% Capitalise the words in the name of the degree programme: it's a name
\degreeprogram{Mathematics and Operations Research}
%%

%% Your major
%%
\major{Applied Mathematics}
%%

%% Choose one of the three below
%%
%\univdegree{BSc}
\univdegree{MSc}
%\univdegree{Lic}
%%

%% Your name (self explanatory...)
%%
\thesisauthor{Joonas Laaksonen}
%%

%% Your thesis title and possible subtitle comes here and possibly, again,
%% together with the Finnish or Swedish abstract. Do not hyphenate the title
%% (and subtitle), and avoid writing too long a title. Should LaTeX typeset a
%% long title (and/or subtitle) unsatisfactorily, you might have to force a
%% linebreak using the \\ control characters. In this case...
%% * Remember, the title should not be hyphenated!
%% * A possible 'and' in the title should not be the last word in the line; it
%%   begins the next line.
%% * Specify the title (and/or subtitle) again without the linebreak characters
%%   in the optional argument in box brackets. This is done because the title
%%   is part of the metadata in the pdf/a file, and the metadata cannot contain
%%   linebreaks.
%%
\thesistitle{Pointwise convergence of high-order finite element
solutions to the Poisson problem with a concentrated load}
% HOXHOXHOX VAI source term?
%\thesistitle[Title of the thesis]{Title of\\ the thesis}
%%
%% Either remove or leave \thesissubtitle{} empty if you don't use it
%%
%\thesissubtitle{A possible subtitle}
%\thesissubtitle[Subtitle of the thesis]{Subtitle of\\ the thesis}
%\thesissubtitle{}

%%
\place{Espoo}
%%

%% The date for the bachelor's thesis is the day it is presented
%%
\date{9 February 2023}
%%

%% Thesis supervisor
%% Note the "\" character in the title after the period and before the space
%% and the following character string.
%% This is because the period is not the end of a sentence after which a
%% slightly longer space follows, but what is desired is a regular interword
%% space.
%%
%\supervisor{Prof.\ Pirjo Professori}
\supervisor{D.Sc.\ (Tech.) Harri Hakula}
%%

%% Advisor(s)---two at the most---of the thesis. Check with your supervisor how
%% many official advisors you can have.
%%
%\advisor{Dr Alan Advisor}
%\advisor{Ms Elsa Expert (MSc)}
%%

%% If you do your thesis work in a company of other institute, give the name of
%% the company or instution here. Otherwise, leave the macro empty, comment it
%% out, or remove it. This will remove this field from the abstract page.
%%
%\collaborativepartner{Company or institute name}
%%

%% Aaltologo: syntax:
%% \uselogo{?|!|''}
%% The logo language is set to be the same as the thesis language.
%%
%\uselogo{?}
%\uselogo{!}
\uselogo{''}
%%

%%%%%%%%%%%%%%%%%%               COPYRIGHT TEXT               %%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Copyright of a work is with the creator/author of the work regardless of
%% whether the copyright mark is explicitly in the work or not. You may, if you
%% wish---we encourage you to do so---publish your work under a Creative
%% Commons license (see creativecommons.org), in which case the license text
%% must be visible in the work. Write here the copyright text you want using the
%% macro \copyrighttext, which writes the text into the metadata of the pdf file
%% as well.
%%
%% Syntax:
%% \copyrigthtext{metadata text}{text visible on the page}
%%
%% CHOOSE ONE OF THE COPYRIGHT NOTICE STYLES BELOW.
%% IF USING THE CC TERMS, CHOOSE THE LICENSE YOU WANT TO USE.
%% The different CC licenses are listed at 
%% https://creativecommons.org/about/cclicenses/.
%% If you use the icons from the dolicense.sty package, add the package above
%% (\usepackage{dolicense}).
%% IMPORTANT NOTE!! Manually write the CC text in the \copyrighttext metadata
%% text field.
%%
%% NOTE: In the macros below, the text written in the metadata must have a
%% \noexpand macro before the \copyright special character. When not in pdf/a
%% mode (i.e. a-1b or a-2b are not specified in \documentclass), two \noexpands
%% are required in the metadata text to correctly render the copyright mark in
%% the pdf metadata. In pdf/a mode one \noexpand suffices.
%%
%% EXAMPLE OF PLAIN COPYRIGHT TEXT
%% The macros \copyright and \year below must be separated by the \ character 
%% (space chacter) from the text that follows. The macros in the argument of the
%% \copyrighttext macro automatically insert the year and the author's name.
%% (Note! \ThesisAuthor is an internal macro of the aaltothesis.cls class file).
%%
%\copyrighttext{Copyright \noexpand\textcopyright\ \number\year\ \ThesisAuthor}
%{Copyright \textcopyright{} \number\year{} \ThesisAuthor}
%%
%% Of course, the same text could have simply been written as
%% \copyrighttext{Copyright \noexpand\copyright\ 2018 Eddie Engineer}
%% {Copyright \copyright{} 2022 Eddie Engineer}
%%
%% EXAMPLES OF CC LICENSE: different ways to display the same license
%% 1. A simple Creative Commons license text with a link to the copyright notice:
%\copyrighttext{\noexpand\textcopyright\ \number\year. This work is 
%	licensed under a CC BY-NC-SA 4.0 license.}{\textcopyright{} 
%	\number\year. This work is licensed under a 
%	\href{https://creativecommons.org/licenses/by-nc-nd/4.0/}{CC BY-NC-SA 4.0} 
%	license.}
%
%% To get the URL of the license of your choice, go to 
%% https://creativecommons.org/about/cclicenses/, click on the chosen license
%% you want to use, and copy-and-paste the URL in the macro \href above.
%%
%% 2. A short Creative Commons license text containing the respective CC icons
%% (requires the package dolicense.sty to be added in the preamble as done
%% above) and a link to the corresponding Creative Commons license webpage (see
%% the dolicense package documentation for other license icons):
%\copyrighttext{\noexpand\textcopyright\ \number\year. This work is licensed
%	under a CC BY-NC-SA 4.0 license.}{
%	\parbox{95mm}{\noindent\textcopyright\ \number\year. \doclicenseText} 
%	\hspace{1em}\parbox{35mm}{\doclicenseImage}
%}
%%
%% 3. An expanded Creative Commons license text containing the respective CC
%% icons text and as generated by the dolicense.sty package (the license is set
%% via package options in \usepackage[options]{dolicense} above; see the
%% dolicense package documentation for other license texts and icons):
\copyrighttext{\noexpand\textcopyright\ \number\year. This work is 
	licensed under a Creative Commons "Attribution-NonCommercial-ShareAlike 4.0 
	International" (BY-NC-SA 4.0) license.}{\noindent\textcopyright\ \number
	\year \ \doclicenseThis}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% The English abstract:
%% All the details (name, title, etc.) on the abstract page appear as specified
%% above.
%% Thesis keywords:
%% Note! The keywords are separated using the \spc macro
%%
\keywords{For keywords choose\spc concepts that are\spc central to your\spc 
thesis}
%%

%% The abstract text. This text is included in the metadata of the pdf file as
%% well as the abstract page.
%%
\thesisabstract{%
The abstract is a short description of the essential contents of the thesis:
what was studied and how and what were the main findings. For a Finnish thesis,
the abstract should be written in both Finnish and English; for a Swedish
thesis, in Swedish and English. The abstracts for English theses written by
Finnish or Swedish speakers should be written in English and either in Finnish
or in Swedish, depending on the student’s language of basic education. Students
educated in languages other than Finnish or Swedish write the abstract only in
English. Students may include a second or third abstract in their native
language, if they wish. 
The abstract text of this thesis is written on the readable abstract page as
well as into the pdf file's metadata via the thesisabstract macro (see the 
comment in the TeX file). Write here the text that goes into the metadata. The 
metadata cannot contain special characters, linebreak or paragraph break 
characters, so these must not be used here. If your abstract does not contain 
special characters and it does not require paragraphs, you may take advantage of
the abstracttext macro (see the comment in the TeX file below). Otherwise, the 
metadata abstract text must be identical to the text on the abstract page.
}

%% You can prevent LaTeX from writing into the xmpdata file (it contains all the 
%% metadata to be written into the pdf file) by setting the writexmpdata switch
%% to 'false'. This allows you to write the metadata in the correct format
%% directly into the file thesistemplate.xmpdata.
%\setboolean{writexmpdatafile}{false}

%% Definitions, theorems, lemmas etc.
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{assumption}{Assumption}[section]

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}

%% Custom commands
\DeclarePairedDelimiter\abs{\lvert}{\rvert}
\DeclarePairedDelimiter\norm{\lVert}{\rVert}
\newcommand*{\innerprod}[2]{\left\langle #1, #2 \right\rangle}
\newcommand*\diff{\mathop{}\!d}
\newcommand*{\boldone}{\text{\usefont{U}{bbold}{m}{n}1}}
\DeclareMathOperator*{\esssup}{ess\,sup}
\DeclareMathOperator\supp{supp}
\DeclareMathOperator{\spn}{span}

\numberwithin{equation}{section}

%% All that is printed on paper starts here
%%
\begin{document}

%% Create the coverpage
%%
\makecoverpage

%% Typeset the copyright text.
%% If you wish, you may leave out the copyright text from the human-readable
%% page of the pdf file. This may seem like a attractive idea for the printed
%% document especially if "Copyright (c) yyyy Eddie Engineer" is the only text
%% on the page. However, the recommendation is to print this copyright text.
%%
\makecopyrightpage

\clearpage
%% Note that when writing your thesis in English, place the English abstract
%% first followed by the possible Finnish or Swedish abstract.

%% Abstract text
%% All the details (name, title, etc.) on the abstract page appear as specified
%% above.
%%
\begin{abstractpage}[english]
  The abstract is a short description of the essential contents of the thesis:
  what was studied and how and what were the main findings.

  For a Finnish thesis, the abstract should be written in both Finnish and
  English; for a Swedish thesis, in Swedish and English. The abstracts for
  English theses written by Finnish or Swedish speakers should be written in
  English and either in Finnish or in Swedish, depending on the student’s
  language of basic education. Students educated in languages other than Finnish
  or Swedish write the abstract only in English. Students may include a second
  or third abstract in their native language, if they wish.

  The abstract text of this thesis is written on the readable abstract page as
  well as into the pdf file's metadata via the \verb+\thesisabstract+ macro
  (see comment in this \TeX{} file above). Write here the text that goes onto
  the readable abstract page. You can have special characters, linebreaks, and
  paragraphs here. Otherwise, this abstract text must be identical to the
  metadata abstract text.
  
  If your abstract does not contain special characters and it does not require
  paragraphs, you may take advantage of the \verb+\abstracttext+ macro (see the
  comment in this \TeX{} file below).
\end{abstractpage}

%% The text in the \thesisabstract macro is stored in the macro \abstractext, so
%% you can use the text metadata abstract directly as follows:
%%
%\begin{abstractpage}[english]
%	\abstracttext{}
%\end{abstractpage}

%% Force a new page so that the possible Finnish or Swedish abstract does not
%% begin on the same page
%%
\newpage
%%
%% Abstract in Finnish.  Delete if you don't need it. 
%%
%% Respecify those fields that differ from the earlier specification or simply
%% respecify all fields.
\thesistitle{Opinnäyteen otsikko}
%\thesissubtitle{Opinnäytteen mahdollinen alaotsikko}
\supervisor{TkT Harri Hakula}
%\advisor{TkT Alan Advisor}
%\advisor{DI Elsa Expert}
\degreeprogram{Matematiikka ja operaatioanalyysi}
\major{Sovellettu matematiikka}
%\collaborativepartner{Yhtiön tai laitoksen nimi}
\date{9.2.2023}
%% The keywords need not be separated by \spc now.
\keywords{Vastus, resistanssi, lämpötila}
%% Abstract text
\begin{abstractpage}[finnish]
Tiivistelmä on lyhyt kuvaus työn keskeisestä sisällöstä: mitä tutkittiin ja 
miten sekä mitkä olivat tärkeimmät tulokset. Suomenkielisen opinnäytteen 
tiivistelmä kirjoitetaan suomeksi ja englanniksi ja ruotsinkielisen vastaavasti 
ruotsiksi ja englanniksi. Suomen- tai ruotsinkielisten opiskelijoiden, joiden 
opinnäytteen kieli on englanti, tulee kirjoittaa tiivistelmänsä englanniksi ja 
koulusivistyskielellään. Muiden kuin koulusivistyskieleltään suomen- tai 
ruotsinkielisten tulee kirjoittaa tiivistelmänsä vain englanniksi. Opiskelija 
voi halutessaan lisätä opinnäytteeseensä toisen tai kolmannen tiivistelmän 
omalla äidinkielellään.
Tämän opinnäytteen tiivistelmäteksti kirjoitetaan opinnäytteen luettavan osan
lomakkeen lisäksi myös pdf-tiedoston metadataan. Kirjoita tähän metadataan
kirjoitettavaa teksti. Metadatatekstissa ei saa olla erikoismerkkejä,
rivinvaiho- tai kappaleenjakomerkkiä, joten näitä merkkeja ei saa käyttää tässä.
Jos tiivistelmäsi ei sisällä erikoimerkkejä eikä kaipaa kappaleenjakoa, voit
hyödynttää makroa abstracttext luodessasi lomakkeen tiivistelmää (katso
kommentti tässä TeX-tiedostossa alla). Metadatatiivistelmatekstin on muuten 
oltava sama kuin lomakkeessa oleva teksti.

\end{abstractpage}

\dothesispagenumbering{}

\newpage

%% Table of contents. 
%%
\thesistableofcontents

%% \clearpage is similar to \newpage, but it also flushes the floats (figures
%% and tables).
%%
\cleardoublepage

\section{Introduction}
\label{sec:intro}

%% Leave page number of the first page empty
%% 
\thispagestyle{empty}
A partial differential equation (PDE) is an equation that consists of an
unknown function of two or more variables and its partial derivatives of
arbitrary order \cite{evans2010}.
Such equations describe how a function, possibly corresponding to a physical
quantity of interest, behaves over its domain of definition
which in practical applications typically corresponds to a geometric shape or
time or both. For example, many fundamental laws of physics can be elegantly
expressed as partial differential equations, e.g.\ Maxwell's equations
in electromagnetism.
The set of all possible partial differential equations is incredibly vast and
complex, which makes it unwieldy, if not impossible,
to come up with a general PDE theory that could be productively used for any kind
of problem. Instead, the study of PDEs focuses on important families
and instances of partial differential equations arising from
different fields of science.

A solution to a partial differential equation is said to be classical if it
can be differentiated at least as many times as the formulation of the equation
requires and the equation holds pointwise everywhere in the domain of the solution.
However, it turns out that rather few partial differential equations
have classical solutions \cite{evans2010}. Moreover, imposing boundary conditions,
that the possible classical solution must satisfy on the boundary of its domain,
complicates the question of existence even further.
For some phenomena the solution may even be expected to be non-differentiable
at some points, so it makes sense to look for solutions in some other sense as well
than just the classical sense. Thus, the initial partial differential equation is
usually reformulated in a more generalized form, which essentially expands
the space of functions where the solution is searched and enables a set of useful
mathematical techniques to be utilized. A solution of the
generalized problem is usually called a generalized solution or a weak solution,
and its existence can be guaranteed for a large set of problems.
Whether a weak solution is also a classical solution can then be
assessed separately, and such results fall under the subdiscipline of
regularity theory of partial differential equations.

In practical applications numerical methods are used to approximate the
solutions of partial differential equations. One such method that has been
extremely successful is the finite element method (FEM). Oden \cite{oden1991}
presents a review of its history.
Without too stringent a viewpoint, some attributes 
of the finite element method can be traced back a couple of centuries, but serious
interest in the method started to accumulate during the mid-1950s and 1960s
especially in the engineering community. During this time the finite element method 
also gained its name. The mathematical foundations were established somewhat
later during the 1970s, and the convergence of the method was attested for several
classes of problems.

Oden also discusses some of the factors leading to the success of the finite
element method. The method is based on the generalized, weak formulation of a
partial differential equation, which will be discussed in more
detail in later sections, but for now it suffices to say that it is a crucial
factor why the finite element method merits its success. Being based on the weak
formulation, the finite element method is essentially geometry-agnostic, which
means that it can be used to solve partial differential equations over almost any
kind of shape. Combined with the rich modern theory of partial differential
equations, the finite element method has solid mathematical foundations which offer
optimal estimates of the convergence of the approximations. 
Moreover, from a computational standpoint, the implementation of the method in 
computer code lends itself extremely well to parallelization.

Decision-making based on computed information requires that the computed
information is reliable. Szabó and Babu{\v s}ka \cite{szabobabuska2011}
discuss this systematically in the context of finite element analysis, i.e.\
the process of using the finite element method to solve a problem. In finite
element analysis the typical workflow is to create a mathematical model,
i.e.\ a set of partial differential equations and constraints
that represent the physical system of interest,
find an approximate solution to the model by using the finite element method,
and finally extract the desired information from the computed approximate solution.
There are two critical factors contributing to the reliability of such computed 
information: the suitability of the mathematical model as a representation of
idealized reality and the accuracy of the approximate solution with respect
to the exact solution.
Szabó and Babu{\v s}ka call the processes of assessing these qualities validation 
and verification, respectively.
The validation process may consist of, for example, comparing the results of
real-life experiments to predictions obtained from the mathematical model.
The verification process leans on the well-understood approximation
properties of the finite element method.

Sometimes a physical phenomenon is modeled sufficiently well by a 
mathematical model for which the approximation results from the standard
theory of the finite element method do not directly apply.
If possible, one option to still be able to perform the verification process would 
be to change the model so that the error estimates readily apply.
However, there could be some tradeoffs involved in the choice between the models,
which could still make the initial model more favorable,
e.g.\ the initial model is a crude simplification but requires much less
effort to solve. For example, Babu{\v s}ka et al.\ \cite{babuskasoanesuri2017}
study the effects of replacing holes having extremely small radii with singular
points, i.e.\ holes with the radii equal to zero,
which simplifies the approximation process
but essentially renders the model as incorrect but still useful.

In this thesis, we study a problem similar in vein to the problem
studied by Babu{\v s}ka et al.\ which may simplify modeling but for which
the convergence of the finite element solutions is not obvious.
The problem is Poisson's equation with a Dirac delta load term, and it can
be expressed as finding a real-valued function $u$ over
a set $\Omega \subset \mathbb{R}^n$ such that
\begin{equation}
    \label{eq:intro_problem}
    -\Delta u = \delta_{x_0} \quad \text{in } \Omega,
\end{equation}
where $\Delta u$ is the Laplacian of $u$,
i.e.\ the sum of the second partial derivatives of $u$
with respect to each independent variable,
and $\delta_{x_0}$ is the Dirac delta for some $x_0 \in \Omega$
which can be loosely regarded as a function that is concentrated
at the point $x_0$ such that
\begin{equation*}
    \delta_{x_0}(x) =
    \begin{cases}
        \infty, & x = x_0 \\
        0, & x \neq x_0
    \end{cases}
\end{equation*}
for all $x \in \Omega$ and
\begin{equation*}
    \int_{\Omega} \delta_{x_0} \diff x = 1.
\end{equation*}
The adverb ``loosely'' should be emphasized because the standard integration
theory forbids the existence of such a function, but it still provides useful
intuition. This also means that the partial differential equation 
\eqref{eq:intro_problem} should be
understood in some specific sense, namely in the weak sense.
Poisson's equation can be used to
model, for example, the electrostatic potential caused by an electric charge, and
with the Dirac delta load term the equation can be thought to model an idealized
point charge, i.e.\ a charge with zero area or volume.

We study the problem \eqref{eq:intro_problem}
in bounded polygonal two-dimensional domains
with some additional convexity assumptions
and with different boundary conditions, namely
Dirichlet, Neumann and mixed Dirichlet-Neumann boundary conditions.
The first objective of this thesis is to consider the unique solvability
of these boundary value problems.
Casas \cite{casas1985} proves this for the Dirichlet problem with
homogeneous boundary values. We extend this result to the other boundary 
value problems with non-homogeneous boundary conditions.

The second objective is to study the convergence
of the finite element method when applied to these problems.
There exist several variants of the finite element method, and each
variant has its own convergence theory. The most common variants
are the $h$-version and the $p$-version, and they will be discussed later.
Casas \cite{casas1985} and Scott \cite{scott1973}
prove the convergence of the $h$-version in the $L^2$ integral norm
when applied to the problem \eqref{eq:intro_problem} with homogeneous Dirichlet
boundary values.
Schatz and Wahlbin \cite{schatzwahlbin1977} also prove estimates for pointwise
convergence of the $h$-version.
More recent results have been obtained by Millar et al.\ \cite{millarmuga2021}
who obtain convergence by approximating the
Dirac delta and by Araya et al.\ \cite{arayabehrens2006} who deduce
a posteriori error estimates.

The convergence of the $p$-version when applied to the problem 
\eqref{eq:intro_problem} seems to be mostly uncharted territory.
Therefore, the second objective of this thesis can be elaborated as
attesting the convergence of the $p$-version of the finite element method
for the problem \eqref{eq:intro_problem}. We shall extend
the $L^2$ convergence result by Casas to the $p$-version
with mixed Dirichlet-Neumann boundary conditions.
We also assess the convergence numerically for a Neumann problem for which
the exact solution is known. In the numerical results, we put emphasis on
the pointwise convergence as it sometimes turns out to be exponential.
Finally, we replace the Dirac delta with its (distributional)
derivative and consider the convergence of the finite element method
numerically only.
The Dirac delta and its derivatives are jointly referred to as 
concentrated loads.

The remainder of this thesis is structured as follows.
Section~\ref{sec:preliminaries} presents the preliminary mathematical
concepts that are essential in the modern theory of partial differential equations
and in the theory of the finite element method.
In Section~\ref{sec:poissons_equation_in_a_polygon},
we show how a classically formulated boundary value problem can be
transformed into a weak form, and then we consider its solvability.
In particular, we consider the weak formulation and solvability of
the problem \eqref{eq:intro_problem}.
Section~\ref{sec:finite_element_method} is devoted to the theory
of the finite element method with emphasis on the $p$-version of the method.
A substantial portion of this section deals with the approximation properties
of high-order piecewise polynomials, which forms the basis for the
convergence properties of the $p$-version.
In Section~\ref{sec:finite_element_solutions_with_a_concentrated_load},
we then take these results into use and consider the convergence of
high-order finite element solutions to the problem \eqref{eq:intro_problem}
as described above

\clearpage

\section{Preliminaries}
\label{sec:preliminaries}

We begin by covering properties related to open subset of $\mathbb{R}^n$,
in particular $\mathbb{R}^2$, which correspond to the geometries, where
the boundary value problems shall be defined.
We will see later that the solvability of many boundary value problems
follows from abstract results from functional analysis, and
in anticipation of this, we go through the definitions and basic properties
of Banach spaces, Hilbert spaces, basic types of linear operators
and dual spaces. Then we consider Lebesgue spaces and Sobolev spaces
that are important instances of Banach and Hilbert spaces, as they correspond
to the function spaces, where we shall search for the solutions of the problems.

\subsection{Domains and Boundaries}
\label{subsec:domains}

Throughout the rest of this thesis, $\Omega$ denotes a subset of $\mathbb{R}^n$,
the $n$-dimensional Euclidean space. Most of the time we restrict
ourselves to the case $n=2$, as that is the setting for the boundary
value problems we are looking to study.
Typically, $\Omega$ is assumed to be non-empty, open and connected,
and we call such a set domain.
Being connected simply means that $\Omega$ cannot be given
as the union of two disjoint non-empty open sets.
Disconnected sets could be handled by considering the
disjoint open sets separately. Most of the time we also assume
that $\Omega$ is bounded, i.e.\ it can be enclosed within a ball of
finite radius.

The convergence results in finite element analysis typically rely on regularity 
results that guarantee higher-order smoothness of the solutions of boundary
value problems. Many of these regularity results, in turn, rely on the 
properties of the domain. One such property is convexity, which will be one 
of our key assumptions later on.
\begin{definition}[Convex set]
    \label{def:convexity}
    A set $\Omega \subset \mathbb{R}^n$ is said to be convex if for every
    pair of points $x,y \in \Omega$ it holds that $tx + (1-t)y \in \Omega$
    for all $t \in (0,1)$.
\end{definition}

Another important property of a domain is the regularity of its boundary.
The boundary of a domain $\Omega$ is denoted by $\partial \Omega$.
Analogously to functions in analysis, boundaries can be defined to be continuous,
Lipschitz continuous, continuously differentiable, etc.
The definition of a domain with Lipschitz boundary is given below,
and it borrows ideas from
Grisvard \cite{grisvard2011} and Schwab \cite{schwab1998}.
See also Figure~\ref{fig:lipschitzboundary} below.
\begin{definition}[Lipschitz boundary]
    \label{def:lipschitzboundary}
    Assume that $n \geq 2$, and let $\Omega \subset \mathbb{R}^n$ be a domain.
    The boundary $\partial \Omega$ is said to be Lipschitz
    if for every $x \in \partial \Omega$ there exist a Lipschitz function
    $g: \mathbb{R}^{n-1} \to \mathbb{R}$, a local coordinate
    system $\{\tilde{e}_1,\dotsc,\tilde{e}_n\} \subset \mathbb{R}^n$
    and constants $d > 0$ and $h > 0$ such that whenever
    a point $y = \sum_{i=1}^{n} \tilde{y}_i \tilde{e}_i \in \mathbb{R}^n$
    satisfies $\abs{\tilde{y}_i} < d$ for all $i=1,\dotsc,n-1$,
    then the following hold.
    \begin{enumerate}[(i)]
        \item \label{def:lipschitzboundary_cond1}
        If $g(\tilde{y}_1,\dotsc,\tilde{y}_{n-1}) = \tilde{y}_n$,
        then $y \in \partial \Omega$.
        \item \label{def:lipschitzboundary_cond2}
        If $g(\tilde{y}_1,\dotsc,\tilde{y}_{n-1}) < \tilde{y}_n
        < g(\tilde{y}_1,\dotsc,\tilde{y}_{n-1}) + h$, then $y \in \Omega$.
        \item \label{def:lipschitzboundary_cond3}
        If $g(\tilde{y}_1,\dotsc,\tilde{y}_{n-1}) > \tilde{y}_n
        > g(\tilde{y}_1,\dotsc,\tilde{y}_{n-1}) - h$, then $y \notin \Omega$.
    \end{enumerate}
\end{definition}
\begin{figure}[t]
    \centering
    \begin{tikzpicture}
        %\draw[help lines] (0,0) grid (10,7);
        \path[draw] (3,0)
            -- (4,2)
            -- (6.5,2)
            -- (8.7,3)
            -- (7.5,6)
            -- (4.5,5.7)
            -- (2,6)
            -- (1,3)
            -- cycle;

        \filldraw[black] (6.5,2) circle (1.5pt);
        \node at (6.75,1.9) {$x$};

        \node at (3.2,3.8) {$\Omega$};
            
        \begin{scope}[shift={(6.5,2)},rotate=12.2219774]
            % Coordinate axes
            \draw[->,thick] (-2.5,-1.3) -- (2.5,-1.3);
            \node[rotate=12.2219774] at (2.55,-1) {$\tilde{e}_1$};
            \draw[->,thick] (0,-1.7) -- (0,2.7);
            \node[rotate=12.2219774] at (0.35,2.75) {$\tilde{e}_2$};

            % Ticks
            \draw[thick] (1.2,-1.45) -- (1.2,-1.15);
            \node[rotate=12.2219774] at (1.2,-1.65) {$d$};
            \draw[thick] (-1.2,-1.45) -- (-1.2,-1.15);
            \node[rotate=12.2219774] at (-1.32,-1.65) {$-d$};

            % Dashed lines
            \draw[dashed] (1.2,-1.3) -- (1.2,0.25993-0.8);
            \draw[dashed] (-1.2,-1.3) -- (-1.2,0.25993-0.8);

            % Double arrows
            \draw[<->] (1.2,0.25993) -- (1.2,0.25993+0.8);
            \node[rotate=12.2219774] at (1.4,0.7) {$h$};
            \draw[<->] (1.2,0.25993) -- (1.2,0.25993-0.8);
            \node[rotate=12.2219774] at (1.4,-0.09) {$h$};
            \draw[<->] (-1.2,0.25993) -- (-1.2,0.25993+0.8);
            \draw[<->] (-1.2,0.25993) -- (-1.2,0.25993-0.8);

            % Upper and lower bounds
            \draw[rotate around={-12.2219774:(-1.2,0.25993+0.8)}]
                (-1.2,0.25993+0.8) -- (-1.2+1.22,0.25993+0.8);
            \draw[rotate around={-12.2219774:(-1.2,0.25993-0.8)}]
                (-1.2,0.25993-0.8) -- (-1.2+1.22,0.25993-0.8);
            \draw[rotate around={12.2219774:(1.2,0.25993+0.8)}]
                (1.2,0.25993+0.8) -- (1.2-1.22,0.25993+0.8);
            \draw[rotate around={12.2219774:(1.2,0.25993-0.8)}]
                (1.2,0.25993-0.8) -- (1.2-1.22,0.25993-0.8);
        \end{scope}
    \end{tikzpicture}
    \caption{A domain with Lipschitz boundary.}
    \label{fig:lipschitzboundary}
\end{figure}
In other words, the requirement \ref{def:lipschitzboundary_cond1}
means that a Lipschitz boundary is locally the image of a Lipschitz function.
The requirements \ref{def:lipschitzboundary_cond2} and 
\ref{def:lipschitzboundary_cond3} mean that the set $\Omega$ is not allowed
to be on both sides of its boundary.
Other types of boundary regularity, such as continuous differentiability,
have analogous definitions by just replacing the word ``Lipschitz'' with e.g.\
``continuously differentiable''.

In finite element analysis, the domain is usually modeled as a union of polygons.
A polygon consists of vertices and line segments that connect the vertices.
In general, a polygonal domain can have holes, that are of course polygonal as well,
but a convex polygonal domain cannot have any holes.
Assuming that the angle between adjacent line segments is never $0$ nor $2\pi$,
a polygonal domain has Lipschitz boundary \cite{grisvard2011}.
This is an important property, as having Lipschitz boundary is needed
for many later results.
Clearly, the boundary of a polygonal domain is not differentiable.

\subsection{Functional Analysis}
\label{subsec:functionalanalysis}

We list here some of the most fundamental concepts and results from functional 
analysis with some basic topology concepts.
For a more complete reference, see for example
\cite{rudin1991} or \cite{rudin1986}.

\subsubsection{Vector Spaces, Normed Spaces and Inner Product Spaces}
\label{subsubsec:normedspaces}

We begin with the definition of a vector space over the real numbers.
\begin{definition}[Real vector space]
    \label{def:vectorspace}
    A vector space over the real numbers is a non-empty set $X$ equipped
    with the following two operations.
    \begin{enumerate}[(i)]
        \item Addition: $x+y \in X$ for all $x,y \in X$.
        \item Scalar multiplication: $a x \in X$ for all $a \in \mathbb{R}$
        and $x \in X$.
    \end{enumerate}
    In addition, the following axioms hold for all $x,y,z \in X$
    and $a,b \in \mathbb{R}$.
    \begin{enumerate}[(i)]
        \item Commutativity: $x+y=y+x$.
        \item Associativity: $(x+y)+z=x+(y+z)$ and $(ab)x=a(bx)$.
        \item Existence of additive identity: there exists a zero vector $0 \in X$
        such that $x+0=x$.
        \item Existence of additive inverse: for every $x \in X$ there exists
        $y \in X$ such that $x+y=0$.
        \item Multiplicative identity: $1x=x$ where $1 \in \mathbb{R}$.
        \item Distributivity: $a(x+y)=ax+ay$ and $(a+b)x=ax+bx$.
    \end{enumerate}
\end{definition}
By a vector space, we shall always mean a real vector space.
A subset of a vector space is said to be a vector subspace,
or simply a subspace, if it is closed under the operations of addition
and scalar multiplication of the ambient vector space.
\begin{definition}[Vector subspace]
    \label{def:subspace}
    A non-empty subset $S$ of a vector space $X$
    is said to be a vector subspace of $X$,
    if $ax+by \in S$ for all $a,b \in \mathbb{R}$ and $x,y \in S$.
\end{definition}

Next we define a norm on a vector space which can be thought to be a measure
of the magnitude of a vector.
\begin{definition}[Norm]
    \label{def:norm}
    A norm on a vector space $X$ is a function $\norm{\cdot}: X \to \mathbb{R}$
    that satisfies the following properties for all $x,y \in X$
    and $a \in \mathbb{R}$.
    \begin{enumerate}[(i)]
        \item $\norm{x+y} \leq \norm{x} + \norm{y}$.
        \item $\norm{ax} = \abs{a} \norm{x}$.
        \item $\norm{x} \geq 0$, and $\norm{x}=0$ if and only if $x=0$.
    \end{enumerate}
\end{definition}
A vector space equipped with a norm is called a normed space.
For example, $\mathbb{R}^n$ is a normed space with the Euclidean norm.
We shall always assume that a normed space is equipped with the usual
norm topology. This means that given a normed space $X$, a subset $S \subset X$
is open if and only if for every $x \in S$ there exists a ball
$B(x,\varepsilon) = \{ y \in X : \norm{x-y} < \varepsilon \}$ with a positive
radius $\varepsilon > 0$ such that $B(x,\varepsilon) \subset S$.
If a function $s: X \to \mathbb{R}$ does not satisfy the condition
that $s(x) = 0$ implies $x = 0$ but otherwise satisfies Definition~\ref{def:norm},
then $s$ is said to be a seminorm.

A norm enables us to consider the convergence of a sequence of vectors.
\begin{definition}[Convergence of a sequence]
    \label{def:convergence}
    A sequence of vectors $(x_i)_{i=1}^{\infty}$ in a normed space $X$
    is said to converge to the limit $x \in X$ if for every $\varepsilon > 0$ 
    there exists a number $N > 0$
    such that $\norm{x-x_i} < \varepsilon$ whenever $i \geq N$.
\end{definition}
The condition in Definition~\ref{def:convergence} can be written succinctly
as $\lim_{i \to \infty} \norm{x-x_i} = 0$.
We can use convergence to define the concept of a closure point of a set.
\begin{definition}[Closure point]
    \label{def:closure_point}
    Let $S$ be a subset of a normed space $X$.
    A point $x \in X$ is said to be a closure point of $S$
    if there exists a sequence $(x_i)_{i=1}^{\infty}$ in $S$
    that converges to $x$.
    The set of all closure points of $S$ is the closure of $S$,
    and it is denoted by $\overline{S}$.
\end{definition}
The definition of the closure has some useful consequences.
It is a standard result that $\overline{S}$ is closed.
Moreover, $S$ is closed precisely when $S = \overline{S}$.
Since $S \subset \overline{S}$,
this means that to prove the closedness of $S$ we only need to show that
every closure point of $S$ belongs to $S$, i.e.\ the limit belongs to $S$.
If $\overline{S} = X$, it is said that the subset $S$ is dense in the
normed space $X$. If $S$ is dense in $X$ and $S$ has a well-known structure
with useful properties, then these properties can often be extended to $X$
via so-called density arguments.

The closure and density essentially allow one to pick a converging sequence
for a given point. Compactness, on the other hand, allows one to pick
a limit point for a given (sub)sequence.
\begin{definition}[Compact set]
    \label{def:compactsubset}
    A subset $S$ of a normed space $X$ is said to be compact if every sequence
    in $S$ has a subsequence that has a limit in $S$.
    Moreover, a subset $S$ is called precompact if $\overline{S}$
    is compact.
\end{definition}
Definition~\ref{def:compactsubset} is more generally referred to as
sequential compactness. Compactness generally means that every open cover of the
set $S$ has a finite subcover. However, in normed spaces,
compactness and sequential compactness are equivalent.

An important class of normed spaces is Banach spaces for which we need
to introduce two key concepts: Cauchy sequences and completeness.
\begin{definition}[Cauchy sequence]
    \label{def:cauchysequence}
    A sequence $(x_i)_{i=1}^{\infty}$ in a normed space $X$ is said to be
    a Cauchy sequence if for every $\varepsilon > 0$ there exists
    a number $N > 0$ such that
    $\norm{x_i - x_j} < \varepsilon$ whenever $i,j \geq N$.
\end{definition}
\begin{definition}[Completeness]
    \label{def:completeness}
    A normed space $X$ is said to be complete if every Cauchy sequence in it
    converges to a limit in $X$.
\end{definition}
A Banach space is then simply a normed space that is complete, i.e.\ it
satisfies Definition~\ref{def:completeness}.
It is easy to see that a closed subspace $S$ of a Banach space $X$ is also
a Banach space: a Cauchy sequence in $S$ is also a Cauchy sequence in $X$,
which means that it converges to some point $x \in X$, but this implies
that $x$ is a closure point of $S$, which then implies that $x \in S$
since $S$ is closed and, thus, $S$ is complete.

Hilbert spaces are an important special case of Banach spaces
for which we need the concept of an inner product.
An inner product can be thought to be a measure of the orthogonality
between two vectors.
\begin{definition}[Inner product]
    \label{def:innerproduct}
    An inner product on a vector space $X$ is a function
    $\innerprod{\cdot}{\cdot}: X \times X \to \mathbb{R}$
    that satisfies the following properties for all $x,y,z \in X$
    and $a \in \mathbb{R}$.
    \begin{enumerate}[(i)]
        \item $\innerprod{x+y}{z}=\innerprod{x}{z} + \innerprod{y}{z}$.
        \item $\innerprod{ax}{y} = a\innerprod{x}{y}$.
        \item $\innerprod{x}{y} = \innerprod{y}{x}$.
        \item $\innerprod{x}{x} \geq 0$, and $\innerprod{x}{x}=0$
        if and only if $x=0$.
    \end{enumerate}
\end{definition}
A vector space equipped with an inner product is called an inner product space.
An inner product also induces a norm. Namely, given an inner product space $X$,
the mapping $x \mapsto \sqrt{\innerprod{x}{x}}$ defines a norm on $X$,
which means that $X$ is also a normed space.
An inner product space that is complete with respect to the induced norm,
i.e.\ a Banach space, is said to be a Hilbert space.
%Again, a closed subspace of a Hilbert space is also a Hilbert space.

An important result for inner product spaces is the Cauchy-Schwarz inequality.
\begin{theorem}[Cauchy-Schwarz inequality]
    \label{thm:cauchyschwarz}
    Let $X$ be an inner product space with the inner product
    $\innerprod{\cdot}{\cdot}$ and the induced norm $\norm{\cdot}$.
    Then for all $x,y \in X$ it holds that
    \begin{equation*}
        \abs{\innerprod{x}{y}} \leq \norm{x} \norm{y}.
    \end{equation*}
\end{theorem}
\begin{proof}
    Let $x,y \in X$. Then
    \begin{align*}
        0 
        &\leq \norm{x + y}^2 \\
        &= \innerprod{x + y}{x + y} \\
        &= \innerprod{x}{x} + \innerprod{y}{y} + 2\innerprod{x}{y} \\
        &= \norm{x}^2 + \norm{y}^2 + 2\innerprod{x}{y}
    \end{align*}
    so that $-\innerprod{x}{y} \leq (\norm{x}^2 + \norm{y}^2)/2$.
    An identical argument with $x-y$ instead of $x+y$ yields
    $\innerprod{x}{y} \leq (\norm{x}^2 + \norm{y}^2)/2$.
    Combining these two inequalities yields
    \begin{equation}
        \label{eq:cauchyschwarzhelperineq}
        \abs{\innerprod{x}{y}} \leq (\norm{x}^2 + \norm{y}^2)/2.
    \end{equation}
    If $x=0$ or $y=0$, the claim is obviously true.
    Let us thus assume that $x \neq 0 \neq y$. Now
    \begin{align*}
        \abs{\innerprod{x}{y}}
        &= \norm{x} \norm{y} 
           \abs*{\innerprod{\frac{x}{\norm{x}}}{\frac{y}{\norm{y}}}} \\
        &\leq \norm{x} \norm{y} (1+1)/2 \\
        &= \norm{x} \norm{y},
    \end{align*}
    where we used the inequality \eqref{eq:cauchyschwarzhelperineq}.
\end{proof}

\subsubsection{Linear Operators}
\label{subsubsec:linearoperators}

In functional analysis, the noun operator is typically a synonym for a function. 
Operators that are linear are arguably some of the most important entities
in functional analysis. We consider here some basic types of linear operators
that we will need later. In particular, we cover
continuous, bounded and compact linear operators.
\begin{definition}[Linear operator]
    \label{def:linearfunction}
    An operator $A: X \to Y$ between two vector spaces $X$ and $Y$
    is said to be linear if it satisfies the following properties
    for all $x,z \in X$ and $a \in \mathbb{R}$.
    \begin{enumerate}[(i)]
        \item $A(x+z) = A(x) + A(z)$.
        \item $A(ax) = a A(x)$.
    \end{enumerate}
\end{definition}
An obvious corollary to the above definition is that $A(0)=0$ since
$A(0)=A(x-x)=A(x)-A(x)=0$.
When an operator is linear, it is customary to
drop the parentheses around a singular argument.
That is, $Ax$ is used to mean $A(x)$.

The definition of a continuous linear operator between two normed spaces
is identical to the definition of a continuous function typically encountered
in e.g.\ calculus.
\begin{definition}[Continuous linear operator]
    \label{def:continuousoperator}
    A linear operator $A: X \to Y$ between two normed spaces
    $X$ and $Y$ is said to be continuous
    if for every $x \in X$ and for every $\varepsilon > 0$
    there exists $\delta > 0$ such that $\norm{Ax - Az}_Y < \varepsilon$
    for all $z \in X$ satisfying $\norm{x-z}_X < \delta$.
\end{definition}
Next we define a bounded linear operator which, however, should not be confused
with the usual definition of boundedness of a function.
\begin{definition}[Bounded linear operator]
    \label{def:boundedness}
    A linear operator $A: X \to Y$ between two normed spaces
    $X$ and $Y$ is said to be bounded
    if there exists a constant $C > 0$ such that
    $\norm{Ax}_Y \leq C \norm{x}_X$ for all $x \in X$.
\end{definition}
In normed spaces, there is an important connection between
continuous linear operators and bounded linear operators.
Namely, they are precisely the same thing.
We prove this basic but fundamental result.
\begin{theorem}
    \label{thm:boundedcontinuous}
    Let $A: X \to Y$ be a linear operator between normed spaces $X$ and $Y$.
    Then $A$ is continuous if and only if it is bounded.
\end{theorem}
\begin{proof}
    Assume first that $A$ is continuous.
    In particular, $A$ is continuous at the origin $0 \in X$, which
    means that for $\varepsilon=1$ there exists $\delta > 0$ such that
    $\norm{Az}_Y < 1$ for all $z \in X$ satisfying
    $\norm{z}_X < \delta$.
    Let now $x \in  X$, and assume that $x \neq 0$. Define
    \begin{equation*}
        z = \frac{\delta}{2} \frac{x}{\norm{x}_X}
    \end{equation*}
    for which clearly $\norm{z}_X = \delta/2 < \delta$.
    Now by using the linearity and continuity of $A$, we get
    \begin{equation*}
        \frac{\delta}{2 \norm{x}_X} \norm{Ax}_Y
        = \norm*{A\left( \frac{\delta}{2} \frac{x}{\norm{x}_X} \right)}_Y
        = \norm{Az}_Y
        < 1.
    \end{equation*}
    Multiplying each side by $2 \norm{x}_X / \delta$ yields
    \begin{equation*}
        \norm{Ax}_Y \leq \frac{2}{\delta} \norm{x}_X.
    \end{equation*}
    If $x=0$, this inequality
    obviously holds as well since $\norm{Ax}_Y = 0 =\norm{x}_X$. Thus,
    $A$ is bounded with the constant $C = 2/\delta > 0$.

    Then assume that $A$ is bounded.
    Let $x \in X$, $\varepsilon > 0$, and set $\delta = \varepsilon / C$,
    where $C$ is the constant in the definition of boundedness. Now
    for all $z \in X$ satisfying $\norm{x-z}_X < \delta$ it holds that
    \begin{equation*}
        \norm{Ax - Az}_Y
        = \norm{A(x-z)}_Y
        \leq C \norm{x-z}_X
        < C \delta
        = \varepsilon,
    \end{equation*}
    where we used the linearity and boundedness of $A$. Thus, $A$ is continuous.
\end{proof}

A compact linear operator is defined as follows.
\begin{definition}[Compact linear operator]
    \label{def:compactoperator}
    A linear operator $A: X \to Y$ between two normed spaces $X$ and $Y$
    is said to be compact if $A$ maps every bounded set in $X$ to
    a precompact set in $Y$.
\end{definition}
A precompact set was defined in Definition~\ref{def:compactsubset},
and a bounded set $S$ in $X$ is naturally understood as the existence of $r > 0$
such that $S \subset B(0,r)$.

\subsubsection{Dual Spaces}
\label{subsubsec:dualspaces}

The concept of a dual space and, in particular, the so-called Riesz representation 
theorem will be essential tools,
when we study the existence and uniqueness of solutions to boundary value problems.
\begin{definition}[Dual space]
    \label{def:dualspace}
    The dual space of a normed space $X$, denoted by $X'$,
    is the vector space of all real-valued continuous linear operators defined on the space $X$. The vector space operations are the usual pointwise operations:
    for all $\varphi, \psi \in X'$, $a \in \mathbb{R}$ and $x \in X$
    the addition and scalar multiplication are defined by
    \begin{enumerate}[(i)]
        \item $(\varphi + \psi)(x) = \varphi(x) + \psi(x)$,
        \item $(a \varphi)(x) = a \varphi(x)$.
    \end{enumerate}
\end{definition}
Real-valued operators defined on a vector space are more commonly referred to
as functionals. As an example, we now interpret the Dirac delta $\delta_{x_0}$ 
as an element of the dual space of $C(\overline{\Omega})$, where
$C(\overline{\Omega})$ is the normed space of bounded uniformly continuous 
functions defined on a domain $\Omega \subset \mathbb{R}^n$.
The norm is given by
\begin{equation*}
    \norm{u}_{C(\overline{\Omega})} = \sup_{x \in \Omega} \abs{u(x)}.
\end{equation*}
Let $x_0 \in \Omega$. We define the Dirac delta as a functional
$\delta_{x_0}: C(\overline{\Omega}) \to \mathbb{R}$ that evaluates its argument
at the point $x_0$, that is, $\delta_{x_0}(u) = u(x_0)$ for all
$u \in C(\overline{\Omega})$.
To show that $\delta_{x_0} \in C(\overline{\Omega})'$,
we need to show that it is linear and continuous.
Linearity is easy: for all $u,v \in C(\overline{\Omega})$
and $a,b \in \mathbb{R}$ we have
\begin{equation*}
    \delta_{x_0}(au+bv)
    = (au+bv)(x_0)
    = au(x_0)+bv(x_0)
    = a \delta_{x_0}(u) + b \delta_{x_0}(v).
\end{equation*}
Boundedness is also easy: for all $u \in C(\overline{\Omega})$ we have
\begin{equation*}
    \abs{\delta_{x_0}(u)}
    = \abs{u(x_0)}
    \leq \sup_{x \in \Omega} \abs{u(x)}
    = \norm{u}_{C(\overline{\Omega})}.
\end{equation*}
Then by Theorem~\ref{thm:boundedcontinuous}, boundedness and continuity
mean the same thing, so $\delta_{x_0}$ is continuous.
Thus, $\delta_{x_0} \in C(\overline{\Omega})'$.

Given an inner product space $X$ and a vector $y \in X$,
it immediately follows from the definition
of an inner product (Definition~\ref{def:innerproduct})
and the Cauchy-Schwarz inequality (Theorem~\ref{thm:cauchyschwarz})
that the functional $x \mapsto \innerprod{y}{x}$ defined on $X$
belongs to the dual space $X'$. When $X$ is also a Hilbert space,
it turns out that every functional in $X'$ is of this form.
This is the message of the Riesz representation theorem.
\begin{theorem}[Riesz representation theorem]
    \label{thm:rieszrepresentationtheorem}
    Let $X$ be a Hilbert space with the inner product $\innerprod{\cdot}{\cdot}$.
    Let $\varphi \in X'$. Then there exists a unique $y \in X$ such that
    $\varphi(x) = \innerprod{y}{x}$ for all $x \in X$.
\end{theorem}
For a proof, see for example \cite[Theorem~4.12 on p.~81]{rudin1986}.

\subsection{Lebesgue Spaces}
\label{subsec:lebesguespaces}

We present here the definition of
Lebesgue spaces and some useful properties of integrable functions mostly
without proofs. For proofs and more standalone measure theoretic treatment
of integration, see for example \cite{folland1999}. That suffices to say that
we skip the complete definition of the Lebesgue measure and Lebesgue integration
and just take them as given. Finally, we also consider the problem of defining an 
integral over the boundary of a domain.

\subsubsection{Lebesgue Integral}
\label{subsubsec:lebesgueintegral}

The Lebesgue measure over $\mathbb{R}^n$ is essentially a real-valued function
that returns the $n$-dimensional volume of practically any set in $\mathbb{R}^n$,
excluding some pathological sets, and that has properties one would usually
expect such a function to have, e.g.\
invariance under rigid motion such as translation and rotation
and the measure of the union of two disjoint
sets is the sum of their individual measures. We denote the Lebesgue measure
of a (measurable) set $\Omega \subset \mathbb{R}^n$ by $\abs{\Omega}$.

The notation for the Lebesgue integral of a function
$f: \mathbb{R}^n \to \mathbb{R}$ over $\Omega \subset \mathbb{R}^n$
is the usual
\begin{equation}
    \label{eq:integral_of_f}
    \int_{\Omega} f \diff x,
\end{equation}
when it exists. When $\Omega = [a,b] \in \mathbb{R}$,
we simply write $\int_{a}^{b} f \diff x$.
The function $f$ is said to be integrable if its integral \eqref{eq:integral_of_f}
exists and is finite.

We now define the Lebesgue spaces.
\begin{definition}[Lebesgue spaces]
    \label{def:lebesguespaces}
    Let $\Omega \subset \mathbb{R}^n$ be open,
    and let $1 \leq p < \infty$ be a real number.
    The Lebesgue space $L^p(\Omega)$ is the normed space of functions
    $u: \Omega \to \mathbb{R}$ that satisfy
    \begin{equation}
        \label{eq:lpintegral}
        \int_{\Omega} \abs{u}^p \diff x < \infty,
    \end{equation}
    and the norm is given by
    \begin{equation*}
        \norm{u}_{L^p(\Omega)}
        = \left( \int_{\Omega} \abs{u}^p \diff x \right)^{1/p}.
    \end{equation*}
    Moreover, when $p=2$, the space $L^2(\Omega)$ is an inner product space
    with the inner product
    \begin{equation*}
        \innerprod{u}{v}_{L^2(\Omega)} = \int_{\Omega} uv \diff x.
    \end{equation*}
\end{definition}
In fact, the Lebesgue spaces $L^p(\Omega)$ are Banach spaces,
and $L^2(\Omega)$ is a Hilbert space.

We defined $u \in L^p(\Omega)$ as a function.
However, this is not strictly speaking true, because $u$ is not uniquely defined.
To see why, assume that $v$ is another function that equals $u$ everywhere
in $\Omega$ except in a non-empty set whose Lebesgue measure is zero,
e.g.\ a countable set of points.
Now $u-v$ is zero everywhere except in a non-empty set with Lebesgue measure zero,
but then clearly $\norm{u-v}_{L^p(\Omega)} = 0$, which implies that $u=v$
in the space $L^p(\Omega)$, even though they are technically different functions.
The correct way to define $u \in L^p(\Omega)$ would be to consider it as
an equivalence class of functions, where two functions are considered to be
equivalent if they satisfy the integrability condition \eqref{eq:lpintegral}
and they are equal almost everywhere, i.e.\ everywhere except in a set
with Lebesgue measure zero. However, for simplicity, we stick to treating
$u \in L^p(\Omega)$ as a function and say that $u=v$ if they are equal almost 
everywhere. One restriction of this choice is that the pointwise values of $u$ are 
not necessarily well-defined.
In particular, we must be careful when evaluating $\delta_{x_0}(u)$,
where the Dirac delta functional is as in Section~\ref{subsubsec:dualspaces}.

We also define $L^{\infty}(\Omega)$ as the normed space of functions
(again, equivalence classes to be pedantic) that are essentially bounded
over $\Omega$. A function $f: \Omega \to \mathbb{R}$ is said to be
essentially bounded
if there exists a constant $M > 0$ such that $\abs{f(x)} \leq M$
for almost every $x \in \Omega$. More specifically, $L^{\infty}(\Omega)$
is the normed space of functions $u: \Omega \to \mathbb{R}$ that satisfy
\begin{equation*}
    \norm{u}_{L^{\infty}(\Omega)}
    = \esssup_{x \in \Omega} \abs{u(x)}
    < \infty,
\end{equation*}
where the essential supremum is defined by
\begin{equation*}
    \esssup_{x \in \Omega} f(x)
    = \inf \{ M \in \mathbb{R} : \abs{\{ x \in \Omega : f(x) > M \}} = 0 \}.
\end{equation*}
$L^{\infty}(\Omega)$ is a Banach space as well.

Different $L^p$-norm inequalities will be the backbone of many applications
later. An important inequality is Hölder's inequality.
\begin{theorem}[Hölder's inequality]
    \label{thm:höldersineq}
    Let $1 \leq p \leq \infty$ and $1 \leq q \leq \infty$ be
    such that $1/p + 1/q = 1$
    (when $p=\infty$ or $q=\infty$, set $q=1$ or $p=1$, respectively).
    Let $u \in L^p(\Omega)$ and $v \in L^q(\Omega)$. Then $uv \in L^1(\Omega)$ and
    \begin{equation*}
        \norm{uv}_{L^1(\Omega)} \leq \norm{u}_{L^p(\Omega)} \norm{v}_{L^q(\Omega)}.
    \end{equation*}
\end{theorem}
See Folland \cite{folland1999} Theorem~6.2 for the case $1<p,q<\infty$
and Theorem~6.8 for the case $p=\infty$ or $q=\infty$.
Numbers $1 \leq p,q \leq \infty$ that satisfy $1/p + 1/q = 1$
are called conjugate exponents. Theorem~\ref{thm:höldersineq} actually
holds in an arbitrary measure space. In particular, it holds for the
counting measure, which means that if $(x_i)_{i=1}^{\infty}$
and $(y_i)_{i=1}^{\infty}$ are sequences in $\mathbb{R}$, then
\begin{equation*}
    \sum_{i=1}^{\infty} \abs{x_i y_i}
    \leq \left( \sum_{i=1}^{\infty} \abs{x_i}^p \right)^{\frac{1}{p}}
        \left( \sum_{i=1}^{\infty} \abs{y_i}^q \right)^{\frac{1}{q}}.
\end{equation*}

When $\Omega$ is bounded, Hölder's inequality implies the imbedding
$L^q(\Omega) \subset L^p(\Omega)$ when $1 \leq p \leq q \leq \infty$,
which we prove next.
\begin{theorem}
    \label{thm:lpimbedding}
    Assume that $\Omega$ is bounded, that is, $\abs{\Omega} < \infty$.
    Let $1 \leq p \leq q \leq \infty$.
    Then there exists a constant $C \geq 0$ such that
    \begin{equation*}
        \norm{u}_{L^p(\Omega)} \leq C \norm{u}_{L^q(\Omega)}
    \end{equation*}
    for all $u \in L^q(\Omega)$. In other words, $L^q(\Omega) \subset L^p(\Omega)$.
\end{theorem}
\begin{proof}
    We may obviously assume $p < q$, as the case $p=q$ is trivial.
    Let $u \in L^q(\Omega)$, and assume first that $q < \infty$.
    Define $v \equiv 1$ on $\Omega$. Since $\Omega$ is bounded, we have
    for all $1 \leq r < \infty$ that
    \begin{equation*}
        \norm{v}_{L^r(\Omega)}^r
        = \int_{\Omega} 1 \diff x
        = \abs{\Omega}
        < \infty
        \quad \text{and} \quad
        \norm{v}_{L^{\infty}(\Omega)} = 1 < \infty.
    \end{equation*}
    That is, $v \in L^r(\Omega)$ for all $1 \leq r \leq \infty$.
    Now since $u \in L^q(\Omega)$, clearly $\abs{u}^p \in L^{q/p}(\Omega)$.
    Note that $q/p > 1$, and its conjugate exponent is given by
    $q/(q-p)$. Now by applying Hölder's inequality to
    $\abs{u}^p \in L^{q/p}(\Omega)$ and $v \in L^{q/(q-p)}(\Omega)$,
    we get
    \begin{align*}
        \norm{u}_{L^p(\Omega)}^p
        &= \int_{\Omega} \abs{u}^p \diff x \\
        &= \int_{\Omega} v \abs{u}^p \diff x \\
        &\leq \norm{v}_{L^{\frac{q}{q-p}}(\Omega)}
              \left( \int_{\Omega} \abs{u}^q \diff x \right)^{\frac{p}{q}} \\
        &= \abs{\Omega}^{\frac{q-p}{q}} \norm{u}_{L^q(\Omega)}^p.
    \end{align*}
    Taking the $p$th root form both sides proves the claim for $q < \infty$.

    If $q=\infty$, then clearly $\abs{u}^p \in L^{\infty}(\Omega)$ as well
    with $\norm{\abs{u}^p}_{L^{\infty}(\Omega)} = \norm{u}_{L^{\infty}(\Omega)}^p$
    Now by applying Hölder's inequality to
    $\abs{u}^p \in L^{\infty}(\Omega)$ and $v \in L^1(\Omega)$, we get
    \begin{align*}
        \norm{u}_{L^p(\Omega)}^p
        &= \int_{\Omega} v \abs{u}^p \diff x \\
        &\leq \norm{v}_{L^1(\Omega)} \norm{\abs{u}^p}_{L^{\infty}(\Omega)} \\
        &= \abs{\Omega} \norm{u}_{L^{\infty}(\Omega)}^p.
    \end{align*}
    Taking the $p$th root form both sides proves the claim for $q = \infty$.
\end{proof}

It is sometimes beneficial to consider the integral of some function
as a limit of integrals. There exist several convergence theorems
for integrals in the theory of Lebesgue integration.
We present below one such theorem which is more commonly known as the
dominated convergence theorem. For a proof, see
\cite[Theorem 2.24 on p.\ 54]{folland1999}.
\begin{theorem}[The dominated convergence theorem]
    \label{thm:dominated_convergence}
    Let $\Omega \subset \mathbb{R}^n$ be open.
    Let $(f_i)_{i=1}^{\infty}$ be a sequence of functions in $L^1(\Omega)$
    that converges pointwise almost everywhere in $\Omega$ to a function $f$.
    Assume that there exists a function $g \in L^1(\Omega)$ such that
    $\abs{f_i} \leq g$ almost everywhere in $\Omega$. Then
    $f \in L^1(\Omega)$ and
    \begin{equation*}
        \lim_{i \to \infty} \int_{\Omega} f_i \diff x
        = \int_{\Omega} f \diff x.
    \end{equation*}
\end{theorem}

We will also need the following result, which essentially states that
the average values of a continuous function over a ball or a sphere
converge to the value of the function as the radius tends to zero.
\begin{theorem}
    \label{thm:lebesgue_differentiation_theorem}
    Let $f: \Omega \to \mathbb{R}$ be a continuous function
    on the domain $\Omega \subset \mathbb{R}^n$. Then for all $x \in \Omega$
    it holds that
    \begin{equation*}
        \lim_{r \to 0^+}
            \frac{1}{\abs{B(x,r)}}
                \int_{B(x,r)} f(y) \diff y = f(x)
    \end{equation*}
    and
    \begin{equation*}
        \lim_{r \to 0^+}
            \frac{1}{\abs{\partial B(x,r)}}
                \int_{\partial B(x,r)} f(y) \diff S = f(x).
    \end{equation*}
\end{theorem}
\begin{proof}
    Let $x \in \Omega$ and $\varepsilon > 0$.
    The function $f$ is continuous at $x$, which means that there exists
    $r_0 > 0$ such that $\abs{f(x)-f(y)} < \varepsilon$ whenever
    $y \in B(x,r_0) \subset \Omega$. Now
    \begin{align*}
        \abs*{\frac{1}{\abs{B(x,r)}} \int_{B(x,r)} f(y) \diff y - f(x)}
        &= \abs*{\frac{1}{\abs{B(x,r)}} \int_{B(x,r)} f(y) - f(x) \diff y} \\
        &\leq \frac{1}{\abs{B(x,r)}} \int_{B(x,r)} \abs{f(y) - f(x)} \diff y \\
        &\leq \frac{1}{\abs{B(x,r)}} \int_{B(x,r)} \varepsilon \diff y \\
        &= \varepsilon,
    \end{align*}
    whenever $r \leq r_0$. Thus, by the definition of a limit, it holds that
    \begin{equation*}
        \lim_{r \to 0^+}
            \frac{1}{\abs{B(x,r)}}
                \int_{B(x,r)} f(y) \diff y = f(x).
    \end{equation*}
    The proof with the sphere $\partial B(x,r)$ is identical.
\end{proof}

\subsubsection{Boundary Integral}
\label{subsubsec:boundaryintegral}

Assume that $\Omega \subset \mathbb{R}^n$, $n \geq 2$, is a bounded domain with
Lipschitz boundary as per Definition~\ref{def:lipschitzboundary}.
Let us define integration over the boundary $\partial \Omega$.
We give the same definition that is given by e.g.\
Schwab \cite{schwab1998} and Ne{\v c}as \cite{necas2011}.

Let $Q_d$ denote an $(n-1)$-dimensional hypercube centered at the origin
and with side length $2d > 0$. By Definition~\ref{def:lipschitzboundary},
for every $x \in \partial \Omega$ there exists a Lipschitz function
$g: \mathbb{R}^{n-1} \to \mathbb{R}$ and an open set
\begin{equation*}
    U = \left\{ y = \sum_{i=1}^{n} \tilde{y}_i \tilde{e}_i \in \mathbb{R}^n :
        \tilde{y}' = (\tilde{y}_1,\dotsc,\tilde{y}_{n-1}) \in Q_d, \,
        \abs{\tilde{y}_n - g(\tilde{y}')} < h
    \right\}
\end{equation*}
that covers a part of the boundary $\partial \Omega$.
The collection of the sets $U$ for all $x \in \partial \Omega$ is
an open cover of $\partial \Omega$. Since $\Omega$ is bounded, its boundary
is compact. This means that the open cover has a finite subcover which
we denote by $\{ U_j \}_{j=1}^{m}$. The corresponding Lipschitz functions
are denoted by $g_j$, $1 \leq j \leq m$. Similarly, we denote
$Q_{d_j}$ and $\{ \tilde{e}_i^j \}_{i=1}^{n}$.

The functions $g_j$ are the graphs of $\partial \Omega \cap U_j$.
Thus, it makes sense to define the integral of a function
$f: \partial \Omega \to \mathbb{R}$ over $\partial \Omega \cap U_j$
as the usual surface integral, that is,
\begin{equation}
    \label{eq:localboundaryintegral}
    \int_{\partial \Omega \cap U_j} f \diff S
    = \int_{Q_{d_j}} f\left( \sum_{i=1}^{n-1} \tilde{y}_i \tilde{e}_i^j + 
        g_j(\tilde{y}') \tilde{e}_n^j \right)
            \sqrt{1 + \abs{\nabla g_j}^2} \diff \tilde{y}',
\end{equation}
provided the integral on the right exists.
For simplicity, we assume in \eqref{eq:localboundaryintegral}
that the local coordinate system $\{ \tilde{e}_1,\dotsc,\tilde{e}_n \}$
is obtained from the standard basis
with rotation and translation but with no scaling.
Note that since $g_j$ is Lipschitz,
the gradient $\nabla g_j$ exists almost everywhere and is essentially bounded
by Rademacher's theorem \cite{schwab1998}.

To then define the integral over the whole boundary, we note that since
$\{ U_j \}_{j=1}^{m}$ is an open cover of $\partial \Omega$, there exists
a partition of unity of $\partial \Omega$ subordinate to $\{ U_j \}_{j=1}^{m}$. 
That is, there exist functions $\eta_j \in C_0^{\infty}(U_j)$,
$1 \leq j \leq m$, such that
\begin{equation*}
    0 \leq \eta_j \leq 1
    \quad \text{and} \quad
    \sum_{j=1}^{m} \eta_j(x) = 1 \text{ for all } x \in \partial \Omega.
\end{equation*}
$C_0^{\infty}(U_j)$ is the space of infinitely differentiable functions $f$
on $U_j$ whose support, i.e.\
$\supp f = \overline{\{ x \in U_j : f(x) \neq 0 \}}$,
is a compact subset of $U_j$.
We now define the integral over $\partial \Omega$ by
\begin{equation}
    \label{eq:boundaryintegral}
    \int_{\partial \Omega} f \diff S
    = \sum_{j=1}^{m} \int_{\partial \Omega \cap U_j} \eta_j f \diff S,
\end{equation}
where the right-hand side integrals are defined by
equation \eqref{eq:localboundaryintegral}.
This definition does not depend on the cover $\{ U_j \}_{j=1}^{m}$
or the partition of unity $\{ \eta_j \}_{j=1}^{m}$ \cite{necas2011}.

The normed spaces $L^p(\partial \Omega)$ for $1 \leq p \leq \infty$ are defined
analogously to the spaces $L^p(\Omega)$. Two functions in $L^p(\partial \Omega)$
are again identified if they are equal everywhere in $\partial \Omega$ except
possibly in a non-empty set with zero $(n-1)$-dimensional measure over
$\partial \Omega$. Similarly, the definition of the space $L^{\infty}(\partial 
\Omega)$ uses an $(n-1)$-dimensional measure to define essentially bounded
functions. We skip the full construction of a measure over $\partial \Omega$
and merely characterize the $(n-1)$-dimensional measure of a measurable
set $\Gamma \subset \partial \Omega$ as the integral of its indicator
function over $\partial \Omega$ via \eqref{eq:boundaryintegral}.

Hölder's inequality extends to the spaces $L^p(\partial \Omega)$,
which we prove next.
\begin{theorem}
    \label{thm:boundaryhöldersineq}
    Let $1 \leq p \leq \infty$ and $1 \leq q \leq \infty$ be
    such that $1/p + 1/q = 1$.
    Let $u \in L^p(\partial \Omega)$ and $v \in L^q(\partial \Omega)$.
    Then $uv \in L^1(\partial \Omega)$ and
    \begin{equation*}
        \norm{uv}_{L^1(\partial \Omega)} \leq \norm{u}_{L^p(\partial \Omega)}
            \norm{v}_{L^q(\partial \Omega)}.
    \end{equation*}
\end{theorem}
\begin{proof}
    Assume first that $1 < p < \infty$ and $1 < q < \infty$.
    Since $\eta_j \in C_0^{\infty}(U_j)$, we may extend it by zero to the whole
    $\mathbb{R}^n$. Then 
    \begin{align*}
        \int_{\partial \Omega} \abs{uv} \diff S
        &= \sum_{j=1}^{m} \int_{\partial \Omega \cap U_j} \eta_j \abs{uv} \diff S \\
        &= \sum_{j=1}^{m} \int_{Q_{d_j}} \eta_j \abs{uv}
            \sqrt{1 + \abs{\nabla g_j}^2} \diff \tilde{y}' \\
        &= \int_{\mathbb{R}^{n-1}} \sum_{j=1}^{n} \eta_j \abs{uv}
            \sqrt{1 + \abs{\nabla g_j}^2} \diff \tilde{y}' \\
        &= \int_{\mathbb{R}^{n-1}} \sum_{j=1}^{n}
            \left( \eta_j^{\frac{1}{p}} \abs{u}
                \left( 1 + \abs{\nabla g_j}^2 \right)^{\frac{1}{2p}} \right)
            \left( \eta_j^{\frac{1}{q}} \abs{v}
                \left( 1 + \abs{\nabla g_j}^2 \right)^{\frac{1}{2q}} \right)
            \diff \tilde{y}' \\
        &\leq \int_{\mathbb{R}^{n-1}}
            \left( \sum_{j=1}^{n} \eta_j \abs{u}^p \sqrt{1 + \abs{\nabla g_j}^2} 
                \right)^{\frac{1}{p}}
            \left( \sum_{j=1}^{n} \eta_j \abs{v}^q \sqrt{1 + \abs{\nabla g_j}^2}
                \right)^{\frac{1}{q}}
            \diff \tilde{y}' \\
        &\leq \left( \int_{\mathbb{R}^{n-1}} \sum_{j=1}^{n} \eta_j \abs{u}^p
                \sqrt{1 + \abs{\nabla g_j}^2}
                    \diff \tilde{y}' \right)^{\frac{1}{p}}
            \left( \int_{\mathbb{R}^{n-1}} \sum_{j=1}^{n} \eta_j \abs{v}^q
                \sqrt{1 + \abs{\nabla g_j}^2}
                    \diff \tilde{y}' \right)^{\frac{1}{q}} \\
        &= \left( \int_{\partial \Omega} \abs{u}^p \diff S
                \right)^{\frac{1}{p}}
           \left( \int_{\partial \Omega} \abs{v}^q \diff S
                \right)^{\frac{1}{q}} \\
        &= \norm{u}_{L^p(\partial \Omega)} \norm{v}_{L^q(\partial \Omega)},
    \end{align*}
    where the first inequality follows from Hölder's inequality for sums
    and the second inequality follows from Hölder's inequality
    in Theorem~\ref{thm:höldersineq} by using the assumptions
    $u \in L^p(\partial \Omega)$ and $v \in L^q(\partial \Omega)$
    and the definition of a boundary integral as a regular Lebesgue integral
    over $\mathbb{R}^{n-1}$.

    Let us then consider the case when $p=\infty$ or $q=\infty$.
    Without loss of generality, let $p=\infty$. Then clearly
    \begin{equation*}
        \int_{\partial \Omega} \abs{uv} \diff S
        \leq \int_{\partial \Omega} \norm{u}_{L^{\infty}(\partial \Omega)}
            \abs{v} \diff S
        = \norm{u}_{L^{\infty}(\partial \Omega)} \norm{v}_{L^1(\partial \Omega)}.
    \end{equation*}
\end{proof}
Since $\Omega$ is assumed to be bounded,
$\partial \Omega$ has finite $(n-1)$-dimensional measure.
Thus, with a proof more or less identical to the proof of 
Theorem~\ref{thm:lpimbedding}, the imbedding
$L^q(\partial \Omega) \subset L^p(\partial \Omega)$
holds when $1 \leq p \leq q \leq \infty$.

\subsection{Sobolev Spaces}
\label{subsec:sobolevspaces}

Sobolev spaces are the function spaces where we shall search for the solutions
of the boundary value problems. We motivate the definition of
Sobolev spaces by the concept of weak differentiability which is a generalization
of the usual classical concept of differentiability.
For proofs and more complete discussion
on Sobolev spaces, see \cite{necas2011} and \cite{adams2003}.

\subsubsection{Weak Derivatives}
\label{subsubsec:weakderivatives}

Let us first clarify the notation used for the spaces of classically
differentiable functions on an open set $\Omega \subset \mathbb{R}^n$.
The space of $k$ times continuously differentiable functions is denoted by
$C^k(\Omega)$, and $C(\Omega) = C^0(\Omega)$ is the space of continuous functions.
The intersection of $C^k(\Omega)$ for all $k \in \mathbb{N}_0$
is the space of infinitely differentiable functions $C^{\infty}(\Omega)$,
and $C_0^{\infty}(\Omega)$ denotes the space of infinitely differentiable
functions with compact support.

Let us then motivate weak differentiability with a classically
differentiable function. Let $u \in C^1(\Omega)$. Now for all
$\phi \in C_0^{\infty}(\Omega)$ integration by parts gives
\begin{equation}
    \label{eq:weakderivativemotivation1}
    \int_{\Omega} u \frac{\partial \phi}{\partial x_j} \diff x
    = - \int_{\Omega} \frac{\partial u}{\partial x_j} \phi \diff x
\end{equation}
for all $1 \leq j \leq n$. There is no boundary term, because
$\phi$ vanishes near the boundary. The identity \eqref{eq:weakderivativemotivation1}
essentially defines the meaning of a weak partial derivative:
a function $v_j$ is a weak partial derivative of $u$ with respect to the variable
$x_j$ if it satisfies
\begin{equation}
    \label{eq:weakderivativemotivation2}
    \int_{\Omega} u \frac{\partial \phi}{\partial x_j} \diff x
    = - \int_{\Omega} v_j \phi \diff x
\end{equation}
for all $\phi \in C_0^{\infty}(\Omega)$.

Clearly, the classical derivative is also a weak derivative, but
the reverse need not be true. Weak derivatives exist
for a larger class of functions than just classically differentiable functions.
Indeed, we may assume that $u \in L_{\text{loc}}^1(\Omega)$, that is,
$u \in L^1(\Omega_0)$ for all open subsets $\Omega_0 \subset \Omega$ whose
closure is a compact subset of $\Omega$. Then $v_j \in L_{\text{loc}}^1(\Omega)$
is a weak partial derivative of $u$ if it satisfies equation 
\eqref{eq:weakderivativemotivation2} for all $\phi \in C_0^{\infty}(\Omega)$.
If a weak partial derivative exists, it is unique up to sets of measure zero
\cite{adams2003}.

Extending the above to higher orders
of weak differentiability is straightforward.
For this we use the standard multi-index notation.
Let $\alpha = (\alpha_1,\dotsc,\alpha_n) \in \mathbb{N}_0^n$
be a multi-index, and define
$\abs{\alpha} = \alpha_1 + \dotsb + \alpha_n$. The elements of $\alpha$
correspond to the numbers of times a function is differentiated
with respect to each variable. Now for $u \in C^k(\Omega)$, $k \geq 1$,
and for $\abs{\alpha} \leq k$ we denote the $\alpha$th partial derivative of $u$ by
\begin{equation*}
    D^{\alpha} u
    = \frac{\partial^{\abs{\alpha}}}
        {\partial x_1^{\alpha_1} \dotsb \partial x_n^{\alpha_n}} u
    = \frac{\partial^{\alpha_1}}{\partial x_1^{\alpha_1}} \dotsb
        \frac{\partial^{\alpha_n}}{\partial x_n^{\alpha_n}} u,
\end{equation*}
where $D^{(0,\dotsc,0)}u=u$.
Successive application of integration by parts gives
\begin{equation*}
    \int_{\Omega} u D^{\alpha} \phi \diff x
    = (-1)^{\abs{\alpha}} \int_{\Omega} D^{\alpha} u \phi \diff x
\end{equation*}
for all $\phi \in C_0^{\infty}(\Omega)$, and $v_{\alpha} = D^{\alpha} u$
is also the $\alpha$th weak partial derivative of $u$.

Let us synthesize the above discussion into a self-contained definition
of a weak partial derivative of arbitrary order.
\begin{definition}[Weak partial derivative]
    \label{def:weakderivative}
    Let $\Omega \subset \mathbb{R}^n$ be open,
    $u \in L_{\text{loc}}^1(\Omega)$, and let 
    $\alpha \in \mathbb{N}_0^n$ be a multi-index. If there exists
    $v_{\alpha} \in L_{\text{loc}}^1(\Omega)$ such that
    \begin{equation*}
        \int_{\Omega} u D^{\alpha} \phi \diff x
        = (-1)^{\abs{\alpha}} \int_{\Omega} v_{\alpha} \phi \diff x
    \end{equation*}
    for all $\phi \in C_0^{\infty}(\Omega)$, then
    $v_{\alpha}$ is said to be the $\alpha$th weak partial derivative of $u$,
    and it is denoted by $D^{\alpha} u$.
\end{definition}
Weak derivatives behave much like classical derivatives.
For example, weak differentiation is commutative and linear:
\begin{equation*}
    D^{\alpha}(D^{\beta} u) = D^{\beta}(D^{\alpha} u)
    \quad \text{and} \quad
    D^{\alpha}(a u + b v) = a D^{\alpha}u + b D^{\alpha}v,
    \quad a,b \in \mathbb{R}.
\end{equation*}
We tend to use the classical notation $\partial u / \partial x_j$
or just $D_j u$ for weak partial derivatives as well,
and this is extended in an obvious manner to other
differential operators such as the gradient $\nabla u$ and the Laplacian $\Delta u$.

We are now ready to define the Sobolev spaces as subspaces of Lebesgue
spaces whose elements are weakly differentiable.
\begin{definition}[Sobolev spaces]
    \label{def:sobolevspaces}
    Let $\Omega \subset \mathbb{R}^n$ be open.
    Let $k$ be a positive integer and $1 \leq p \leq \infty$.
    The Sobolev space $W^{k,p}(\Omega)$ is the normed space of functions
    $u \in L^p(\Omega)$ that have all weak partial derivatives of orders
    $0 \leq \abs{\alpha} \leq k$, and the weak partial derivatives satisfy
    $D^{\alpha} u \in L^p(\Omega)$ for all $0 \leq \abs{\alpha} \leq k$.
    The norm is given by
    \begin{align*}
        \norm{u}_{W^{k,p}(\Omega)}
        &= \left( \sum_{0 \leq \abs{\alpha} \leq k}
                \norm{D^{\alpha} u}_{L^p(\Omega)}^p \right)^{\frac{1}{p}}
                    \quad \text{for } 1 \leq p < \infty, \\
        \norm{u}_{W^{k,\infty}(\Omega)}
        &= \max_{0 \leq \abs{\alpha} \leq k}
                \norm{D^{\alpha} u}_{L^{\infty}(\Omega)}.
    \end{align*}
    Moreover, when $p=2$, the space $W^{k,2}(\Omega)$, commonly denoted
    by $H^k(\Omega)$, is an inner product space with the inner product
    \begin{equation*}
        \innerprod{u}{v}_{H^k(\Omega)}
        = \sum_{0 \leq \abs{\alpha} \leq k}
                \innerprod{D^{\alpha} u}{D^{\alpha} v}_{L^2(\Omega)}.
    \end{equation*}
\end{definition}
For $1 \leq p < \infty$ it is also common to consider the
$L^p$-norms of the weak derivatives of some fixed order $\abs{\alpha} = k$:
\begin{equation*}
    \abs{u}_{W^{k,p}(\Omega)}
    = \left( \sum_{\abs{\alpha} = k}
                \norm{D^{\alpha} u}_{L^p(\Omega)}^p \right)^{\frac{1}{p}}.
\end{equation*}
These are seminorms in $W^{k,p}(\Omega)$.

The Sobolev spaces inherit many of their properties from the Lebesgue spaces.
Once again, two functions in a Sobolev space are identified,
if they are equal almost everywhere.
The spaces $W^{k,p}(\Omega)$ are Banach spaces for all $k$ and $p$,
and $H^k(\Omega)$ is a Hilbert space for all $k$.
When $k$ and $m$ are positive integers such that $k \leq m$,
it is obvious that the imbedding
$W^{m,p}(\Omega) \subset W^{k,p}(\Omega)$ holds for all $1 \leq p \leq \infty$.
When $\Omega$ is bounded, Theorem~\ref{thm:lpimbedding} can also be extended
to the Sobolev spaces, which we show next.
\begin{theorem}
    \label{thm:sobolevlpimbedding}
    Assume that $\Omega$ is bounded. Let $k$ be a positive integer, and let
    $1 \leq p \leq q \leq \infty$. Then there exists a constant $C \geq 0$
    such that
    \begin{equation*}
        \norm{u}_{W^{k,p}(\Omega)} \leq C \norm{u}_{W^{k,q}(\Omega)}
    \end{equation*}
    for all $u \in W^{k,q}(\Omega)$. In other words,
    $W^{k,q}(\Omega) \subset W^{k,p}(\Omega)$.
\end{theorem}
\begin{proof}
    Let $u \in W^{k,q}(\Omega)$, and assume first that $q < \infty$.
    Then by Theorem~\ref{thm:lpimbedding}, we get
    \begin{align}
        \norm{u}_{W^{k,p}(\Omega)}^p
        &= \sum_{0 \leq \abs{\alpha} \leq k} \norm{D^{\alpha} u}_{L^p(\Omega)}^p
            \nonumber \\
        &\leq C_1 \sum_{0 \leq \abs{\alpha} \leq k}
            \norm{D^{\alpha} u}_{L^q(\Omega)}^p \nonumber \\
        \label{eq:thm2.8intermediate}
        &= C_1 \sum_{0 \leq \abs{\alpha} \leq k}
            \norm{D^{\alpha} u}_{L^q(\Omega)}^{q \frac{p}{q}}
    \end{align}
    for some constant $C_1 \geq 0$ independent of $u$.
    The function $t \mapsto t^{p/q}$ is increasing on $[0, \infty)$,
    which means that
    \begin{equation*}
        \norm{D^{\alpha} u}_{L^q(\Omega)}^{q \frac{p}{q}}
        \leq \left( \sum_{0 \leq \abs{\alpha} \leq k}
            \norm{D^{\alpha} u}_{L^q(\Omega)}^{q}
                \right)^{\frac{p}{q}}
        = \norm{u}_{W^{k,q}(\Omega)}^p
    \end{equation*}
    Inserting this into \eqref{eq:thm2.8intermediate} gives
    \begin{equation*}
        \norm{u}_{W^{k,p}(\Omega)}^p
        \leq C_1 \sum_{0 \leq \abs{\alpha} \leq k} \norm{u}_{W^{k,q}(\Omega)}^p
        = C_1 C_2 \norm{u}_{W^{k,q}(\Omega)}^p,
    \end{equation*}
    where
    $C_2 = \abs{\{ \alpha \in \mathbb{N}_0^n : 0 \leq \abs{\alpha} \leq k \}}$.
    Taking the $p$th root from both sides proves the claim for $q < \infty$.

    Assume then that $q = \infty$. The case $p=q$ is obvious, so let $p < \infty$.
    By Theorem~\ref{thm:lpimbedding} and the definition of
    $\norm{u}_{W^{k,\infty}(\Omega)}$, we get
    \begin{align*}
        \norm{u}_{W^{k,p}(\Omega)}^p
        &= \sum_{0 \leq \abs{\alpha} \leq k} \norm{D^{\alpha} u}_{L^p(\Omega)}^p \\
        &\leq C_1 \sum_{0 \leq \abs{\alpha} \leq k}
            \norm{D^{\alpha} u}_{L^{\infty}(\Omega)}^p \\
        &\leq C_1 \sum_{0 \leq \abs{\alpha} \leq k}
            \norm{u}_{W^{k,\infty}(\Omega)}^p \\
        &= C_1 C_2 \norm{u}_{W^{k,\infty}(\Omega)}^p.
    \end{align*}
    Taking the $p$th root from both sides proves the claim for $q=\infty$.
\end{proof}

Functions in Sobolev spaces resemble classically differentiable functions,
although they need not be continuous or bounded in the interior of the domain.
This resemblance becomes more explicit by the properties of
weak derivatives but also by the fact that the space
$C^{\infty}(\Omega) \cap W^{k,p}(\Omega)$ is dense in $W^{k,p}(\Omega)$
for all positive integers $k$ and real numbers $1 \leq p < \infty$.
In other words, for every $u \in W^{k,p}(\Omega)$ there exists a sequence
of infinitely differentiable functions that converges to $u$ with respect
to the norm $\norm{\cdot}_{W^{k,p}(\Omega)}$. For a proof, see
\cite[Theorem 3.17 on p.\ 67]{adams2003}. This is an immensely useful
result that allows one to deduce properties of Sobolev spaces by first
proving the property for smooth functions and then extend it to functions
in Sobolev spaces by passing to a limit. Note, however, that the density result
does not hold when $p=\infty$.

It is also common to consider the closure of the space $C_0^{\infty}(\Omega)$
with respect to the norm $\norm{\cdot}_{W^{k,p}(\Omega)}$. The resulting
subspace of $W^{k,p}(\Omega)$ is denoted by $W_0^{k,p}(\Omega)$ and
by $H_0^k(\Omega)$ when $p=2$.
A function in this space vanishes on the boundary $\partial \Omega$
in the trace sense. Boundary traces will be discussed later.
These types of Sobolev spaces are important for partial differential equations
with Dirichlet boundary conditions.

For a function in $W_0^{1,p}(\Omega)$ there exists a useful inequality
between the $L^p$-norms of the function and its gradient. This is commonly
known as Poincaré's inequality.
\begin{theorem}[Poincaré's inequality]
    \label{thm:poincare_inequality}
    Let $\Omega \subset \mathbb{R}^n$ be a bounded domain,
    and let $1 \leq p < \infty$.
    Then there exists a constant $C > 0$ such that
    \begin{equation*}
        \norm{u}_{L^p(\Omega)} \leq C \abs{u}_{W^{1,p}(\Omega)}
    \end{equation*}
    for all $u \in W_0^{1,p}(\Omega)$.
\end{theorem}
For a proof, see \cite[Theorem 6.30 on p. 183]{adams2003}.
Theorem~\ref{thm:poincare_inequality} is sometimes also called
Friedrichs' inequality or Poincaré-Friedrichs inequality.
We will later prove a variant of Poincaré's inequality,
where $u$ does not necessarily belong to the space $W_0^{1,p}(\Omega)$.

\subsubsection{Sobolev Imbeddings}
\label{subsubsec:sobolevimbeddingtheorem}

We previously saw two types of imbeddings between Sobolev spaces $W^{k,p}(\Omega)$
where either $k$ or $p$ was fixed:
when $k$ and $m$ are such that $k \leq m$, then
$W^{m,p}(\Omega) \subset W^{k,p}(\Omega)$ for all $1 \leq p \leq \infty$,
and when $\Omega$ is also bounded, then $W^{k,q}(\Omega) \subset W^{k,p}(\Omega)$
whenever $1 \leq p \leq q \leq \infty$.
When the boundary of $\Omega$ satisfies some additional regularity
assumptions, further imbeddings exist where both $k$ and $p$ can vary.
Moreover, in some cases for some positive integer $j$,
$W^{k,p}(\Omega)$ can be considered as a subset of
$j$ times continuously differentiable functions
in the sense that each 
equivalence class $u \in W^{k,p}(\Omega)$ contains
a $j$ times continuously differentiable function.
Such an imbedding is denoted by
$W^{k,p}(\Omega) \subset C^j(\Omega)$ as usual. These further imbeddings
are usually formulated as the Sobolev imbedding theorem \cite{adams2003}.

The Sobolev imbedding theorem also states that the imbeddings are continuous.
This means that when we consider an imbedding of the form $X \subset Y$
between two normed spaces $X$ and $Y$ via the identity mapping
$I: X \to Y$, $Ix = x$, then the operator $I$ is continuous.
Since the operator $I$ is linear, this is equivalent to $I$ being bounded
by Theorem~\ref{thm:boundedcontinuous}. For example, the imbedding
$W^{m,p}(\Omega) \subset W^{k,p}(\Omega)$ for $k \leq m$ is obviously
continuous, since $\norm{u}_{W^{k,p}(\Omega)} \leq \norm{u}_{W^{m,p}(\Omega)}$
for all $u \in W^{m,p}(\Omega)$. By Theorem~\ref{thm:sobolevlpimbedding},
the imbedding $W^{k,q}(\Omega) \subset W^{k,p}(\Omega)$ for
$1 \leq p \leq q \leq \infty$ is also continuous.
Similarly, an imbedding is said to be compact if the operator $I$ is compact,
see Definition~\ref{def:compactoperator}. Most Sobolev imbeddings are
compact, and this result is known as the Rellich-Kondrachov theorem 
\cite{adams2003}.

We now present a simplified combined version of the Sobolev imbedding
theorem and the Rellich-Kondrachov theorem which contains the relevant
imbeddings for our purposes. In their most general forms,
both theorems consider both bounded and unbounded domains,
different types of boundary regularity, and the results
depend on the dimension $n$. We are only interested in the
case $n=2$ and bounded domains with Lipschitz boundaries.
Note that below $C^k(\overline{\Omega})$ denotes the normed space of functions
$u \in C^k(\Omega)$ for which $D^{\alpha} u$ is bounded and uniformly
continuous on $\Omega$ for all $0 \leq \abs{\alpha} \leq k$,
and its norm is given by
\begin{equation*}
    \norm{u}_{C^k(\overline{\Omega})}
    = \max_{0 \leq \abs{\alpha} \leq k}
        \sup_{x \in \Omega} \abs{D^{\alpha} u(x)}.
\end{equation*}
As usual, we use the alias $C(\overline{\Omega}) = C^0(\overline{\Omega})$.
The notation $C^k(\overline{\Omega})$ signifies
that $u$ along with its partial derivatives of order
$\abs{\alpha} \leq k$ can be uniquely extended to the boundary $\partial \Omega$.
\begin{theorem}
    \label{thm:sobolevimbedding}
    Let $\Omega \subset \mathbb{R}^2$ be a bounded domain with Lipschitz boundary.
    Let $k \geq 1$ and $j \geq 0$ be integers, and let $1 \leq p < \infty$ be a
    real number. Then the following imbeddings are continuous and compact.
    \begin{enumerate}[(i)]
        \item If $kp < 2$, then
        \begin{equation*}
            W^{j+k,p}(\Omega) \subset W^{j,q}(\Omega)
            \quad \text{if } 1 \leq q < 2p/(2-kp) .
        \end{equation*}
        \item If $kp = 2$, then
        \begin{equation*}
            W^{j+k,p}(\Omega) \subset W^{j,q}(\Omega)
            \quad \text{if } 1 \leq q < \infty.
        \end{equation*}
        \item If $kp > 2$, then
        \begin{align*}
            W^{j+k,p}(\Omega) &\subset W^{j,q}(\Omega)
            \quad \text{if } 1 \leq q < \infty, \\
            W^{j+k,p}(\Omega) &\subset C^j(\overline{\Omega}).
        \end{align*}
    \end{enumerate}
    Note that $W^{0,p}(\Omega) = L^p(\Omega)$.
\end{theorem}
For the proofs and complete versions of the above imbeddings, see
\cite[Theorem 4.12 on p. 85]{adams2003} for the Sobolev imbedding theorem
and \cite[Theorem 6.3 on p. 168]{adams2003} for the Rellich-Kondrachov theorem.

Let us immediately note one important consequence of 
Theorem~\ref{thm:sobolevimbedding} regarding the Dirac delta functional
$\delta_{x_0}$. In Section~\ref{subsubsec:dualspaces}, we defined $\delta_{x_0}$
as an element of the dual space $C(\overline{\Omega})'$ such that
for some $x_0 \in \Omega$ we have $\delta_{x_0}(u) = u(x_0)$
for all $u \in C(\overline{\Omega})$.
If we now try to define $\delta_{x_0}$ similarly as an element of the dual space
of an arbitrary Sobolev space $W^{k,p}(\Omega)$, we run into the subtlety
that $W^{k,p}(\Omega)$ does not really consist of functions but equivalence
classes of functions, and for every possible value $c \in \mathbb{R}$
each such equivalence class contains a function $u$ such that $u(x_0) = c$.
The problem then becomes to choose one of these functions to evaluate
$\delta_{x_0}(u)$. When $W^{k,p}(\Omega) \subset C(\overline{\Omega})$,
we can simply choose the continuous function and $\delta_{x_0}(u)$
is well-defined. Theorem~\ref{thm:sobolevimbedding} states when this is possible.
For example, $W^{1,p}(\Omega) \subset C(\overline{\Omega})$ when $p > 2$
and, thus, $\delta_{x_0} \in W^{1,p}(\Omega)'$. Note that the continuity
of $\delta_{x_0}$ follows from the continuity of the imbedding:
\begin{equation*}
    \abs{\delta_{x_0}(u)}
    = \abs{u(x_0)}
    \leq \norm{u}_{C(\overline{\Omega})}
    \leq C \norm{u}_{W^{1,p}(\Omega)}
\end{equation*}
for all $u \in W^{1,p}(\Omega)$.

\subsubsection{Boundary Traces}
\label{subsubsec:boundarytraces}

By definition, boundary value problems require the ability to consider
the restriction of a function on the boundary $\partial \Omega$ in some sense.
This is obviously possible in the usual pointwise sense
for functions in $C(\overline{\Omega})$
and, thus by Theorem~\ref{thm:sobolevimbedding}, for functions
in e.g.\ $W^{1,p}(\Omega) \subset C(\overline{\Omega})$
when $\Omega$ is a two-dimensional bounded domain with Lipschitz boundary
and $p > 2$. But what about the case $p \leq 2$ where pointwise
evaluation does not necessarily make sense? Moreover,
the $n$-dimensional Lebesgue measure of $\partial \Omega$ is zero.
Fortunately, a function in $W^{1,p}(\Omega)$, for any $1 \leq p \leq 2$,
restricted on $\partial \Omega$
can be considered as a function in $L^q(\partial \Omega)$ for some $q$
in a way that extends naturally to functions in $C(\overline{\Omega})$.
This is the message of the following trace theorem.
\begin{theorem}[Trace theorem]
    \label{thm:tracetheorem}
    Let $\Omega \subset \mathbb{R}^2$ be a bounded domain with Lipschitz boundary.
    Let $1 \leq p < 2$ and $q = p/(2-p)$,
    Then there exists a unique bounded linear operator
    \begin{equation*}
        T: W^{1,p}(\Omega) \to L^q(\partial \Omega)   
    \end{equation*}
    such that $Tu = u|_{\partial \Omega}$ for all
    $u \in C(\overline{\Omega}) \cap W^{1,p}(\Omega)$.
    Moreover, if $2 \leq p < \infty$,
    then the claim holds for all $1 \leq q < \infty$.
\end{theorem}
For a reference,
see \cite[Theorem 4.2 on p.\ 79 and Theorem 4.6 on p.\ 81]{necas2011}.
The operator $T$ is called the trace operator.
For a function $u \in W^{1,p}(\Omega)$ it is customary to use the usual
notation $u|_{\partial \Omega}$ to mean the restriction of $u$ on the
boundary $\partial \Omega$ in the trace sense.
Similarly, $\norm{u}_{L^p(\partial \Omega)}$ is used to mean
$\norm{Tu}_{L^p(\partial \Omega)}$.

The trace operator is not surjective.
Thus, if we wish to pick a function e.g.\ $g \in L^2(\partial \Omega)$
such that there exists $u \in H^1(\Omega)$ for which
$Tu = g$, then we need to require explicitly that $g \in T(H^1(\Omega))$.
The range of the trace operator can be characterized as a fractional-order
Sobolev space on $\partial \Omega$, which we shall not consider
any further. For more information, see \cite{adams2003}
or \cite{lions1972}.

Boundary values are also needed in the well-known integration by parts
formula for continuously differentiable functions.
Using the concept of a boundary trace,
integration by parts can be extended to functions in Sobolev spaces.
\begin{theorem}[Integration by parts]
    \label{thm:integrationbyparts}
    Let $\Omega \subset \mathbb{R}^2$ be a bounded domain with Lipschitz
    boundary. Let $1 < p < \infty$ and $1 < q < \infty$ be such that
    $1/p + 1/q \leq 3/2$, and let $u \in W^{1,p}(\Omega)$
    and $v \in W^{1,q}(\Omega)$. Then for $i=1,2$ it holds that
    \begin{equation*}
        \int_{\Omega} u \frac{\partial v}{\partial x_i} \diff x
        = - \int_{\Omega} \frac{\partial u}{\partial x_i} v \diff x
            + \int_{\partial \Omega} uv n_i \diff S,
    \end{equation*}
    where $n = (n_1, n_2)$ is the exterior unit normal
    to the boundary $\partial \Omega$.
\end{theorem}
See \cite[Theorem 1.1 on p.\ 117]{necas2011} for the proof,
where the claim is first proved for smooth functions and then
extended to the Sobolev spaces via density. Note that the exterior
unit normal exists almost everywhere on $\partial \Omega$
\cite[Lemma 4.2 on p.\ 83]{necas2011}.
As a corollary to Theorem~\ref{thm:integrationbyparts},
let us prove a Green's formula that will be extremely useful later.
\begin{theorem}[Green's formula]
    \label{thm:greensformula}
    Let $\Omega \subset \mathbb{R}^2$ be a bounded domain with Lipschitz
    boundary. Let $1 < p < \infty$ and $1 < q < \infty$ be such that
    $1/p + 1/q \leq 3/2$, and let $u \in W^{2,p}(\Omega)$
    and $v \in W^{1,q}(\Omega)$. Then
    \begin{equation*}
        \int_{\Omega} \nabla u \cdot \nabla v \diff x
        = -\int_{\Omega} \Delta u v \diff x
            + \int_{\partial \Omega} \frac{\partial u}{\partial n} v \diff S,
    \end{equation*}
    where $\partial u / \partial n = \nabla u \cdot n$ is the directional
    derivative of $u$ in the direction of the exterior
    unit normal on $\partial \Omega$.
\end{theorem}
\begin{proof}
    Since $u \in W^{2,p}(\Omega)$, then
    $\nabla u \in W^{1,p}(\Omega) \times W^{1,p}(\Omega)$.
    Now by the integration by parts formula in
    Theorem~\ref{thm:integrationbyparts}, we get
    \begin{align*}
        \int_{\Omega} \nabla u \cdot \nabla v \diff x
        &= \int_{\Omega} \frac{\partial u}{\partial x_1}
            \frac{\partial v}{\partial x_1} \diff x
            + \int_{\Omega} \frac{\partial u}{\partial x_2}
            \frac{\partial v}{\partial x_2} \diff x \\
        &= -\int_{\Omega} \left( 
            \frac{\partial^2 u}{\partial x_1^2}
                + \frac{\partial^2 u}{\partial x_2^2} \right) v \diff x
            + \int_{\partial \Omega} \left(
                \frac{\partial u}{\partial x_1} n_1
                    + \frac{\partial u}{\partial x_2} n_2 \right) v \diff S \\
        &= -\int_{\Omega} \Delta u v \diff x
            + \int_{\partial \Omega} \frac{\partial u}{\partial n} v \diff S.
    \end{align*}
\end{proof}

\clearpage

\section{Poisson's Equation in a Polygon}
\label{sec:poissons_equation_in_a_polygon}

Assume that $\Omega \subset \mathbb{R}^2$ is a bounded polygonal domain.
Let $\Gamma_j$ denote the $j$th linear boundary segment on $\partial \Omega$
for $j = 1,2,\dotsc,J$, where $J$ is the total number of boundary segments.
That is,
\begin{equation*}
    \partial \Omega = \bigcup_{1 \leq j \leq J} \overline{\Gamma_j}.
\end{equation*}
The linear boundary segments are assumed to be analogous to one-dimensional
open intervals, which is why the union is taken over the closures of the
boundary segments. We assume that $\Omega$ does not contain any slits.
In other words, the angle between two linear boundary segments with a common vertex
is never $0$ nor $2\pi$.
This implies that $\partial \Omega$ is Lipschitz according to
Definition~\ref{def:lipschitzboundary}.

Poisson's equation in $\Omega$ with prescribed boundary conditions
is classically formulated as finding a function
$u \in C^2(\Omega) \cap C^1(\overline{\Omega})$ such that
\begin{equation}
    \label{eq:classical_poissons_equation}
    \left\{
        \begin{aligned}
            -\Delta u &= f && \text{in } \Omega \\
            u &= g_j && \text{on } \Gamma_j, \quad j \in D \\
            \frac{\partial u}{\partial n} &= g_j && \text{on } \Gamma_j,
            \quad j \in N,
        \end{aligned}
    \right.
\end{equation}
where the functions $f$ and $g_j$ for $j=1,2,\dotsc,J$ constitute the data
of the problem. On each linear boundary segment either a Dirichlet or a Neumann
boundary condition is imposed according to the index sets $D$ and $N$, respectively,
that are disjoint subsets of the full index set
$\{ j \in \mathbb{N} : 1 \leq j \leq J \}$.

Of course, $\Omega$ need not be polygonal for the boundary value problem
\eqref{eq:classical_poissons_equation} to make sense. One could consider
a general open set $\Omega \subset \mathbb{R}^n$, but for the purposes of
this thesis the assumption that $\Omega$ is a polygon has important theoretical
and practical implications. This is especially true in the light of
the finite element method.

The unknown function $u$ in problem \eqref{eq:classical_poissons_equation}
can be used to model quantities, such as chemical concentration, temperature or
electric potential, over a physical domain $\Omega$ when the quantity is
in equilibrium, that is, the quantity does not change over time \cite{evans2010}. 
The function $f$ is typically called the load term or the source term. For example,
in the context of heat diffusion, it can correspond to a source of heat,
and its unit is energy per unit volume and time. In the context of electrostatics,
the function $f$ corresponds to the charge density over $\Omega$.
We refer to the function $f$ simply as the load.
The Dirichlet boundary condition means that the quantity is held fixed
on that boundary segment,
and the Neumann boundary condition corresponds to the flux
on that boundary segment. For example, in the context of heat diffusion,
$g_j = 0$ for some $j \in N$ means that the boundary segment $\Gamma_j$ is perfectly 
insulated.

A solution of the classically formulated problem 
\eqref{eq:classical_poissons_equation} is accordingly said to be classical.
However, proving the existence of classical solutions is typically difficult
and may turn out to be impossible if the data are not at least continuous
and the boundary $\partial \Omega$ smooth enough.
Even when a classical solution does exist, approximating it via
e.g.\ finite differences can become unwieldy in complex domains.
This makes the classical problem unfit for many practical applications.
Instead, the problem is typically formulated in a weak form for which
the existence and uniqueness of a solution, even for irregular data,
follows rather easily from abstract results of functional analysis.
Then the weak solution can be approximated
with the finite element method for virtually any shape that can be modeled
as a union of polygons.

Let us formulate the boundary value problem \eqref{eq:classical_poissons_equation}
in weak form.
Let $f \in L^2(\Omega)$, $g_j \in T(H^2(\Omega))$ for $j \in D$ and
$g_j \in T(H^1(\Omega))$ for $j \in N$, where $T$ is the trace operator in
Theorem~\ref{thm:tracetheorem}. Assume that $u \in H^2(\Omega)$
is a classical solution of the problem \eqref{eq:classical_poissons_equation}.
Let $v \in H^1(\Omega)$ such that $v|_{\Gamma_j} = 0$ for all $j \in D$.
Multiplying both sides of Poisson's equation by $v$,
integrating both sides over $\Omega$ and applying Green's formula
from Theorem~\ref{thm:greensformula} gives
\begin{equation}
    \label{eq:weak_formulation_step1}
    \int_{\Omega} \nabla u \cdot \nabla v \diff x
        - \int_{\partial \Omega} \frac{\partial u}{\partial n} v \diff S
    = \int_{\Omega} f v \diff x.
\end{equation}
Using the Neumann boundary conditions and the fact that
$v|_{\Gamma_j} = 0$ for all $j \in D$, the boundary integral becomes
\begin{align}
    \int_{\partial \Omega} \frac{\partial u}{\partial n} v \diff S
    &= \sum_{j \in D} \int_{\Gamma_j} \frac{\partial u}{\partial n} v \diff S
        + \sum_{j \in N} \int_{\Gamma_j} \frac{\partial u}{\partial n} v \diff S
            \nonumber \\
    \label{eq:weak_formulation_step2}
    &= \sum_{j \in N} \int_{\Gamma_j} g_j v \diff S.
\end{align}
Combining \eqref{eq:weak_formulation_step1} and \eqref{eq:weak_formulation_step2}
gives
\begin{equation}
    \label{eq:weak_formulation_variational}
    \int_{\Omega} \nabla u \cdot \nabla v \diff x
    = \int_{\Omega} f v \diff x + \sum_{j \in N} \int_{\Gamma_j} g_j v \diff S.
\end{equation}
Note that the expression \eqref{eq:weak_formulation_variational}
also makes sense when only
$u \in H^1(\Omega)$. This motivates the definition of a weak solution
to the problem \eqref{eq:classical_poissons_equation}.
\begin{definition}
    \label{def:weak_solution}
    A function $u \in H^1(\Omega)$ is said to be a weak solution to the
    boundary value problem \eqref{eq:classical_poissons_equation} if
    \begin{enumerate}[(i)]
        \item it satisfies the identity \eqref{eq:weak_formulation_variational}
        for all $v \in H^1(\Omega)$ with $v|_{\Gamma_j} = 0$ for all $j \in D$,
        \item $u|_{\Gamma_j} = g_j$ for all $j \in D$.
    \end{enumerate}
\end{definition}

It is difficult to deduce the existence of a weak solution to the problem
\eqref{eq:classical_poissons_equation} when it is formulated in its most
general form. Instead, it is more convenient
to separately consider the cases $D \neq \varnothing$,
i.e.\ pure Dirichlet and mixed Dirichlet-Neumann problems, and
$D = \varnothing$, i.e.\ pure Neumann problem.
For each case we consider a special instance of the problem whose
solution will enable us to deduce the existence of a weak solution
to the general problem as per Definition~\ref{def:weak_solution}.
Let us begin with the case $D \neq \varnothing$.

It will be easier to work with
a problem that has homogeneous Dirichlet boundary conditions
$g_j = 0$ for all $j \in D$.
Thus, we would like to transform the problem \eqref{eq:classical_poissons_equation}
to an equivalent problem with such boundary conditions.
To make this simple, we always assume that there exists a function
$u_D \in H^2(\Omega)$ such that $u_D|_{\Gamma_j} = g_j$ for all $j \in D$.
This implies that when $g_i$ and $g_j$ approach a common vertex,
they approach the same value, because
$H^2(\Omega) \subset C(\overline{\Omega})$
by the Sobolev imbedding theorem, i.e.\ Theorem~\ref{thm:sobolevimbedding}.

Consider then finding a weak solution $w \in H^1(\Omega)$ to the modified problem
\begin{equation}
    \label{eq:poissons_equation_modified}
    \left\{
        \begin{aligned}
            -\Delta w &= f + \Delta u_D && \text{in } \Omega \\
            w &= 0 && \text{on } \Gamma_j, \quad j \in D \\
            \frac{\partial w}{\partial n} &=
                g_j - \frac{\partial u_D}{\partial n} && \text{on } \Gamma_j,
                \quad j \in N.
        \end{aligned}
    \right.
\end{equation}
Note that since $u_D \in H^2(\Omega)$, it holds that
$f + \Delta u_D \in L^2(\Omega)$, and since the normal vector $n$
is constant on each linear boundary segment, it clearly holds that
$g_j - \partial u_D / \partial n \in T(H^1(\Omega))$ for all $j \in N$.

If $w \in H^1(\Omega)$ is a weak solution to the problem
\eqref{eq:poissons_equation_modified}, then $u = w + u_D \in H^1(\Omega)$
is a weak solution to the original non-homogeneous problem
\eqref{eq:classical_poissons_equation}. Namely, we easily see that
$u|_{\Gamma_j} = g_j$ for all $j \in D$, and by the definition of
a weak solution and by Green's formula, we have
\begin{align*}
    \int_{\Omega} \nabla u \cdot \nabla v \diff x
    &= \int_{\Omega} \nabla w \cdot \nabla v \diff x
        + \int_{\Omega} \nabla u_D \cdot \nabla v \diff x \\
    &= \int_{\Omega} (f + \Delta u_D) v \diff x
        + \sum_{j \in N} \int_{\Gamma_j}
            \left( g_j - \frac{\partial u_D}{\partial n} \right) v \diff S \\
    &\hspace{7mm} - \int_{\Omega} \Delta u_D v \diff x
                    + \sum_{j \in N} \int_{\Gamma_j}
                        \frac{\partial u_D}{\partial n} v \diff S \\
    &= \int_{\Omega} fv \diff x + \sum_{j \in N} \int_{\Gamma_j} g_j v \diff S
\end{align*}
for all $v \in H^1(\Omega)$ with $v|_{\Gamma_j} = 0$ for all $j \in D$.
This means that to solve the non-homogeneous problem 
\eqref{eq:classical_poissons_equation}, it suffices to only consider the 
homogeneous problem
\begin{equation}
    \label{eq:poissons_equation_homogeneous}
    \left\{
        \begin{aligned}
            -\Delta u &= f && \text{in } \Omega \\
            u &= 0 && \text{on } \Gamma_j, \quad j \in D \\
            \frac{\partial u}{\partial n} &= g_j && \text{on } \Gamma_j,
            \quad j \in N.
        \end{aligned}
    \right.
\end{equation}

Homogeneity brings symmetricity to the weak formulation.
Namely, define a subspace $V_D$ of $H^1(\Omega)$ as
\begin{equation*}
    V_D = \{ v \in H^1(\Omega) :
        v|_{\Gamma_j} = 0 \text{ for all } j \in D \}.
\end{equation*}
Then Definition~\ref{def:weak_solution}
can be written succinctly as: Find $u \in V_D$ such that it satisfies
\eqref{eq:weak_formulation_variational} for all $v \in V_D$.

Consider then the pure Neumann problem, i.e.\ $D = \varnothing$.
By Definition~\ref{def:weak_solution}, the weak formulation is simple:
Find $u \in H^1(\Omega)$ such that it satisfies 
\eqref{eq:weak_formulation_variational} for all $v \in H^1(\Omega)$.
However, there are a few subtleties.
First, the data $f$ and $g_j$, $j \in N$,
must satisfy a compatibility condition as follows.
Define $v \equiv 1$ in $\Omega$. Since $\Omega$ is bounded, clearly
$v \in H^1(\Omega)$. Plugging $v$ into \eqref{eq:weak_formulation_variational}
gives
\begin{equation}
    \label{eq:neumann_compatibility_condition}
    \int_{\Omega} f \diff x + \sum_{j \in N} \int_{\Gamma_j} g_j \diff S = 0.
\end{equation}
Thus, $f$ and $g_j$ for all $j \in N$
must satisfy \eqref{eq:neumann_compatibility_condition}.

Second, if $u \in H^1(\Omega)$ is a weak solution to the pure Neumann problem,
then $u + C \in H^1(\Omega)$ is also a weak solution for any constant
$C \in \mathbb{R}$.
In other words, a weak solution is never unique as per Definition
\ref{def:weak_solution}. To fix a solution,
it is usually searched from the space of functions with zero mean value:
\begin{equation*}
    V_N = \left\{ v \in H^1(\Omega) : \int_{\Omega} v \diff x = 0 \right\}.
\end{equation*}
The weak formulation would then become: Find $u \in V_N$ such that it satisfies
\eqref{eq:weak_formulation_variational} for all $v \in H^1(\Omega)$.
But the symmetry is now lost, which is not great.
Fortunately, if the compatibility condition 
\eqref{eq:neumann_compatibility_condition} is
satisfied and \eqref{eq:weak_formulation_variational} holds for all
$v \in V_N$, then it also holds for all $v \in H^1(\Omega)$.
Let us prove this. Let $v \in H^1(\Omega)$. Then $v - \overline{v} \in V_N$, where
\begin{align*}
    \overline{v} = \frac{1}{\abs{\Omega}} \int_{\Omega} v \diff x.
\end{align*}
Now
\begin{align*}
    \int_{\Omega} \nabla u \cdot \nabla v \diff x
    &= \int_{\Omega} \nabla u \cdot \nabla (v - \overline{v}) \diff x \\
    &= \int_{\Omega} f (v - \overline{v}) \diff x
        + \sum_{j \in N} \int_{\Gamma_j} g_j (v - \overline{v}) \diff S \\
    &= \int_{\Omega} f v \diff x + \sum_{j \in N} \int_{\Gamma_j} g_j v \diff S
        - \overline{v} \left( \int_{\Omega} f \diff x
            + \sum_{j \in N} \int_{\Gamma_j} g_j \diff S \right) \\
    &= \int_{\Omega} f v \diff x + \sum_{j \in N} \int_{\Gamma_j} g_j v \diff S,
\end{align*}
where the last equality follows from the compatibility condition
\eqref{eq:neumann_compatibility_condition}.
Thus, in the case of a pure Neumann problem,
we rather consider the weak formulation:
Find $u \in V_N$ such that it satisfies \eqref{eq:weak_formulation_variational}
for all $v \in V_N$.

The above weak forms of the boundary value problem
\eqref{eq:classical_poissons_equation} formulated in the
Sobolev space $H^1(\Omega)$ are the most commonly studied formulations,
see e.g.\ \cite{evans2010}, \cite{grisvard2011}, \cite{ciarlet2002},
\cite{braess2007}. Due to the symmetricity and the fact
that $H^1(\Omega)$ is a Hilbert space, the existence and uniqueness of
solutions can be shown relatively easily, as we will see.
Moreover, in many cases the weak solution can be shown to belong to
$H^2(\Omega)$. We refer to the weak formulations presented above as the
classical weak formulations.

Let us now discuss how to formulate the problem 
\eqref{eq:classical_poissons_equation}
when the load is the Dirac delta, i.e.\ $f = \delta_{x_0}$.
We cannot consider $\delta_{x_0}$ as a function over $\Omega$ in any
reasonable way. Instead, it is understood as in
Section~\ref{subsubsec:sobolevimbeddingtheorem} as a member of the dual
space $W^{1,q}(\Omega)'$ for some $q > 2$. It is a functional such that
$\delta_{x_0}(v) = v(x_0)$ for all $v \in W^{1,q}(\Omega)$. Recall that
$W^{1,q}(\Omega) \subset C(\overline{\Omega})$ so the pointwise evaluation
makes sense. This already suggests that
the problem \eqref{eq:classical_poissons_equation} can be understood
in some weak sense only. We can motivate it as a limit of the classical
weak problems where $f \in L^2(\Omega)$.
Let us do this in the context of electrostatics.

Assume that we would like to model the electric potential in $\Omega$
caused by a single point charge located at the point $x_0 \in \Omega$.
The load $f$ corresponds to the charge density of the point charge
which is infinite at $x_0$ and zero everywhere else in $\Omega$.
Such a function is zero almost everywhere, which means that it would vanish
in \eqref{eq:weak_formulation_variational}. This would then incorrectly correspond
to the scenario, where there are no charges in $\Omega$.
Let us instead consider the point charge as the limit of small charged disks.
Let $B(x_0,\varepsilon) \subset \Omega$ be a disk centered at the point $x_0$
with a small radius $\varepsilon > 0$. For simplicity, assume that the total
charge over the disk is one, so that the charge density over $\Omega$ is now
given by
\begin{equation*}
    f_{\varepsilon}
    = \frac{1}{\abs{B(x_0,\varepsilon)}} \boldone_{B(x_0,\varepsilon)}.
\end{equation*}
Clearly, $f_{\varepsilon} \in L^2(\Omega)$.
Assume that $u_{\varepsilon} \in H^1(\Omega)$ is a weak solution to the 
corresponding weak problem with the load $f_{\varepsilon}$.
Choose now $v \in W^{1,q}(\Omega) \subset H^1(\Omega)$, $q > 2$,
according to the type of the boundary value problem,
i.e.\ either $v \in V_D$ or $v \in V_N$, and plug it into
\eqref{eq:weak_formulation_variational}:
\begin{align*}
    \int_{\Omega} \nabla u_{\varepsilon} \cdot \nabla v \diff x
    &= \int_{\Omega} f_{\varepsilon} v \diff x
        + \sum_{j \in N} \int_{\Gamma_j} g_j v \diff S \\
    &= \frac{1}{\abs{B(x_0,\varepsilon)}}
        \int_{B(x_0,\varepsilon)} v \diff x
        + \sum_{j \in N} \int_{\Gamma_j} g_j v \diff S \\
    &\xrightarrow[]{\varepsilon \to 0} \delta_{x_0}(v)
        + \sum_{j \in N} \int_{\Gamma_j} g_j v \diff S.
\end{align*}
The limit follows from Theorem~\ref{thm:lebesgue_differentiation_theorem}
and the definition of $\delta_{x_0}$.
Thus, the Dirac delta can be thought to model the effect of the point charge
as a limit.

Let us now define what we mean by a weak solution to the problem
\begin{equation}
    \label{eq:poissons_equation_with_dirac_delta}
    \left\{
        \begin{aligned}
            -\Delta u &= \delta_{x_0} && \text{in } \Omega \\
            u &= g_j && \text{on } \Gamma_j, \quad j \in D \\
            \frac{\partial u}{\partial n} &= g_j && \text{on } \Gamma_j,
            \quad j \in N,
        \end{aligned}
    \right.
\end{equation}
where $x_0 \in \Omega$ and the functions $g_j \in T(H^2(\Omega))$ for $j \in D$
and $g_j \in T(H^1(\Omega))$ for $j \in N$ are the same as before.
\begin{definition}
    \label{def:weak_solution_dirac}
    Let $1 < p < 2$ and $2 < q < \infty$ be conjugate exponents,
    i.e.\ $1/p + 1/q = 1$.
    A function $u \in W^{1,p}(\Omega)$ is said to be a weak solution to the
    boundary value problem \eqref{eq:poissons_equation_with_dirac_delta} if
    \begin{enumerate}[(i)]
        \item it satisfies
        \begin{equation}
            \label{eq:variational_identity_dirac}
            \int_{\Omega} \nabla u \cdot \nabla v \diff x
            = v(x_0) + \sum_{j \in N} \int_{\Gamma_j} g_j v \diff S
        \end{equation}
        for all $v \in W^{1,q}(\Omega)$ with $v|_{\Gamma_j} = 0$
        for all $j \in D$,
        \item $u|_{\Gamma_j} = g_j$ for all $j \in D$.
    \end{enumerate}
\end{definition}
An identical definition for the homogeneous pure Dirichlet problem
can be found in e.g.\ \cite{casas1985} and \cite{arayabehrens2006}.
The conjugate exponents are obviously needed for the expression
\eqref{eq:variational_identity_dirac} to make sense.
It will not be necessary to consider the cases $D \neq \varnothing$
and $D = \varnothing$ separately. We will, however, need to consider
the solvability of the classical weak formulation first before we are able
to find a weak solution to the problem 
\eqref{eq:poissons_equation_with_dirac_delta}, which is one of the
primary goals of this thesis.

\subsection{Solvability of the Classical Weak Formulation}
\label{subsec:solvability_of_the_classical_weak_formulation}

As a reminder, the classical weak formulation of the boundary value problem 
\eqref{eq:classical_poissons_equation} is the following.
Let $f \in L^2(\Omega)$ and $g_j \in T(H^1(\Omega))$ for $j \in N$.
Recall that it suffices to only consider
the problem with the homogeneous Dirichlet boundary conditions
$g_j = 0$ for all $j \in D$.
When $D \neq \varnothing$, i.e.\ pure Dirichlet problem or mixed
Dirichlet-Neumann problem, let
\begin{equation}
    \label{eq:VD_test_space}
    V_D = \{ v \in H^1(\Omega)
        : v|_{\Gamma_j} = 0 \text{ for all } j \in D \}.
\end{equation}
When $D = \varnothing$, i.e.\ pure Neumann problem, let
\begin{equation}
    \label{eq:VN_test_space}
    V_N = \left\{ v \in H^1(\Omega) : \int_{\Omega} v \diff x = 0 \right\}.
\end{equation}
The spaces $V_D$ and $V_N$ are clearly subspaces
of the Hilbert space $H^1(\Omega)$.
We wish to find a unique function $u \in V_D$ (resp.\ $u \in V_N$) such that
\begin{equation}
    \label{eq:weak_formulation_recap}
    \int_{\Omega} \nabla u \cdot \nabla v \diff x
    = \int_{\Omega} fv \diff x + \sum_{j \in N} \int_{\Gamma_j} g_j v \diff S
\end{equation}
for all $v \in V_D$ (resp.\ $v \in V_N$).

\subsubsection{Existence and Uniqueness of Solutions}

The identity \eqref{eq:weak_formulation_recap} can be written in the form
\begin{equation}
    \label{eq:abstract_variational_identity}
    a(u,v) = \varphi(v),
\end{equation}
where $a: V \times V \to \mathbb{R}$ and $\varphi: V \to \mathbb{R}$
are defined by
\begin{equation}
    \label{eq:weak_poisson_bilinear_form}
    a(u,v) = \int_{\Omega} \nabla u \cdot \nabla v \diff x
\end{equation}
and
\begin{equation}
    \label{eq:weak_poisson_functional}
    \varphi(v) = \int_{\Omega} fv \diff x
        + \sum_{j \in N} \int_{\Gamma_j} g_j v \diff S
\end{equation}
for all $u,v \in V$ where either $V = V_D$ or $V = V_N$.

For a general vector space $V$ a mapping of the form $a: V \times V \to \mathbb{R}$
is said to be bilinear if both univariate mappings
$u \mapsto a(u,v)$ and $v \mapsto a(u,v)$ are linear when the other argument
is kept fixed. The mapping $a$ is said to be symmetric if
$a(u,v) = a(v,u)$ for all $u,v \in V$.
Clearly, \eqref{eq:weak_poisson_bilinear_form} defines a symmetric bilinear 
mapping. The functional in \eqref{eq:weak_poisson_functional}
is also obviously linear.

When $V$ is a Hilbert space and the mappings $a$ and $\varphi$ are bilinear
and linear with some additional assumptions, there exists an abstract result
that asserts the existence and uniqueness of a vector $u \in V$ such that
\eqref{eq:abstract_variational_identity} holds for all $v \in V$.
This is the message of the well-known Lax-Milgram theorem.
\begin{theorem}[Lax-Milgram Theorem]
    \label{thm:lax_milgram}
    Let $V$ be a Hilbert space with the inner product $\innerprod{\cdot}{\cdot}$
    and the induced norm $\norm{\cdot}$.
    Let $a: V \times V \to \mathbb{R}$ be a symmetric bilinear
    mapping that satisfies the following two properties.
    \begin{enumerate}[(i)]
        \item Boundedness: There exists a constant $C > 0$ such that
        \begin{equation*}
            \abs{a(u,v)} \leq C \norm{u} \norm{v}
        \end{equation*}
        for all $u,v \in V$.
        \item Ellipticity: There exists a constant $\alpha > 0$ such that
        \begin{equation*}
            a(u,u) \geq \alpha \norm{u}^2
        \end{equation*}
        for all $u \in V$.
    \end{enumerate}
    Then for any $\varphi \in V'$ there exists a unique $u \in V$ such that
    \begin{equation*}
        a(u,v) = \varphi(v)
    \end{equation*}
    for all $v \in V$.
\end{theorem}
\begin{proof}
    From the ellipticity property it follows that $a(u,u) \geq 0$ and
    $a(u,u) = 0$ if and only if $u=0$ for all $u \in V$.
    Since the mapping $a$ is also bilinear and symmetric, it is
    an inner product on the space $V$.
    
    Let us consider the inner product space $(V, a(\cdot,\cdot))$
    with the induced norm $\norm{\cdot}_a$.
    By the boundedness of $a$, we have that
    \begin{equation*}
        \norm{u}_a^2
        = a(u,u)
        \leq C \norm{u}^2,
    \end{equation*}
    and by the ellipticity of $a$, we have that
    \begin{equation*}
        \norm{u}_a^2
        = a(u,u)
        \geq \alpha \norm{u}^2.
    \end{equation*}
    Combining these, we have that
    \begin{equation*}
        \sqrt{\alpha} \norm{u} \leq \norm{u}_a \leq \sqrt{C} \norm{u}
    \end{equation*}
    for all $u \in V$,
    which means that the norms $\norm{\cdot}$ and $\norm{\cdot}_a$
    are equivalent. It easily follows from this that $(V, a(\cdot,\cdot))$
    is also a Hilbert space, and the dual spaces of
    $(V,\innerprod{\cdot}{\cdot})$ and
    $(V, a(\cdot,\cdot))$ are the same.

    Finally, let $\varphi$ be a functional that belongs to the dual space
    of $(V,\innerprod{\cdot}{\cdot})$. Then $\varphi$ also belongs
    to the dual space of $(V, a(\cdot,\cdot))$,
    and by the Riesz representation theorem, i.e.\
    Theorem~\ref{thm:rieszrepresentationtheorem}, there exists a unique
    $u \in V$ such that $\varphi(v) = a(u,v)$ for all $v \in V$,
    which is what we wanted to show.
\end{proof}
The assumption that the mapping $a$ is symmetric is not necessary, but it
simplifies the proof quite a lot, and we will not be dealing with non-symmetric
mappings anyway. For a proof without the symmetricity assumption,
see \cite[Theorem 1 on p. 297]{evans2010}.

The Lax-Milgram theorem now provides a means to prove the existence of
a unique solution to the classical weak formulation of Poisson's equation,
where either $V = V_D$ or $V = V_N$ and the mappings $a$ and $\varphi$ are given by
\eqref{eq:weak_poisson_bilinear_form} and \eqref{eq:weak_poisson_functional},
respectively. To fulfill the assumptions of the Lax-Milgram theorem,
we need to show the following.
\begin{enumerate}[(i)]
    \item The subspaces $V_D$ and $V_N$ of $H^1(\Omega)$ are Hilbert spaces.
    \item The symmetric bilinear mapping in \eqref{eq:weak_poisson_bilinear_form}
    is bounded and elliptic.
    \item The linear functional in \eqref{eq:weak_poisson_functional}
    is continuous, i.e.\ bounded, so it belongs to $V'$.
\end{enumerate}
Let us consider these assertions next.

In the case of a pure Dirichlet problem,
$V_D = H_0^1(\Omega) = \overline{C_0^{\infty}(\Omega)}$
so $V_D$ is obviously a Hilbert space. The other cases are rather easy as well.
\begin{theorem}
    \label{thm:test_spaces_are_hilbert_spaces}
    Let the subspaces $V_D \subset H^1(\Omega)$ and $V_N \subset H^1(\Omega)$
    be as in \eqref{eq:VD_test_space} and \eqref{eq:VN_test_space}.
    Then both $V_D$ and $V_N$ are Hilbert spaces.
\end{theorem}
\begin{proof}
    It obviously suffices to show that $V_D$ and $V_N$ are closed subspaces.

    Consider first the subspace $V_D$.
    Let $u \in H^1(\Omega)$ be a closure point of $V_D$, that is,
    there exists a sequence $(u_i)_{i=1}^{\infty}$ in $V_D$ that converges
    to $u$ in $H^1(\Omega)$. Now by the trace theorem,
    i.e.\ Theorem~\ref{thm:tracetheorem}, and the fact that $u_i|_{\Gamma_j} = 0$
    for all $j \in D$, we get for all $j \in D$ that
    \begin{align*}
        \norm{u}_{L^2(\Gamma_j)}
        &= \norm{u - u_i}_{L^2(\Gamma_j)} \\
        &\leq \norm{u - u_i}_{L^2(\partial \Omega)} \\
        &\leq C \norm{u - u_i}_{H^1(\Omega)} \\
        &\xrightarrow[]{i \to \infty} 0.
    \end{align*}
    Thus, $\norm{u}_{L^2(\Gamma_j)} = 0$, which implies that
    $u|_{\Gamma_j} = 0$ and $u \in V_D$.
    We conclude that $V_D$ is closed.

    Then let $u \in H^1(\Omega)$ be a closure point of $V_N$, that is,
    there exists a sequence $(u_i)_{i=1}^{\infty}$ in $V_N$ that converges
    to $u$ in $H^1(\Omega)$. Now
    \begin{align*}
        \abs*{\int_{\Omega} u \diff x}
        &= \abs*{\int_{\Omega} u - u_i \diff x} \\
        &\leq \norm{u - u_i}_{L^1(\Omega)} \\
        &\leq C \norm{u - u_i}_{L^2(\Omega)} \\
        &\leq C \norm{u - u_i}_{H^1(\Omega)} \\
        &\xrightarrow[]{i \to \infty} 0,
    \end{align*}
    where the second inequality follows from Theorem~\ref{thm:lpimbedding}.
    This means that the integral of $u$ is zero, i.e.\ $u \in V_N$,
    which implies that $V_N$ is closed.
\end{proof}

Proving the ellipticity of the bilinear mapping $a$ is by far the
trickiest step. It will, however, become easy after introducing the following
theorem which is a variant of Poincaré's inequality in
Theorem~\ref{thm:poincare_inequality}.
\begin{theorem}
    \label{thm:friedrichs_inequality}
    Let $\Omega \subset \mathbb{R}^n$ be a bounded domain with Lipschitz
    boundary. Then there exists a constant $C > 0$ such that
    \begin{equation*}
        \norm{u}_{L^2(\Omega)} \leq C \abs{u}_{H^1(\Omega)}
    \end{equation*}
    for all $u \in V$, where either $V = V_D$ or $V = V_N$.
\end{theorem}
\begin{proof}
    We proceed via proof by contradiction.
    Assume that the claim is not true for any constant $C > 0$.
    Then there exists a sequence $(u_i)_{i=1}^{\infty}$ in $V$ such that
    \begin{equation*}
        \norm{u_i}_{L^2(\Omega)} > i \abs{u_i}_{H^1(\Omega)},
        \quad i=1,2,\dotsc.
    \end{equation*}
    Dividing both sides by $\norm{u_i}_{L^2(\Omega)}$
    and then by $i$ yields
    \begin{equation*}
        \abs{v_i}_{H^1(\Omega)} < \frac{1}{i},
        \quad i=1,2,\dotsc,
    \end{equation*}
    where $v_i = u_i / \norm{u_i}_{L^2(\Omega)}$.
    Clearly, $\norm{v_i}_{L^2(\Omega)} = 1$ for all $i$.
    Note that the sequence $(v_i)_{i=1}^{\infty}$ is bounded in
    $V \subset H^1(\Omega)$:
    \begin{align*}
        \norm{v_i}_{H^1(\Omega)}^2
        &= \norm{v_i}_{L^2(\Omega)}^2 + \abs{v_i}_{H^1(\Omega)}^2 \\
        &\leq 1 + \frac{1}{i^2} \\
        &\leq 2,
        \qquad i=1,2,\dotsc.
    \end{align*}
    By Theorem~\ref{thm:sobolevimbedding}, the imbedding
    $H^1(\Omega) \subset L^2(\Omega)$ is compact. Thus, there exists
    a subsequence of the sequence $(v_i)_{i=1}^{\infty}$ that converges
    to some $v \in L^2(\Omega)$ with respect to the norm
    $\norm{\cdot}_{L^2(\Omega)}$. Without loss of generality,
    denote this subsequence by $(v_i)_{i=1}^{\infty}$ as well.

    Let us then show that $v \in H^1(\Omega)$ with $\nabla v = 0$.
    Let $\phi \in C_0^{\infty}(\Omega)$. First note the limit
    \begin{align*}
        \abs*{\int_{\Omega} v D_k \phi \diff x
            - \int_{\Omega} v_i D_k \phi \diff x}
        &\leq \int_{\Omega} \abs*{(v - v_i) D_k \phi} \diff x \\
        &\leq \norm{v - v_i}_{L^2(\Omega)} \norm{D_k \phi}_{L^2(\Omega)} \\
        &\xrightarrow[]{i \to \infty} 0,
    \end{align*}
    for all $k=1,2,\dotsc,n$, where the second step follows from
    Hölder's inequality. Using this limit, we get
    \begin{align*}
        \abs*{\int_{\Omega} v D_k \phi \diff x}
        &= \abs*{\lim_{i \to \infty} \int_{\Omega} v_i D_k \phi \diff x} \\
        &= \lim_{i \to \infty} \hspace{0.7mm}
            \abs*{\int_{\Omega} D_k v_i \phi \diff x} \\
        &\leq \limsup_{i \to \infty} \int_{\Omega} \abs{D_k v_i \phi} \diff x \\
        &\leq \limsup_{i \to \infty} \hspace{0.7mm} \norm{D_k v_i}_{L^2(\Omega)}
            \norm{\phi}_{L^2(\Omega)} \\
        &\leq \limsup_{i \to \infty} \hspace{0.7mm} \abs{v_i}_{H^1(\Omega)}
            \norm{\phi}_{L^2(\Omega)} \\
        &\leq \limsup_{i \to \infty} \hspace{0.7mm}
            \frac{1}{i} \norm{\phi}_{L^2(\Omega)} \\
        &= 0.
    \end{align*}
    Note above also the use of Hölder's inequality
    and the bound $\abs{v_i}_{H^1(\Omega)} < 1/i$ for all $i$.
    The above implies that
    \begin{equation*}
        \int_{\Omega} v D_k \phi \diff x = 0
    \end{equation*}
    for all $k=1,2,\dotsc,n$, which then implies that
    $D_k v = 0$ for all $k=1,2,\dotsc,n$. In other words, $\nabla u = 0$.
    
    Since $\Omega$ is connected, the fact that $\nabla v = 0$ implies
    that $v$ is constant almost everywhere in $\Omega$. Say $v = c$.
    We show next that $c = 0$. Assume first that $V = V_D$. 
    Clearly, $v|_{\partial \Omega} = c$.
    Recall that $v_i \in V$ and, thus, $v_i|_{\Gamma_j} = 0$ for all $j \in D$.
    Now by the trace theorem, we get for any $j \in D$ that
    \begin{align*}
        \norm{v}_{L^2(\Gamma_j)}^2
        &= \norm{v - v_i}_{L^2(\Gamma_j)}^2 \\
        &\leq \norm{v - v_i}_{L^2(\partial \Omega)}^2 \\
        &\leq C \norm{v - v_i}_{H^1(\Omega)}^2 \\
        &= C \left(\norm{v - v_i}_{L^2(\Omega)}^2
            + \abs{v_i}_{H^1(\Omega)}^2 \right) \\
        &\leq C \left(\norm{v - v_i}_{L^2(\Omega)}^2
            + \frac{1}{i^2} \right) \\
        &\xrightarrow[]{i \to \infty} 0.
    \end{align*}
    Thus,
    \begin{equation*}
        0
        = \norm{v}_{L^2(\Gamma_j)}^2
        = \norm{c}_{L^2(\Gamma_j)}^2
        = c^2 \abs{\Gamma_j},
    \end{equation*}
    where $\abs{\Gamma_j}$ is the $(n-1)$-dimensional measure of $\Gamma_j$.
    Since this measure is non-zero
    (recall that $\Gamma_j$ is analogous to a non-empty open interval),
    $v=c=0$ holds almost everywhere in $\Omega$.

    Assume then that $V = V_N$. By Theorem~\ref{thm:lpimbedding}, we get
    \begin{align*}
        \abs*{\int_{\Omega} v \diff x}
        &= \abs*{\int_{\Omega} v - v_i \diff x} \\
        &\leq \norm{v - v_i}_{L^1(\Omega)} \\
        &\leq C \norm{v - v_i}_{L^2(\Omega)} \\
        &\xrightarrow[]{i \to \infty} 0.
    \end{align*}
    Thus,
    \begin{equation*}
        0
        = \int_{\Omega} v \diff x
        = c \abs{\Omega},
    \end{equation*}
    and $v=c=0$ almost everywhere in $\Omega$.

    However, the fact that $\norm{v_i}_{L^2(\Omega)} = 1$ for all $i$
    implies that $\norm{v}_{L^2(\Omega)} = 1$ as follows. By the inverse
    triangle inequality, we get
    \begin{equation*}
        \abs*{\norm{v}_{L^2(\Omega)} - \norm{v_i}_{L^2(\Omega)}}
        \leq \norm{v - v_i}_{L^2(\Omega)}
        \xrightarrow[]{i \to \infty} 0,
    \end{equation*}
    from which we get that
    \begin{equation*}
        \norm{v}_{L^2(\Omega)}
        = \lim_{i \to \infty} \norm{v_i}_{L^2(\Omega)}
        = 1.
    \end{equation*}
    We have now arrived at a contradiciton between the results $v = 0$
    almost everywhere in $\Omega$ and $\norm{v}_{L^2(\Omega)} = 1$.
    The initial claim must thus hold.
\end{proof}

Let us now prove the rest of the assertions.
\begin{theorem}
    \label{thm:weak_poisson_reqs_2_and_3}
    Let either $V = V_D$ or $V = V_N$.
    The bilinear mapping $a: V \times V \to \mathbb{R}$ in
    \eqref{eq:weak_poisson_bilinear_form} is bounded and elliptic,
    and the linear functional $\varphi: V \to \mathbb{R}$ in
    \eqref{eq:weak_poisson_functional} is bounded.
\end{theorem}
\begin{proof}
    By the Cauchy-Schwarz and Hölder's inequalities, we have
    \begin{align*}
        \abs{a(u,v)}
        &\leq \int_{\Omega} \abs{\nabla u \cdot \nabla v} \diff x \\
        &\leq \int_{\Omega} \abs{\nabla u} \abs{\nabla v} \diff x \\
        &\leq \norm{\nabla u}_{L^2(\Omega)} \norm{\nabla v}_{L^2(\Omega)} \\
        &\leq \norm{u}_{H^1(\Omega)} \norm{v}_{H^1(\Omega)}
    \end{align*}
    for all $u,v \in V$. Thus, $a$ is bounded.

    By Theorem~\ref{thm:friedrichs_inequality}, we have
    \begin{align*}
        a(u,u)
        &= \int_{\Omega} \nabla u \cdot \nabla u \diff x \\
        &= \abs{u}_{H^1(\Omega)}^2 \\
        &= \frac{1}{2} \abs{u}_{H^1(\Omega)}^2
            + \frac{1}{2} \abs{u}_{H^1(\Omega)}^2 \\
        &\geq \frac{1}{2C} \norm{u}_{L^2(\Omega)}^2
            + \frac{1}{2} \abs{u}_{H^1(\Omega)}^2 \\
        &\geq \min\left\{ \frac{1}{2C}, \frac{1}{2} \right\}
            \left( \norm{u}_{L^2(\Omega)}^2 + \abs{u}_{H^1(\Omega)}^2 \right) \\
        &= \min\left\{ \frac{1}{2C}, \frac{1}{2} \right\}
            \norm{u}_{H^1(\Omega)}^2 \\
        &= \alpha \norm{u}_{H^1(\Omega)}^2
    \end{align*}
    for some constant $C > 0$ and for all $u \in V$. Thus, $a$ is elliptic.

     Finally, by Hölder's inequality and the trace theorem, we have
     \begin{align*}
        \abs{\varphi(v)}
        &\leq \int_{\Omega} \abs{fv} \diff x
            + \int_{\Gamma_N} \abs{g_N v} \diff S \\
        &\leq \norm{f}_{L^2(\Omega)} \norm{v}_{L^2(\Omega)}
            + \norm{g_N}_{L^2(\partial \Omega)} \norm{v}_{L^2(\partial \Omega)} \\
        &\leq \norm{f}_{L^2(\Omega)} \norm{v}_{H^1(\Omega)}
            + \norm{g_N}_{L^2(\partial \Omega)} C \norm{v}_{H^1(\Omega)} \\
        &= \left( \norm{f}_{L^2(\Omega)} + C \norm{g_N}_{L^2(\partial \Omega)} 
            \right) \norm{v}_{H^1(\Omega)}
     \end{align*}
     for all $v \in V$. Thus, $\varphi$ is bounded and $\varphi \in V'$.
\end{proof}

The existence of a unique weak solution to the classical weak formulation
follows now directly from the Lax-Milgram theorem.
This also implies the existence of weak solutions
as per Definition~\ref{def:weak_solution}, which was the goal all along.
We still need to consider the uniqueness of the solutions as, for example,
there may be multiple candidates for the function $g_D \in H^2(\Omega)$
in the case of Dirichlet boundary conditions.
In the case of only Neumann boundary conditions, we already know that
a weak solution is not unique, but it turns out to be unique up to
an additive constant.
For future reference, let us state the full existence and uniqueness theorem.
\begin{theorem}
    \label{thm:weak_poisson_is_solvable}
    Let $\Omega \subset \mathbb{R}^2$ be a bounded polygonal domain without slits.
    Let $f \in L^2(\Omega)$, $g_j \in T(H^2(\Omega))$ for $j \in D$
    and $g_j \in T(H^1(\Omega))$ for $j \in N$.
    Assume that there exists a function $g_D \in H^2(\Omega)$ such that
    $g_D|_{\Gamma_j} = g_j$ for all $j \in D$.
    Then the boundary value problem
    \begin{equation*}
        \left\{
            \begin{aligned}
                -\Delta u &= f && \text{in } \Omega \\
                u &= g_j && \text{on } \Gamma_j, \quad j \in D \\
                \frac{\partial u}{\partial n} &= g_j && \text{on } \Gamma_j,
                \quad j \in N
            \end{aligned}
        \right.
    \end{equation*}
    has a weak solution $u \in H^1(\Omega)$.
    When $D \neq \varnothing$, $u$ is unique.
    When $D = \varnothing$, $u$ is unique up to an additive constant.
\end{theorem}
\begin{proof}
    When $D \neq \varnothing$, the existence of a weak solution follows
    directly from the Lax-Milgram theorem, i.e.\ Theorem~\ref{thm:lax_milgram},
    and the discussion at the beginning of this section.
    If $u$ and $v$ are weak solutions, then $u-v$ is clearly
    a weak solution to the problem
    \begin{equation}
        \label{eq:weak_poisson_is_solvable_homogeneous}
        \left\{
            \begin{aligned}
                -\Delta w &= 0 && \text{in } \Omega \\
                u &= 0 && \text{on } \Gamma_j, \quad j \in D \\
                \frac{\partial u}{\partial n} &= 0 && \text{on } \Gamma_j,
                \quad j \in N.
            \end{aligned}
        \right.
    \end{equation}
    Clearly, $w = 0$ is a weak solution, and it is unique
    by the Lax-Milgram theorem. Thus, $u - v = 0$, that is, $u = v$.

    When $D = \varnothing$, the Lax-Milgram theorem implies the existence
    of a unique weak solution in the space $V_N$. If now $u$ and $v$ are two
    weak solutions, not necessarily in the space $V_N$, then $u-v$ is again
    a weak solution to the homogeneous problem 
    \eqref{eq:weak_poisson_is_solvable_homogeneous}.
    So is the function $u-v - (\overline{u} - \overline{v}) \in V_N$, where
    \begin{equation*}
        \overline{u} = \frac{1}{\abs{\Omega}} \int_{\Omega} u \diff x.
    \end{equation*}
    By the Lax-Milgram theorem, $u-v-(\overline{u} - \overline{v}) = 0$,
    i.e.\ $u = v + C$ with the constant $C = \overline{u} - \overline{v}$,
    which implies that a weak solution is unique up to an additive constant.
\end{proof}

The Lax-Milgram theorem is a very general existence result.
It could be used to show the existence and uniqueness of solutions
to other second-order elliptic boundary value problems as well
and in higher dimensions than $n=2$. One could also consider more
general domains with Lipschitz boundaries with little modifications.
See for example \cite[Chapter 6]{evans2010}.

\subsubsection{Regularity of the Weak Solutions}
\label{subsubsec:regularity_of_the_weak_solutions}

Poisson's equation contains the second-order differential operator $\Delta$,
which motivates the question whether a weak solution $u \in H^1(\Omega)$
actually belongs to the space $H^2(\Omega)$.
This is of particular importance in finite element analysis as typical convergence
results rely on the answer being yes. Whether the answer is indeed yes
depends on the domain $\Omega$. For a polygonal domain we need the following
additional assumptions.
\begin{assumption}
    \label{ass:regular_polygonal_domain}
    Let $\Omega \subset \mathbb{R}^2$ be a bounded polygonal domain.
    The linear boundary segments $\Gamma_j$, $j = 1,2,\dotsc,J$,
    that constitute $\partial \Omega$ are arranged so that
    $\Gamma_j$ is followed by $\Gamma_{j+1}$.
    For $j=J$, set $\Gamma_{J+1} = \Gamma_1$.
    Denote the angle between the segments $\Gamma_j$ and $\Gamma_{j+1}$
    by $\theta_j$. The angle is the one on the side of $\Omega$.
    Assume that the angles $\theta_j$ satisfy the following assumptions.
    \begin{itemize}[(i)]
        \item $0 < \theta_j < \pi$ for all $j=1,2,\dotsc,J$,
        i.e.\ $\Omega$ is convex.
        \item For all $j=1,2,\dotsc,J$ if $\Gamma_j$ has a prescribed
        Dirichlet boundary condition and $\Gamma_{j+1}$ has a prescribed
        Neumann boundary condition, or the other way around, then
        $0 < \theta_j < \pi / 2$.
    \end{itemize}
\end{assumption}

Now we have the following regularity result.
\begin{theorem}
    \label{thm:H2_regularity}
    Let $\Omega \subset \mathbb{R}^2$ be a polygonal domain that
    satisfies Assumption~\ref{ass:regular_polygonal_domain}.
    Then the weak solutions in Theorem~\ref{thm:weak_poisson_is_solvable}
    belong to the space $H^2(\Omega)$.
\end{theorem}
For a reference, see \cite[Theorem 4.4.4.13 on p. 245]{grisvard2011}
and \cite[Theorem 1]{grisvard1976}.
When $u \in H^2(\Omega)$, then $\Delta u \in L^2(\Omega)$
and $\partial u / \partial n$ on $\Gamma_j$ exists in the sense of traces
for all $j \in N$.
It turns out that when the weak solution belongs
to the space $H^2(\Omega)$, Poisson's equation holds in the sense of $L^2$
and the Neumann boundary conditions hold in the sense of traces.
Note that the Dirichlet boundary conditions already hold in the sense
of traces because it is embedded into the solution space.
\begin{theorem}
    \label{thm:weak_solution_is_strong_solution}
    Let $u \in H^1(\Omega)$ be a weak solution provided by
    Theorem~\ref{thm:weak_poisson_is_solvable}. Assume that $u \in H^2(\Omega)$.
    Then
    \begin{enumerate}[(i)]
        \item $-\Delta u = f$ in the sense of $L^2$,
        \item $\frac{\partial u}{\partial n}|_{\Gamma_j} = g_j$ for all $j \in N$.
    \end{enumerate}
\end{theorem}
For a proof, see for example
\cite[Proposition 5.1.9 on p.\ 131]{scottbrenner2007}.
Let us finish off the discussion on the classical weak
formulation of Poisson's equation
by proving an a priori $H^2$-norm estimate for the weak solution
with homogeneous boundary values $g_j = 0$ for all $j=1,2,\dotsc,J$.
This estimate will be extremely useful later.
\begin{theorem}
    \label{thm:a_priori_H2_estimate}
    By Theorem~\ref{thm:weak_poisson_is_solvable},
    let $u \in H^1(\Omega)$ be the unique weak solution
    of the boundary value problem
    \begin{equation*}
        \left\{
            \begin{aligned}
                -\Delta u &= f && \text{in } \Omega \\
                u &= 0 && \text{on } \Gamma_j, \quad j \in D \\
                \frac{\partial u}{\partial n} &= 0 && \text{on } \Gamma_j,
                \quad j \in N.
            \end{aligned}
        \right.
    \end{equation*}
    When $D = \varnothing$, the uniqueness is enforced by requiring
    that $\int_{\Omega} u \diff x = 0$. Assume that $u \in H^2(\Omega)$.
    Then there exists a constant $C > 0$ independent of $u$ and $f$ such that
    \begin{equation*}
        \norm{u}_{H^2(\Omega)} \leq C \norm{f}_{L^2(\Omega)}.
    \end{equation*}
\end{theorem}
\begin{proof}
    Note that $u \in V_D$ or $u \in V_N$ depending
    on the type of the boundary value problem.
    Theorem~\ref{thm:friedrichs_inequality} now implies
    \begin{align}
        \norm{u}_{H^2(\Omega)}^2
        &= \norm{u}_{L^2(\Omega)}^2
            + \abs{u}_{H^1(\Omega)}^2
                + \abs{u}_{H^2(\Omega)}^2 \nonumber \\
        &\leq C^2 \abs{u}_{H^1(\Omega)}^2
            + \abs{u}_{H^1(\Omega)}^2
                + \abs{u}_{H^2(\Omega)}^2 \nonumber \\
        \label{eq:a_priori_H2_estimate_intmed1}
        &= (C^2 + 1) \abs{u}_{H^1(\Omega)}^2 + \abs{u}_{H^2(\Omega)}^2,
    \end{align}
    where $C > 0$ is some constant independent of $u$ and $f$.

    Consider next the seminorm $\abs{u}_{H^1(\Omega)}$.
    By the definition of a weak solution, Hölder's inequality
    and Theorem~\ref{thm:friedrichs_inequality}, we get
    \begin{align*}
        \abs{u}_{H^1(\Omega)}^2
        &= \int_{\Omega} \nabla u \cdot \nabla u \diff x \\
        &= \int_{\Omega} f u \diff x \\
        &\leq \norm{f}_{L^2(\Omega)} \norm{u}_{L^2(\Omega)} \\
        &\leq \norm{f}_{L^2(\Omega)} C \abs{u}_{H^1(\Omega)},
    \end{align*}
    where $C$ is the same constant as in \eqref{eq:a_priori_H2_estimate_intmed1}.
    Dividing both sides by $\abs{u}_{H^1(\Omega)}$ gives
    \begin{equation}
        \label{eq:a_priori_H2_estimate_intmed2}
        \abs{u}_{H^1(\Omega)} \leq C \norm{f}_{L^2(\Omega)}.
    \end{equation}
    If $\abs{u}_{H^1(\Omega)} = 0$, this inequality is also obviously true.

    By \cite[Proof of Theorem 4.3.1.4 on p. 199]{grisvard2011}, it holds that
    \begin{equation*}
        \abs{u}_{H^2(\Omega)} \leq \norm{\Delta u}_{L^2(\Omega)},
    \end{equation*}
    which combined with the result $-\Delta u = f$ from
    Theorem~\ref{thm:weak_solution_is_strong_solution} yields
    \begin{equation}
        \label{eq:a_priori_H2_estimate_intmed3}
        \abs{u}_{H^2(\Omega)} \leq \norm{f}_{L^2(\Omega)}.
    \end{equation}

    Plugging \eqref{eq:a_priori_H2_estimate_intmed2}
    and \eqref{eq:a_priori_H2_estimate_intmed3}
    into \eqref{eq:a_priori_H2_estimate_intmed1} gives
    \begin{align*}
        \norm{u}_{H^2(\Omega)}^2
        &\leq (C^2+1) C^2 \norm{f}_{L^2(\Omega)}^2 + \norm{f}_{L^2(\Omega)}^2 \\
        &= (C^4 + C^2 + 1) \norm{f}_{L^2(\Omega)}^2
    \end{align*}
    Taking the square root from both sides finishes the proof.
\end{proof}

\subsection{Solvability of Poisson's Equation with a Concentrated Load}
\label{subsec:poissons_equation_with_a_concentrated_load}

Let us recall what we mean by a weak solution to the boundary value problem
\begin{equation}
    \label{eq:poissons_eq_with_dirac_delta_recap}
    \left\{
        \begin{aligned}
            -\Delta u &= \delta_{x_0} && \text{in } \Omega \\
            u &= g_j && \text{on } \Gamma_j, \quad j \in D \\
            \frac{\partial u}{\partial n} &= g_j && \text{on } \Gamma_j,
            \quad j \in N,
        \end{aligned}
    \right.
\end{equation}
where the boundary data $g_j$ for $j=1,2,\dotsc,J$ are the same as before,
i.e.\ $g_j \in T(H^2(\Omega))$ for $j \in D$ and
$g_j \in T(H^1(\Omega))$ for $j \in N$. Let $1 < p < 2$.
A function $u \in W^{1,p}(\Omega)$ is a weak solution
if $u|_{\Gamma_j} = g_j$ for all $j \in D$ and it satisfies
\begin{equation*}
    \int_{\Omega} \nabla u \cdot \nabla v \diff x
    = v(x_0) + \sum_{j \in N} \int_{\Gamma_j} g_j v \diff S
\end{equation*}
for all $v \in W^{1,q}(\Omega)$ with $v|_{\Gamma_j} = 0$ for all $j \in D$
where $2 < q < \infty$ is the conjugate exponent of $p$.

The Lax-Milgram theorem cannot now be used to deduce the existence of a unique
solution because the problem is not formulated in the Hilbert space $H^1(\Omega)$.
In particular, $\delta_{x_0} \notin H^1(\Omega)'$ as there is no obvious
well-defined meaning to the expression $\delta_{x_0}(v) = v(x_0)$ for
an arbitrary $v \in H^1(\Omega)$ due to the imbedding
$H^1(\Omega) \subset C(\overline{\Omega})$ not being true.
The problem does, however, turn out to have a solution,
and when $\Omega$ satisfies Assumption~\ref{ass:regular_polygonal_domain},
it is possible to show that the solution is also unique.
Casas \cite{casas1985} proves the existence and uniqueness of
a solution to the pure Dirichlet problem with homogeneous boundary
values in convex polygonal domains. The proof by Casas is an abstract
existence proof that uses results from functional analysis.
An outline for a somewhat more constructive proof is given by
Araya et al.\ \cite{arayabehrens2006} to the same problem that Casas considers.
Namely, there exists a fundamental solution to a specific instance of
the problem \eqref{eq:poissons_eq_with_dirac_delta_recap} that arises from the
classical theory of partial differential equations.
This fundamental solution is commonly called Green's function,
and we use it in a similar manner to Araya et al.\ to deduce
the existence of a weak solution to the general problem.

\subsubsection{Green's Function}
\label{subsubsec:greens_function}

Consider Poisson's equation in free space:
\begin{equation}
    \label{eq:poissons_eq_in_free_space}
    -\Delta u = f \quad \text{in } \mathbb{R}^2.
\end{equation}
When $f \in C_0^2(\mathbb{R}^2)$, i.e.\ $f$ is twice continuously differentiable
with compact support, then \eqref{eq:poissons_eq_in_free_space} has
a classical solution $u \in C^2(\mathbb{R}^2)$ with an explicit formula
\begin{equation*}
    u(x) = \int_{\mathbb{R}^2} \Phi(x-y) f(y) \diff y,
\end{equation*}
where $\Phi$ is the fundamental solution of Laplace's equation $\Delta u = 0$
\cite[Theorem 1 on p. 23]{evans2010}. The fundamental solution $\Phi$ is given by
\begin{equation*}
    \Phi(x) = -\frac{1}{2 \pi} \log \abs{x}
\end{equation*}
for $x \in \mathbb{R}^2 \setminus \{ 0 \}$.
By a direct calculation,
\begin{align*}
    \Delta \Phi(x)
    &= \frac{\partial^2 \Phi}{\partial x_1^2}(x)
        + \frac{\partial^2 \Phi}{\partial x_2^2}(x) \\
    &= -\frac{1}{2\pi} \frac{x_2^2 - x_1^2}{\abs{x}^4}
        -\frac{1}{2\pi} \frac{x_1^2 - x_2^2}{\abs{x}^4} \\
    &= 0
\end{align*}
for all $x \in \mathbb{R}^2 \setminus \{ 0 \}$.

We may shift the singularity at the origin to an arbitrary point
$x_0 \in \mathbb{R}^2$ and define
\begin{equation}
    \label{eq:greens_function}
    \Phi_{x_0}(x) = -\frac{1}{2 \pi} \log \abs{x - x_0}
\end{equation}
for $x \in \mathbb{R}^2 \setminus \{ x_0 \}$.
Clearly, $\Delta \Phi_{x_0}(x) = 0$ for all $x \in \mathbb{R}^2 \setminus \{x_0\}$.
We set $\Phi_{x_0}(x_0) = 0$.
The function $\Phi_{x_0}$ turns out to solve the problem 
\eqref{eq:poissons_eq_with_dirac_delta_recap} when the boundary values
are set accordingly.
This is illustrated by the following theorem.
\begin{theorem}
    \label{thm:greens_function_is_solution}
    Let $\Omega \subset \mathbb{R}^2$ be a bounded polygonal domain without slits.
    Let $x_0 \in \Omega$, and define $\Phi_{x_0}$ by \eqref{eq:greens_function}.
    Let $1 < p < 2$. Then $\Phi_{x_0} \in W^{1,p}(\Omega)$,
    and $\Phi_{x_0}$ is a weak solution to the problem
    \begin{equation}
        \label{eq:greens_function_is_solution_problem}
        \left\{
            \begin{aligned}
                -\Delta u &= \delta_{x_0} && \text{in } \Omega \\
                u &= \Phi_{x_0} && \text{on } \Gamma_j, \quad j \in D \\
                \frac{\partial u}{\partial n} &=
                \frac{\partial \Phi_{x_0}}{\partial n} && \text{on } \Gamma_j,
                \quad j \in N.
            \end{aligned}
        \right.
    \end{equation}
\end{theorem}
\begin{proof}
    The gradient of $\Phi_{x_0}$ is given by
    \begin{equation*}
        \nabla \Phi_{x_0}(x) = -\frac{1}{2\pi} \frac{x-x_0}{\abs{x-x_0}^2}
    \end{equation*}
    for $x \in \mathbb{R}^2 \setminus \{ x_0 \}$.
    Set $\nabla \Phi_{x_0}(x_0) = 0$.
    Let us show that $\Phi_{x_0} \in L^p(\Omega)$ and
    $\nabla \Phi_{x_0} \in L^p(\Omega) \times L^p(\Omega)$.
    Since $\Omega$ is bounded, let $B(x_0,R) \subset \mathbb{R}^2$
    be a ball that is centered at $x_0$ with radius $R > 1$
    so that $\Omega \subset B(x_0,R)$. Now
    \begin{align*}
        \norm{\Phi_{x_0}}_{L^p(\Omega)}^p
        &\leq \norm{\Phi_{x_0}}_{L^p(B(x_0,R))}^p \\
        &= \frac{1}{(2\pi)^p} \int_{B(x_0,R)} \abs*{\log\abs{x-x_0}}^p \diff x \\
        &= \frac{1}{(2\pi)^p} \int_{0}^{R} \int_{\partial B(x_0,r)}
            \abs*{\log r}^p \diff S \diff r \\
        &= \frac{1}{(2\pi)^{p-1}} \int_{0}^{R} r \abs*{\log r}^p \diff r \\
        &= \frac{1}{(2\pi)^{p-1}} \left(
            \int_{0}^{1} r (-\log r)^p \diff r
                + \int_{1}^{R} r \log^p r \diff r
                \right).
    \end{align*}
    The second integral is obviously finite.
    For the first integral the loose estimate $x \leq e^x$
    for all $x \in \mathbb{R}$ gives
    \begin{align*}
        \int_{0}^{1} r (-\log r)^p \diff r
        &\leq \int_{0}^{1} r \left(e^{-\log r} \right)^p \diff r \\
        &= \int_{0}^{1} r^{1-p} \diff r \\
        &= \lim_{\varepsilon \to 0} \int_{\varepsilon}^{1} r^{1-p} \diff r \\
        &= \lim_{\varepsilon \to 0} \left(
            \frac{1}{2-p} \left( 1 - \varepsilon^{2-p} \right)
                \right) \\
        &= \frac{1}{2-p}.
    \end{align*}
    The limit is finite since $2-p > 0$. Thus,
    $\norm{\Phi_{x_0}}_{L^p(\Omega)} < \infty$ and $\Phi_{x_0} \in L^p(\Omega)$.

    Consider then the integrability of the derivatives:
    \begin{align*}
        \norm{D_i \Phi_{x_0}}_{L^p(\Omega)}^p
        &\leq \norm{D_i \Phi_{x_0}}_{L^p(B(x_0,R))}^p \\
        &= \frac{1}{(2\pi)^p} \int_{B(x_0,R)}
            \frac{(x_i - x_{0i})^p}{\abs{x-x_0}^{2p}} \diff x \\
        &\leq \frac{1}{(2\pi)^p} \int_{B(x_0,R)}
            \frac{\abs{x-x_0}^p}{\abs{x-x_0}^{2p}} \diff x \\
        &= \frac{1}{(2\pi)^p} \int_{B(x_0,R)}
            \frac{1}{\abs{x-x_0}^p} \diff x \\
        &= \frac{1}{(2\pi)^p} \int_{0}^{R} \int_{\partial B(x_0,r)}
            \frac{1}{r^p} \diff S \diff r \\
        &= \frac{1}{(2\pi)^{p-1}} \int_{0}^{R} r^{1-p} \diff r,
        \quad i=1,2.
    \end{align*}
    This is the same integral as above, and it is finite since $p < 2$.
    Thus, $\nabla \Phi_{x_0} \in L^p(\Omega) \times L^p(\Omega)$.

    To conclude that $\Phi_{x_0} \in W^{1,p}(\Omega)$, we need to show that
    $\nabla \Phi_{x_0}$ is the weak gradient of $\Phi_{x_0}$.
    This is not obvious due to the singularity at the point $x_0$.
    Let $\varepsilon > 0$ be small so that
    $B(x_0,\varepsilon) \subset \Omega$.
    We need to consider $\Phi_{x_0}$ inside and outside this ball separately.
    Outside the ball, $\Phi_{x_0}$ is smooth and bounded
    so we may use classical results from calculus.
    Let $\phi \in C_0^{\infty}(\Omega)$. Then for $i=1,2$ we have
    \begin{equation}
        \label{eq:greens_function_weak_diff_intmed1}
        \int_{\Omega} \Phi_{x_0} D_i \phi \diff x
        = \int_{B(x_0,\varepsilon)} \Phi_{x_0} D_i \phi \diff x
            + \int_{\Omega \setminus \overline{B(x_0,\varepsilon)}}
                \Phi_{x_0} D_i \phi \diff x.
    \end{equation}
    Bringing $\varepsilon$ to zero, the first integral in
    \eqref{eq:greens_function_weak_diff_intmed1} becomes
    \begin{equation}
        \label{eq:greens_function_weak_diff_intmed2}
        \lim_{\varepsilon \to 0}
            \int_{B(x_0,\varepsilon)} \Phi_{x_0} D_i \phi \diff x
        = \int_{\Omega} \lim_{\varepsilon \to 0} \boldone_{B(x_0,\varepsilon)}
            \Phi_{x_0} D_i \phi \diff x
        = 0,   
    \end{equation}
    where we used the dominated convergence theorem with the estimate
    $\Phi_{x_0} D_i \phi \leq \abs{\Phi_{x_0}} \norm{D_i\phi}_{L^{\infty}(\Omega)}
    \in L^1(\Omega)$. By integration by parts, the second integral in
    \eqref{eq:greens_function_weak_diff_intmed1} becomes
    \begin{equation}
        \label{eq:greens_function_weak_diff_intmed3}
        \int_{\Omega \setminus \overline{B(x_0,\varepsilon)}}
            \Phi_{x_0} D_i \phi \diff x
        = -\int_{\Omega \setminus \overline{B(x_0,\varepsilon)}}
            D_i \Phi_{x_0} \phi \diff x
                - \int_{\partial B(x_0,\varepsilon)} \Phi_{x_0} \phi n_i \diff S.
    \end{equation}
    By the dominated convergence theorem, the first integral in
    \eqref{eq:greens_function_weak_diff_intmed3} has the limit
    \begin{align*}
        \lim_{\varepsilon \to 0}
            \int_{\Omega \setminus \overline{B(x_0,\varepsilon)}}
                D_i \Phi_{x_0} \phi \diff x
        &= \int_{\Omega}
                \lim_{\varepsilon \to 0}
                    \boldone_{\Omega \setminus \overline{B(x_0,\varepsilon)}}
                        D_i \Phi_{x_0} \phi \diff x \\
        &= \int_{\Omega} D_i \Phi_{x_0} \phi \diff x,
    \end{align*}
    where we used the estimate $D_i \Phi_{x_0} \phi \leq
    \abs{D_i \Phi_{x_0}}\norm{\phi}_{L^{\infty}(\Omega)} \in L^1(\Omega)$
    in the application of the dominated convergence theorem.
    The boundary term in \eqref{eq:greens_function_weak_diff_intmed3}
    can be estimated by
    \begin{align*}
        \abs*{\int_{\partial B(x_0,\varepsilon)} \Phi_{x_0} \phi n_i \diff S}
        &\leq \int_{\partial B(x_0,\varepsilon)} \abs{\Phi_{x_0} \phi n_i} \diff S\\
        &\leq \norm{\phi}_{L^{\infty}(\Omega)}
            \int_{\partial B(x_0,\varepsilon)} \abs*{\log \varepsilon} \diff S \\
        &= 2 \pi \norm{\phi}_{L^{\infty}(\Omega)} \varepsilon \log \varepsilon \\
        &\xrightarrow[]{\varepsilon \to 0} 0.
    \end{align*}
    The limit follows from a simple application of L'Hôpital's rule.
    Thus, the boundary term vanishes as $\varepsilon \to 0$.
    Bringing now $\varepsilon$ to zero in 
    \eqref{eq:greens_function_weak_diff_intmed1}, we get
    \begin{equation*}
        \int_{\Omega} \Phi_{x_0} D_i \phi \diff x
        = - \int_{\Omega} D_i \Phi_{x_0} \phi \diff x.
    \end{equation*}
    That is, the weak derivatives exist and $\Phi_{x_0} \in W^{1,p}(\Omega)$.

    We need to show that $\Phi_{x_0}$ solves the problem 
    \eqref{eq:greens_function_is_solution_problem} in the weak sense.
    The boundary values obviously hold.
    Let $v \in W^{1,q}(\Omega)$ such that $v|_{\Gamma_j} = 0$ for all $j \in D$
    and where $q$ is the conjugate exponent of $p$. Now
    \begin{equation}
        \label{eq:greens_function_weak_diff_intmed4}
        \int_{\Omega} \nabla \Phi_{x_0} \cdot \nabla v \diff x
        = \int_{B(x_0,\varepsilon)} \nabla \Phi_{x_0} \cdot \nabla v \diff x
            + \int_{\Omega \setminus \overline{B(x_0,\varepsilon)}}
                \nabla \Phi_{x_0} \cdot \nabla v \diff x.
    \end{equation}
    By the Cauchy-Schwarz and Hölder's inequality, we have
    \begin{equation*}
        \nabla \Phi_{x_0} \cdot \nabla v
        \leq \abs{\nabla \Phi_{x_0}} \abs{\nabla v}
        \in L^1(\Omega).
    \end{equation*}
    Thus, we may apply the dominated convergence theorem to the limit of the
    first integral in \eqref{eq:greens_function_weak_diff_intmed4}:
    \begin{equation*}
        \lim_{\varepsilon \to 0} \int_{B(x_0,\varepsilon)}
            \nabla \Phi_{x_0} \cdot \nabla v \diff x
        = \int_{\Omega} \lim_{\varepsilon \to 0} \boldone_{B(x_0,\varepsilon)}
            \nabla \Phi_{x_0} \cdot \nabla v \diff x
        = 0.
    \end{equation*}
    By Green's formula, the second integral in
    \eqref{eq:greens_function_weak_diff_intmed4} becomes
    \begin{align*}
        \int_{\Omega \setminus \overline{B(x_0,\varepsilon)}}
                \nabla \Phi_{x_0} \cdot \nabla v \diff x
        &= -\int_{\Omega \setminus \overline{B(x_0,\varepsilon)}}
            \Delta \Phi_{x_0} v \diff x
                + \sum_{j \in N} \int_{\Gamma_j}
                    \frac{\partial \Phi_{x_0}}{\partial n} v \diff S\\
        &\hspace{40.7mm} - \int_{\partial B(x_0,\varepsilon)}
                    \frac{\partial \Phi_{x_0}}{\partial n} v \diff S
    \end{align*}
    The first integral vanishes, because $\Delta \Phi_{x_0} = 0$
    everywhere except at the point $x_0$.
    The limit of the last boundary integral can be calculated exactly.
    Note that $n = (x-x_0)/\varepsilon$. Now
    \begin{align*}
        \int_{\partial B(x_0,\varepsilon)}
            \frac{\partial \Phi_{x_0}}{\partial n} v \diff S
        &= \int_{\partial B(x_0,\varepsilon)}
            \left(-\frac{1}{2\pi} \frac{x-x_0}{\abs{x-x_0}^2} \cdot
                \frac{x-x_0}{\varepsilon} \right) v \diff S \\
        &= \int_{\partial B(x_0,\varepsilon)}
            \left(-\frac{1}{2\pi\varepsilon} \frac{\abs{x-x_0}^2}{\abs{x-x_0}^2}
                \right) v \diff S \\
        &= -\frac{1}{2\pi\varepsilon} \int_{\partial B(x_0,\varepsilon)}
            v \diff S \\
        &\xrightarrow[]{\varepsilon \to 0} -v(x_0).
    \end{align*}
    The limit follows from Theorem~\ref{thm:lebesgue_differentiation_theorem}.
    Thus, bringing $\varepsilon$ to zero in 
    \eqref{eq:greens_function_weak_diff_intmed4}, we get
    \begin{equation*}
        \int_{\Omega} \nabla \Phi_{x_0} \cdot \nabla v \diff x
        = v(x_0) + \sum_{j \in N} \int_{\Gamma_j}
            \frac{\partial \Phi_{x_0}}{\partial n} v \diff S,
    \end{equation*}
    which is what we wanted to show.
\end{proof}

The Green's function $\Phi_{x_0}$ is used as an auxiliary
function to find a general classical solution to Poisson's equation.
In the same spirit, we consider next how $\Phi_{x_0}$ can be used to prove
a theorem equivalent to Theorem~\ref{thm:greens_function_is_solution} but
with general boundary data.

\subsubsection{Existence and Uniqueness of Solutions with General Boundary Data}
\label{subsubsec:existence_and_uniqueness_of_solutions_with_arbitrary_data}

Theorem~\ref{thm:greens_function_is_solution} and the solvability of
the classical weak formulation of Poisson's equation imply that the problem
\eqref{eq:poissons_eq_with_dirac_delta_recap} has a weak solution.
\begin{theorem}
    \label{thm:dirac_load_is_solvable}
    Let $\Omega \subset \mathbb{R}^2$ be a bounded polygonal domain without slits,
    and choose $x_0 \in \Omega$.
    Let $g_j \in T(H^2(\Omega))$ for $j \in D$ and $g_j \in T(H^1(\Omega))$
    for $j \in N$. Assume that there exists a function $g_D \in H^2(\Omega)$
    such that $g_D|_{\Gamma_j} = g_j$ for all $j \in D$.
    Let $1 < p < 2$. Then the boundary value problem
    \begin{equation}
        \label{eq:dirac_load_is_solvable_problem}
        \left\{
            \begin{aligned}
                -\Delta u &= \delta_{x_0} && \text{in } \Omega \\
                u &= g_j && \text{on } \Gamma_j, \quad j \in D \\
                \frac{\partial u}{\partial n} &= g_j && \text{on } \Gamma_j,
                \quad j \in N
            \end{aligned}
        \right.
    \end{equation}
    has a weak solution $u \in W^{1,p}(\Omega)$.
\end{theorem}
\begin{proof}
    Define $\Phi_{x_0}$ by \eqref{eq:greens_function} like before.
    The startegy is to consider the problem
    \begin{equation}
        \label{eq:dirac_load_is_solvable_aux_problem}
        \left\{
            \begin{aligned}
                -\Delta w &= 0 && \text{in } \Omega \\
                w &= g_j - \Phi_{x_0} && \text{on } \Gamma_j, \quad j \in D \\
                \frac{\partial w}{\partial n} &=
                    g_j - \frac{\partial \Phi_{x_0}}{\partial n}
                        && \text{on } \Gamma_j, \quad j \in N
            \end{aligned}
        \right.
    \end{equation}
    and use Theorem~\ref{thm:weak_poisson_is_solvable} and
    Theorem~\ref{thm:greens_function_is_solution}.
    
    Assume that Theorem~\ref{thm:weak_poisson_is_solvable} implies the
    existence of a weak solution $w \in H^1(\Omega)$ to the problem
    \eqref{eq:dirac_load_is_solvable_aux_problem}.
    Then $u = w + \Phi_{x_0}$ is a weak solution to the problem
    \eqref{eq:dirac_load_is_solvable_problem} as follows.
    First, $w \in W^{1,p}(\Omega)$ due to the imbedding
    $H^1(\Omega) \subset W^{1,p}(\Omega)$ so $u \in W^{1,p}(\Omega)$.
    Second, we clearly have $u|_{\Gamma_j} = g_j$ for all $j \in D$.
    Finally, let $v \in W^{1,q}(\Omega)$ such that $v|_{\Gamma_j} = 0$
    for all $j \in D$ where $2 < q < \infty$ is the conjugate exponent of $p$.
    Note that $W^{1,q}(\Omega) \subset H^1(\Omega)$. We then have
    \begin{align*}
        \int_{\Omega} \nabla u \cdot \nabla v \diff x
        &= \int_{\Omega} \nabla w \cdot \nabla v \diff x
            + \int_{\Omega} \nabla \Phi_{x_0} \cdot \nabla v \diff x \\
        &= \sum_{j \in N} \int_{\Gamma_j}
            \left( g_j - \frac{\partial \Phi_{x_0}}{\partial n} \right) v \diff S
            + v(x_0)
            + \sum_{j \in N} \int_{\Gamma_j}
                \frac{\partial \Phi_{x_0}}{\partial n} v \diff S \\
        &= v(x_0) + \sum_{j \in N} \int_{\Gamma_j} g_j v \diff S.
    \end{align*}

    We now only need to show that Theorem~\ref{thm:weak_poisson_is_solvable}
    is applicable to the problem \eqref{eq:dirac_load_is_solvable_aux_problem}.
    It is not clear whether the Dirichlet and Neumann boundary functions
    belong to the spaces $T(H^2(\Omega))$ and $T(H^1(\Omega))$, respectively.
    If $\Phi_{x_0} \in H^2(\Omega)$, then this would be obviously true,
    but it is easy to show that
    $\nabla \Phi_{x_0} \notin L^2(\Omega) \times L^2(\Omega)$, which implies
    that $\Phi_{x_0} \notin H^2(\Omega)$.
    
    The only issue is the singularity of $\Phi_{x_0}$ at the point $x_0$. 
    The function $\Phi_{x_0}$ is smooth everywhere else including the boundary.
    Since $\Phi_{x_0}$ is radial when $x_0$ is the origin,
    let us remove the singularity by truncating 
    $\Phi_{x_0}$ over a ball $B(x_0,\varepsilon) \subset \Omega$
    with a small radius $\varepsilon > 0$, and denote the truncated
    function by $\Phi_{x_0,\varepsilon}$ that is defined by
    \begin{equation*}
        \Phi_{x_0,\varepsilon}(x)
        = (1 - \boldone_{B(x_0,\varepsilon)}(x)) \Phi_{x_0}(x)
            + \boldone_{B(x_0,\varepsilon)}(x) \Phi_{x_0}(x_0 + \varepsilon r)
    \end{equation*}
    for $x \in \overline{\Omega}$ and
    where $r \in \mathbb{R}^2$ is an arbitrary unit vector. Clearly,
    $\Phi_{x_0,\varepsilon}|_{\partial \Omega} = \Phi_{x_0}|_{\partial \Omega}$.
    
    Let us smooth out $\Phi_{x_0,\varepsilon}$ over the edge
    $\partial B(x_0, \varepsilon)$.
    Choose $\varepsilon$ so that the distance between the ball
    $B(x_0,\varepsilon)$ and the boundary $\partial \Omega$
    is at least $\varepsilon$. By a standard mollification argument,
    there exists a function $\eta \in C_0^{\infty}(\mathbb{R})$ such that
    $\eta(t) = 1$ whenever $\abs{t} < \varepsilon/4$
    and $\eta(t) = 0$ whenever $\abs{t} > \varepsilon/2$.
    Consider then the function
    \begin{equation*}
        g_{\Phi}(x)
        = (1 - \eta(\abs{x-x_0}-\varepsilon)) \Phi_{x_0,\varepsilon}(x)
            + \eta(\abs{x-x_0}-\varepsilon) \Phi_{x_0,\varepsilon}(x_0)
    \end{equation*}
    for $x \in \overline{\Omega}$.
    When $x \neq x_0$, the function $g_{\Phi}$ is smooth because all its
    components are smooth. Moreover, $g_{\Phi}$ is constant whenever
    $\abs{x-x_0} < \varepsilon/2$, which implies that it is smooth at
    the point $x_0$ as well. In particular,
    $g_{\Phi} \in C^{\infty}(\overline{\Omega}) \subset H^2(\Omega)$.

    The fact that $g_{\Phi} = \Phi_{x_0}$ near and on the boundary
    implies that $\Phi_{x_0}|_{\partial \Omega} \in T(H^2(\Omega))$ and
    $\partial \Phi_{x_0} / \partial n \in T(H^1(\Omega))$ on
    each boundary segment $\Gamma_j$ for $j \in N$. Moreover,
    \begin{equation*}
        T(g_D - g_{\Phi})
        = Tg_D - Tg_{\Phi}
        = g_j - \Phi_{x_0}
    \end{equation*}
    for all $j \in D$ and $g_D - g_{\Phi} \in H^2(\Omega)$.
    We may thus apply Theorem~\ref{thm:weak_poisson_is_solvable}
    to the problem \eqref{eq:dirac_load_is_solvable_aux_problem},
    which concludes the proof.
\end{proof}

Theorem~\ref{thm:dirac_load_is_solvable} does not say anything about
the uniqueness of the weak solutions. When the domain satisfies
Assumption~\ref{ass:regular_polygonal_domain}, we are able to show
uniqueness as well.
\begin{theorem}
    \label{thm:uniqueness_of_dirac_solution}
    Let $\Omega \subset \mathbb{R}^2$ be a bounded polygonal domain
    that satisfies Assumption~\ref{ass:regular_polygonal_domain}.
    Let $u \in W^{1,p}(\Omega)$ be a weak solution to the problem
    \eqref{eq:dirac_load_is_solvable_problem}.
    When $D \neq \varnothing$, $u$ is unique.
    When $D = \varnothing$, $u$ is unique up to an additive constant.
\end{theorem}
\begin{proof}
    Let $v \in W^{1,p}(\Omega)$ be another weak solution to the problem
    \eqref{eq:dirac_load_is_solvable_problem}.
    Then $u - v \in W^{1,p}(\Omega)$ satisfies
    \begin{equation}
        \label{eq:uniqueness_of_dirac_solution_intmed1}
        \int_{\Omega} \nabla (u-v) \cdot \nabla w \diff x = 0
    \end{equation}
    for all $w \in W^{1,q}(\Omega)$ where $2 < q < \infty$ is the conjugate
    exponent of $p$. Moreover, $(u-v)|_{\Gamma_j} = 0$ for all $j \in D$.

    Consider then the boundary value problem
    \begin{equation}
        \label{eq:uniqueness_of_dirac_solution_aux_problem}
        \left\{
            \begin{aligned}
                -\Delta h &= u-v && \text{in } \Omega \\
                h &= 0 && \text{on } \Gamma_j, \quad j \in D \\
                \frac{\partial h}{\partial n} &= 0 && \text{on } \Gamma_j,
                \quad j \in N,
            \end{aligned}
        \right.
    \end{equation}
    where $u-v \in L^2(\Omega)$ by the Sobolev imbedding theorem.
    When $D = \varnothing$, the source term and the boundary terms need
    to satisfy the compatibility condition
    \begin{equation}
        \label{eq:uniqueness_of_dirac_solution_compatibility}
        \int_{\Omega} u - v \diff x = 0.
    \end{equation}
    The general case, where \eqref{eq:uniqueness_of_dirac_solution_compatibility}
    does not necessarily hold, is considered later.

    By Theorem~\ref{thm:weak_poisson_is_solvable}
    and Theorem~\ref{thm:H2_regularity}, there exists a weak solution
    $h \in H^2(\Omega)$ to the problem 
    \eqref{eq:uniqueness_of_dirac_solution_aux_problem}.
    Moreover, by Theorem~\ref{thm:weak_solution_is_strong_solution},
    it holds that $-\Delta h = u-v$
    and $\partial h / \partial n = 0$ on each $\Gamma_j$ for $j \in N$.
    Now by these facts and Green's formula, we get
    \begin{align*}
        \norm{u-v}_{L^2(\Omega)}^2
        &= \int_{\Omega} (u-v)^2 \diff x \\
        &= - \int_{\Omega} (u-v) \Delta h  \diff x \\
        &= \int_{\Omega} \nabla (u-v) \cdot \nabla h \diff x
            - \sum_{j \in D} \int_{\Gamma_j}
                \frac{\partial h}{\partial n} (u-v) \diff S
            - \sum_{j \in N} \int_{\Gamma_j}
                \frac{\partial h}{\partial n} (u-v) \diff S \\
        &= 0.
    \end{align*}
    Note that the first term is zero because the Sobolev imbedding theorem
    implies that $H^2(\Omega) \subset W^{1,q}(\Omega)$ and we may thus
    apply the identity \eqref{eq:uniqueness_of_dirac_solution_intmed1}.
    The integrals over the Dirihlet boundary terms vanish because
    $(u-v)|_{\Gamma_j} = 0$ for all $j \in D$.
    
    The result $\norm{u-v}_{L^2(\Omega)}^2 = 0$ implies that $u = v$
    almost everywhere in $\Omega$. This concludes the proof for the
    case $D \neq \varnothing$. This also concludes the proof for the case
    $D = \varnothing$ with the condition 
    \eqref{eq:uniqueness_of_dirac_solution_compatibility}, i.e.\
    $u-v \in V_N$. If the condition 
    \eqref{eq:uniqueness_of_dirac_solution_compatibility} does not hold,
    then as usual we consider the normalized function
    $u-v-(\overline{u} - \overline{v}) \in V_N$, where
    \begin{equation*}
        \overline{u} = \frac{1}{\abs{\Omega}} \int_{\Omega} u \diff x.
    \end{equation*}
    Using the normalized function as the source term for the problem
    \eqref{eq:uniqueness_of_dirac_solution_aux_problem} then
    implies that $u-v-(\overline{u} - \overline{v}) = 0$,
    i.e.\ $u$ and $v$ differ by a constant. This concludes the proof.
\end{proof}

\subsubsection{Derivatives of the Dirac Delta}
\label{subsubsec:derivatives_of_the_dirac_delta}

Informally, we may consider the Dirac delta $\delta_{x_0}$ as a kernel function
that is defined by the identity
\begin{equation*}
    \int_{\Omega} \delta_{x_0} \phi \diff x = \phi(x_0)
\end{equation*}
for all $\phi \in C_0^{\infty}(\Omega)$.
What would the partial derivatives $D^{\alpha} \delta_{x_0}$ look like
for an arbitrary multi-index $\alpha$?

Recall that the $\alpha$th weak partial derivative
of a function $u \in W^{k,p}(\Omega)$ is defined by the integral identity
\begin{equation*}
    \int_{\Omega} D^{\alpha} u \phi \diff x
    = (-1)^{\abs{\alpha}} \int_{\Omega} u D^{\alpha} \phi \diff x
\end{equation*}
for all $\phi \in C_0^{\infty}(\Omega)$.
This motivates the definition of $D^{\alpha} \delta_{x_0}$, again informally,
as a kernel function such that
\begin{equation*}
    \int_{\Omega} D^{\alpha} \delta_{x_0} \phi \diff x
    = (-1)^{\abs{\alpha}} \int_{\Omega} \delta_{x_0} D^{\alpha} \phi \diff x
    = (-1)^{\abs{\alpha}} D^{\alpha} \phi(x_0)
\end{equation*}
for all $\phi \in C_0^{\infty}(\Omega)$.
The formal definition follows from the theory of distributions
and their derivatives, and the gist would essentially be the same.
For reference, see \cite[Chapter 6]{rudin1991}.

We again consider $D^{\alpha} \delta_{x_0}$ as a functional
\begin{equation*}
    D^{\alpha} \delta_{x_0}(v) = (-1)^{\abs{\alpha}} D^{\alpha} v(x_0),
\end{equation*}
when the pointwise evaluation makes sense.
This motivates the question whether it makes sense to consider the
boundary value problem
\begin{equation}
    \label{eq:poisson_with_derivative_of_dirac}
    \left\{
        \begin{aligned}
            -\Delta u &= D^{\alpha} \delta_{x_0} && \text{in } \Omega \\
            u &= g_j && \text{on } \Gamma_j, \quad j \in D \\
            \frac{\partial u}{\partial n} &= g_j && \text{on } \Gamma_j,
            \quad j \in N,
        \end{aligned}
    \right.
\end{equation}
where $\Omega \subset \mathbb{R}^2$ is a bounded polygonal domain.
Evidently, the weak formulation could be to find a function $u \in U$ such that
\begin{equation}
    \label{eq:poisson_with_derivative_of_dirac_variational}
    \int_{\Omega} \nabla u \cdot \nabla v \diff x
    = (-1)^{\abs{\alpha}} D^{\alpha} v(x_0)
        + \sum_{j \in N} \int_{\Gamma_j} g_j v \diff S
\end{equation}
for all $v \in V$ where $U$ and $V$ are suitable Sobolev spaces.
For example, the Sobolev imbedding theorem implies that
when $V \subset W^{k,q}(\Omega)$ with $k > \abs{\alpha}$ and $q > 2$,
the evaluation of the partial derivative in 
\eqref{eq:poisson_with_derivative_of_dirac_variational} makes sense.

We will not try to consider the problem \eqref{eq:poisson_with_derivative_of_dirac}
in its most general form.
Instead, let us briefly consider the case $\abs{\alpha} = 1$
with the help of Green's function $\Phi_{x_0}$.
The function $\Phi_{x_0} \in W^{1,p}(\Omega)$, $1 < p < 2$, satisfies
\begin{equation}
    \label{eq:derivative_of_greens_function_variational_intmed1}
    \int_{\Omega} \nabla \Phi_{x_0} \cdot \nabla v \diff x
    = v(x_0) + \sum_{j \in N} \int_{\Gamma_j}
        \frac{\partial \Phi_{x_0}}{\partial n} v \diff S
\end{equation}
for all suitable $v \in W^{1,q}(\Omega)$ with $q > 2$.
Assume that $v \in W^{2,q}(\Omega) \subset C^1(\overline{\Omega})$ is
such that \eqref{eq:derivative_of_greens_function_variational_intmed1} holds.
Consider $x_0$ as a variable, and differentiate both sides of
\eqref{eq:derivative_of_greens_function_variational_intmed1}
with respect to $x_0$ according to the multi-index $\alpha$.
Setting $\nabla (D_{x_0}^{\alpha} \Phi_{x_0})(x_0) = 0$ and
assuming that the differentiation can be taken under the integral
and inside the gradient, we get
\begin{equation}
    \label{eq:derivative_of_greens_function_variational_intmed2}
    \int_{\Omega} \nabla (D_{x_0}^{\alpha} \Phi_{x_0}) \cdot \nabla v \diff x
    = D_{x_0}^{\alpha} v(x_0) + \sum_{j \in N} \int_{\Gamma_j}
        \frac{\partial D_{x_0}^{\alpha} \Phi_{x_0}}{\partial n} v \diff S.
\end{equation}
By a simple calculation,
$D_{x_0}^{\alpha} \Phi_{x_0} = -D_x^{\alpha} \Phi_{x_0}$.
Denote $D^{\alpha} = D_x^{\alpha}$ as usual.
Inserting this into \eqref{eq:derivative_of_greens_function_variational_intmed2}
results in
\begin{align*}
    \int_{\Omega} \nabla (D^{\alpha} \Phi_{x_0}) \cdot \nabla v \diff x
    &= -D^{\alpha} v(x_0) + \sum_{j \in N} \int_{\Gamma_j}
        \frac{\partial D^{\alpha} \Phi_{x_0}}{\partial n} v \diff S \\
    &= D^{\alpha} \delta_{x_0}(v) + \sum_{j \in N} \int_{\Gamma_j}
        \frac{\partial D^{\alpha} \Phi_{x_0}}{\partial n} v \diff S.
\end{align*}
We see that $D^{\alpha} \Phi_{x_0}$ would be a special weak solution
to the problem \eqref{eq:poisson_with_derivative_of_dirac}
if the operations above were justified. One can, however, easily show that
$\nabla (D^{\alpha} \Phi_{x_0}) \notin L^1(\Omega) \times L^1(\Omega)$
due to the singularity at the point $x_0$,
which implies that when $v \in W^{2,q}(\Omega)$ is such that $\nabla v = (1,1)$
in a neighbourhood of $x_0$, the integral on the left-hand side does not converge.
Thus, it is still not clear how to define the spaces $U$ and $V$.
We will not bother ourselves with the issue of defining them any further.
The finite element method can, however, still be applied to the problem,
and it will be interesting to see whether it converges to the
function $D^{\alpha} \Phi_{x_0}$.

\clearpage

\section{The Finite Element Method}
\label{sec:finite_element_method}

We introduce here the finite element method as a general procedure for obtaining
approximate solutions to weakly formulated elliptic boundary value problems.
After the introduction, we consider the error of the approximate solutions
with emphasis on the $p$-version of the finite element method.
This is done through the approximation properties of high-order polynomials
in one and two dimensions.

%This section mostly deals with the theoretical
%aspects of the finite element method. Practical aspects are deferred to the
%next section, where the method is applied to the Dirac delta problem.

\subsection{Definition of a Finite Element Solution}
\label{subsec:basic_properties_of_finite_element_solutions}

Consider the task of finding a solution to the weakly formulated
boundary value problem
\begin{equation}
    \label{eq:fem_departure}
    \text{Find } u \in U \text{ s.t.\ }
    a(u,v) = \varphi(v) \text{ for all } v \in V,
\end{equation}
where $U$ and $V$ are Sobolev subspaces, the mapping $a: U \times V \to \mathbb{R}$
is bilinear and $\varphi \in V'$.
We assume that \eqref{eq:fem_departure} corresponds to an
elliptic second-order boundary value problem
with Dirichlet and/or Neumann boundary conditions.
As an example, consider the classical weak formulation of Poisson's
equation with homogeneous Dirichlet boundary conditions, where
\begin{equation*}
    U = V
    = \left\{ v \in H^1(\Omega)
        : v|_{\Gamma_j} = 0 \text{ for all } j \in D \right\}
\end{equation*}
or, if $D = \varnothing$,
\begin{equation*}
    U = V
    = \left\{ v \in H^1(\Omega) : \int_{\Omega} v \diff x = 0 \right\}.
\end{equation*}
With the Dirac delta load, the spaces $U$ and $V$ are otherwise
defined identically but $U \subset W^{1,p}(\Omega)$
and $V \subset W^{1,q}(\Omega)$, where
$1 < p < 2$ and $2 < q < \infty$ are conjugate exponents.
Recall that a problem with non-homogeneous Dirichlet boundary
conditions can be cast into a problem with
homogeneous Dirichlet boundary conditions as described
at the beginning of Section~\ref{sec:poissons_equation_in_a_polygon}.

Assume that the problem \eqref{eq:fem_departure} has a unique solution.
For what was considered in Section~\ref{sec:poissons_equation_in_a_polygon},
the validity of this assumption relies at least partly on the applicability
of the Lax-Milgram theorem. The Lax-Milgram theorem does not, however,
provide a method for constructing the solution for computational purposes.
In fact, it is rare to find an explicit formula for the solution,
but we may still try to approximate it.

Let $S_U$ and $S_V$ be finite-dimensional subspaces of $U$ and $V$,
respectively. That is, $S_U = \spn \{ u_1,\dotsc,u_m \} \subset U$
and $S_V = \spn \{ v_1,\dotsc,v_m \} \subset V$
for some positive integer $m \in \mathbb{N}$.
Note that $\dim S_U = \dim S_V = m$.
Consider then the discretized problem
\begin{equation}
    \label{eq:fem_discretized}
    \text{Find } u_S \in S_U \text{ s.t.\ }
    a(u_S,v) = \varphi(v) \text{ for all } v \in S_V.
\end{equation}
A solution to the problem \eqref{eq:fem_discretized} essentially
defines the idea of a finite element solution to \eqref{eq:fem_departure}
which is to search for an approximate solution in a suitable finite-dimensional
subspace instead of considering the whole space which is virtually always
infinite-dimensional. One of the most emblematic features of
the finite element method is the choice of the subspaces $S_U$ and $S_V$.
Before considering that in more detail, let us first consider when the general
discretized problem \eqref{eq:fem_discretized} actually has a solution.
This will also steer us towards the construction of finite element solutions
in practice.
Note that a possible solution can be written as
\begin{equation}
    \label{eq:uS_wrt_basis}
    u_S = \sum_{i=1}^{m} b_i u_i
\end{equation}
for some coordinate vector $b = (b_1,\dotsc,b_m) \in \mathbb{R}^m$.
Consider then the following theorem.
\begin{theorem}
    \label{thm:discretized_problem_solution_equivalence}
    Define a matrix $K \in \mathbb{R}^{m \times m}$ such that
    $K_{ij} = a(u_j,v_i)$, and define a vector $r \in \mathbb{R}^m$
    such that $r_i = \varphi(v_i)$. Then $u_S$ is a solution
    to the discretized problem \eqref{eq:fem_discretized}
    if and only if the coordinate vector $b$ of $u_S$ solves the system
    of equations $Kb = r$.
\end{theorem}
\begin{proof}
    Assume first that $u_S$ is a solution to \eqref{eq:fem_discretized}.
    Let $v \in S_V$ which can be written as
    \begin{equation}
        \label{eq:v_wrt_basis}
        v = \sum_{i=1}^{m} c_i v_i
    \end{equation}
    for some $c = (c_1,\dotsc,c_m) \in \mathbb{R}^m$.
    Inserting \eqref{eq:uS_wrt_basis} and \eqref{eq:v_wrt_basis} into
    \eqref{eq:fem_discretized} and using the linearity of $a$ and $\varphi$
    gives
    \begin{equation}
        \label{eq:fem_discretized_intmed1}
        \sum_{i=1}^{m} \sum_{j=1}^{m} b_i c_j a(u_i,v_j)
        = \sum_{i=1}^{m} c_i \varphi(v_i).
    \end{equation}
    Note that \eqref{eq:fem_discretized_intmed1} can be written as
    \begin{equation}
        \label{eq:fem_discretized_intmed2}
        c^T K b = c^T r.
    \end{equation}
    The vector $c$ was chosen to be arbitrary, which means that by setting
    $c = Kb - r$ in \eqref{eq:fem_discretized_intmed2},
    we see that the coefficient vector $b$
    must solve the system of equations $Kb = r$.

    Assume then that $b$ solves the system $Kb = r$.
    Let $v \in S_V$ as in \eqref{eq:v_wrt_basis}.
    Backtracking the steps above, we conclude that
    \begin{equation*}
        a(u_S,v) = \varphi(v),
    \end{equation*}
    which means that $u_S$ solves the problem \eqref{eq:fem_discretized}.
\end{proof}

The matrix $K$ is usually called the stiffness matrix, and
the vector $r$ is usually called the load vector.
The assumption that $\dim S_U = \dim S_V = m$ is now useful
because $K$ becomes a square matrix.
In particular, the discretized problem \eqref{eq:fem_discretized}
has a unique solution if and only if $K$ is non-singular,
and the solution can be computed by solving the system $Kb=r$.
It turns out that the matrix $K$ is non-singular
precisely when the mapping $a$ and the subspaces $S_U$ and $S_V$
satisfy a certain regularity condition \cite{schwab1998}.
\begin{theorem}
    \label{thm:nonsingularity_of_K}
    The matrix $K$ in Theorem~\ref{thm:discretized_problem_solution_equivalence}
    is non-singular if and only if for every
    $0 \neq u \in S_U$ there exists a $v \in S_V$ such that $a(u,v) \neq 0$.
\end{theorem}
\begin{proof}
    Assume first that $K$ is non-singular.
    Let $0 \neq u \in S_U$ and write
    \begin{equation}
        \label{eq:nonsingularity_of_K_u}
        u = \sum_{i=1}^{m} b_i u_i
    \end{equation}
    for some $b = (b_1,\dotsc,b_m) \in \mathbb{R}^m$.
    Since $u \neq 0$, also $b \neq 0$.
    Because $K$ is non-singular, $Kb \neq 0$.
    Let $v \in S_V$ be such that
    \begin{equation*}
        %\label{eq:nonsingularity_of_K_v}
        v = \sum_{i=1}^{m} c_i v_i,
    \end{equation*}
    where $c = (c_1,\dotsc,c_m) = Kb \in \mathbb{R}^m$. Now
    \begin{equation*}
        a(u,v) = c^T Kb = (Kb)^T Kb = \norm{Kb}^2 > 0.
    \end{equation*}
    That is, $a(u,v) \neq 0$.

    Assume then the other direction that for every
    $0 \neq u \in S_U$ there exists a $v \in S_V$ such that $a(u,v) \neq 0$.
    Aiming for a contradiction, assume that $K$ is singular.
    The singularity of $K$ implies that
    there exists a $0 \neq b \in \mathbb{R}^m$ such that $Kb = 0$.
    Defining $0 \neq u \in S_U$ as in \eqref{eq:nonsingularity_of_K_u},
    we now get that
    \begin{equation*}
        a(u,v) = c^T Kb = 0
    \end{equation*}
    for all $v \in S_V$.
    This contradicts the initial assumption, which means that $K$
    must be non-singular.
\end{proof}

The Sobolev subspaces $S_U$ and $S_V$ should naturally be chosen so that
Theorem~\ref{thm:nonsingularity_of_K} can be easily used to deduce
the non-singularity of $K$. We assume that the mapping $a$ corresponds
to an elliptic second-order differential operator, i.e.
$U \subset W^{1,p}(\Omega)$ and $V \subset W^{1,q}(\Omega)$
for some real numbers $p$ and $q$.
We saw in Section~\ref{subsec:solvability_of_the_classical_weak_formulation}
that symmetricity of the weak formulation made it more convenient to prove the
existence of a unique solution. The same also applies to the discretized
weak formulation \eqref{eq:fem_discretized} by requiring that $S_U = S_V$.
Let $S$ denote this common subspace.
When $S \subset H^1(\Omega)$, the ellipticity of $a$ implies that
$a(u,u) > 0$ for all $0 \neq u \in S$, which then implies
via Theorem~\ref{thm:nonsingularity_of_K} that $K$ is non-singular
and the discretized problem has a unique solution.
The mapping $a$ is typically also symmetric, which means that the
matrix $K$ is symmetric. Moreover, the ellipticity of $a$ implies that
$K$ is positive definite.
A system of linear equations $Kb = r$ with a symmetric and positive
definite matrix $K$ can be solved efficiently on a computer.
The subspace $S$ should preferably be chosen so that
the stiffness matrix $K$ and the load vector $r$ are easy to compute.
The assumption that $S \subset H^1(\Omega)$ is easy to satisfy in practice.

With these considerations in mind, let us discuss the particular choice of the 
finite-dimensional subspace $S \subset H^1(\Omega)$
on which the finite element method is usually based.
As usual, we assume that $\Omega \subset \mathbb{R}^2$ is a polygonal domain.
In the finite element method, $\Omega$ is then modeled as a finite
mesh of triangular or quadrilateral subdomains which are called elements,
and the subspace $S$ is the space of piecewise-defined continuous
functions for which the piecewise parts of the domain
correspond to the elements of the mesh and,
after a change of variables to so-called reference elements,
the piecewise functions are polynomials of some fixed degree.

We denote a mesh on the domain $\Omega$ by $\mathcal{M}$
which is a finite set of triangles or quadrilaterals or a mix of both
whose closures' union is exactly the closure of $\Omega$.
In other words, $\mathcal{M} = \{ E_i \}_{i=1}^{N}$, where
$N$ is the total number of elements and
$E_i$ is a triangle or a quadrilateral for all $i=1,2,\dotsc,N$, and
\begin{equation*}
    \overline{\Omega} = \bigcup_{i=1}^{N} \overline{E_i}.
\end{equation*}
For future convenience, it is assumed that the intersection
$\overline{E_i} \cap \overline{E_j}$ for all $i \neq j$
either is empty, consists of a common vertex or consists of an entire common edge.
Figure~\ref{fig:example_mesh} contains an example of such a mesh.
The triangles and quadrilaterals are always assumed to be non-degenerate.
\iffalse
\begin{figure}[t]
    \centering
    \begin{tikzpicture}
        %\draw[help lines] (0,0) grid (8,6);
        \path[draw] (1,2.5)
            -- (4,0.5)
            -- (6.5,2)
            -- (7,4)
            -- (6.2,5)
            -- (2,5.5)
            -- cycle;
        \path[draw] (3,4) -- (2.8,2.8) -- (4.5,2.5) -- (5,4) -- cycle;
        \path[draw] (1,2.5) -- (2.5,1.5) -- (2.8,2.8) -- cycle;
        \path[draw] (2.5,1.5) -- (5,1.1) -- (4.5,2.5);
        \path[draw] (4.5,2.5) -- (7,4);
        \path[draw] (5,4) -- (6.2,5);
        \path[draw] (5,4) -- (2,5.5);
        \path[draw] (3,4) -- (2,5.5);
        %\node at (4.9,4.6) {$T_1$};
        %\node at (3.4,4.4) {$T_2$};
        %\node at (2.2,3.6) {$Q_3$};
        %\node at (2.2,2.2) {$T_4$};
        %\node at (3.7,2) {$Q_5$};
        %\node at (4,0.9) {$T_6$};
        %\node at (5.8,2.4) {$Q_7$};
        %\node at (5.8,3.9) {$Q_8$};
        %\node at (3.9,3.35) {$Q_9$};
    \end{tikzpicture}
    \caption{A finite element mesh.}
    \label{fig:example_mesh}
\end{figure}
\fi

We denote arbitrary triangular and quadrilateral domains by $T$ and $Q$,
respectively. We also define a reference triangle $\widehat{T}$
and a reference quadrilateral $\widehat{Q}$ by
\begin{equation*}
    \widehat{T} = \{ (x_1,x_2) \in \mathbb{R}^2 : 
        0 < x_1 < 1,\text{ } 0 < x_2 < 1 - x_1 \}
\end{equation*}
and $\widehat{Q} = (-1,1) \times (-1,1)$,
see Figure~\ref{fig:reference_triangle} and Figure~\ref{fig:reference_quad}.
The symbol $\widehat{E}$ is used to mean $\widehat{T}$ or $\widehat{Q}$
when $E$ corresponds to a triangle or a quadrilateral, respectively.
It is more convenient to carry out most of the analysis of the finite element
method on the reference elements and then consider a general element
via a bijective mapping $F: \widehat{E} \to E$.

\begin{figure}[t]
\centering
    \begin{minipage}{.5\textwidth}
        \centering
        \begin{tikzpicture}
            %\draw[help lines] (0,0) grid (6,6);
            
            \draw (1,1) -- (5,1);
            \node at (1,0.6) {$(0,0)$};
            \filldraw[black] (1,1) circle (1.5pt);
            
            \draw (5,1) -- (1,5);
            \node at (5,0.6) {$(1,0)$};
            \filldraw[black] (5,1) circle (1.5pt);
            
            \draw (1,1) -- (1,5);
            \node at (1,5.35) {$(0,1)$};
            \filldraw[black] (1,5) circle (1.5pt);
        \end{tikzpicture}
        \captionof{figure}{The reference triangle $\widehat{T}$.}
        \label{fig:reference_triangle}
    \end{minipage}%
    \begin{minipage}{.5\textwidth}
        \centering
        \begin{tikzpicture}
            %\draw[help lines] (0,0) grid (6,6);

            \draw (1,1) -- (5,1);
            \node at (1,0.6) {$(-1,-1)$};
            \filldraw[black] (1,1) circle (1.5pt);
            
            \draw (5,1) -- (5,5);
            \node at (5,0.6) {$(1,-1)$};
            \filldraw[black] (5,1) circle (1.5pt);

            \draw (5,5) -- (1,5);
            \node at (5,5.35) {$(1,1)$};
            \filldraw[black] (5,5) circle (1.5pt);
            
            \draw (1,5) -- (1,1);
            \node at (1,5.35) {$(-1,1)$};
            \filldraw[black] (1,5) circle (1.5pt);
        \end{tikzpicture}
        \captionof{figure}{The reference quadrilateral $\widehat{Q}$.}
        \label{fig:reference_quad}
    \end{minipage}
\end{figure}

We assume that the bijective mappings are the simplest possible,
that is, linear interpolations of the coordinates of the element's vertices.
Let us construct these first for $\widehat{E} = \widehat{T}$.
Corresponding to each vertex, i.e.\ node, of the reference triangle,
define the nodal shape functions
\begin{align}
    \label{eq:tri_nodal_shape_start}
    &L_1(\hat{x}_1,\hat{x}_2) = 1 - \widehat{x}_1 - \widehat{x}_2 \\[0.5em]
    &L_2(\hat{x}_1,\hat{x}_2) = \widehat{x}_1 \\[0.5em]
    \label{eq:tri_nodal_shape_end}
    &L_3(\hat{x}_1,\hat{x}_2) = \widehat{x}_2.
\end{align}
The mapping $F$ is now defined by
\begin{equation}
    \label{eq:tri_element_map}
    F(\hat{x}) = \sum_{i=1}^{3} L_i(\hat{x}) V_i,
\end{equation}
where $V_i$ are the coordinates of the vertices of the triangle $T$
in counterclockwise order.

When $\widehat{E} = \widehat{Q}$, we similarly define the nodal shape functions
\begin{align}
    \label{eq:quad_nodal_shape_start}
    &N_1(\hat{x}_1,\hat{x}_2) = \frac{1}{4}(1 - \hat{x}_1)(1 - \hat{x}_2) \\[0.5em]
    &N_2(\hat{x}_1,\hat{x}_2) = \frac{1}{4}(1 + \hat{x}_1)(1 - \hat{x}_2) \\[0.5em]
    &N_3(\hat{x}_1,\hat{x}_2) = \frac{1}{4}(1 + \hat{x}_1)(1 + \hat{x}_2) \\[0.5em]
    \label{eq:quad_nodal_shape_end}
    &N_4(\hat{x}_1,\hat{x}_2) = \frac{1}{4}(1 - \hat{x}_1)(1 + \hat{x}_2).
\end{align}
The mapping $F$ is then defined by
\begin{equation}
    \label{eq:quad_element_map}
    F(\hat{x}) = \sum_{i=1}^{4} N_i(\hat{x}) V_i,
\end{equation}
where $V_i$ are the coordinates of the vertices of the quadrilateral $Q$
in counterclockwise order.

It is easy to show that
the triangle element mapping \eqref{eq:tri_element_map}
corresponds to an affine mapping $F(\hat{x}) = A\hat{x} + b$
for some non-singular matrix $A \in \mathbb{R}^{2 \times 2}$
and translation vector $b \in \mathbb{R}^{2}$, which is obviously bijective.
When the quadrilateral corresponds to a parallelogram,
the mapping \eqref{eq:quad_element_map} also corresponds to an affine
mapping, but for a general quadrilateral, the mapping 
\eqref{eq:quad_element_map} is only bilinear and the invertibility is not obvious.
It turns out that the mapping \eqref{eq:quad_element_map} is bijective
if and only if the quadrilateral $Q$ is convex \cite[p.\ 158]{strang1973}.
Thus, we assume that quadrilateral elements are always convex.

For each $i=1,2,\dotsc,N(\mathcal{M})$,
let $F_i: \widehat{E_i} \to E_i$ be the bijective mapping as defined above.
The finite element space $S$ is now defined by
\begin{align}
    S
    &= S(\Omega, \mathcal{M}, p) \nonumber \\
    \label{eq:fem_space}
    &= \{
        u \in C(\overline{\Omega})
            : u \circ F_i \in \mathcal{P}_p(\widehat{E_i}),
                \text{ } i=1,2,\dotsc,N(\mathcal{M}),
                    \text{ } Bu = 0
    \},
\end{align}
where $\mathcal{P}_p(\widehat{E})$ is the space of
bivariate polynomials of degree $p \in \mathbb{N}$
and $Bu=0$ corresponds to the homogeneous Dirichlet boundary
conditions or, in the case of only Neumann boundary conditions,
to the zero mean-value requirement.

There is some ambiguity in the definition of the space 
$\mathcal{P}_p(\widehat{E})$ regarding the degree $p$ and whether
$\widehat{E} = \widehat{T}$ or $\widehat{E} = \widehat{Q}$.
The degree $p$ of the polynomials has at least two possible interpretations.
For this consider a monomial $x_1^i x_2^j$.
The degree $p$ can be interpreted as the total degree,
i.e.\ $0 \leq i + j \leq p$,
or it can be interpreted as the degree of each independent variable,
i.e.\ $0 \leq i \leq p$ and $0 \leq j \leq p$.
Using the terminology in \cite{szabobabuska2011},
the former interpretation is the trunk polynomial space
and the latter is the product polynomial space, and we denote them by
$\mathcal{P}_p^{(tr)}(\widehat{E})$ and
$\mathcal{P}_p^{(pr)}(\widehat{E})$, respectively.
In the case of quadrilaterals, the trunk space $\mathcal{P}_p^{(tr)}(\widehat{Q})$
is modified by supplementing it with the monomials $x_1^p x_2$ and $x_1 x_2^p$.
This makes the construction of a suitable basis
for $\mathcal{P}_p^{(tr)}(\widehat{Q})$ easier as the monomial basis
is not particularly apt to practical applications.
All in all, we consider three instances of the polynomial space
$\mathcal{P}_p(\widehat{E})$, and they are illustrated in
Figure~\ref{fig:pascal_tri_polynomials}.

The basis of the polynomial space $\mathcal{P}_p(\widehat{E})$
should be chosen so that it is easy to construct a basis for the
finite element space $S$ in \eqref{eq:fem_space} which is then used to construct
the stiffness matrix $K$. We defer the presentation of the explicit
forms of the basis functions to
Section~\ref{sec:finite_element_solutions_with_a_concentrated_load},
but the idea is to divide the basis of $\mathcal{P}_p(\widehat{E})$
into two types of basis functions: external and internal.
An internal basis function vanishes on the boundary $\partial \widehat{E}$
which then defines a basis function for the space $S$
after mapping it via the element map and extending it by zero to the rest
of the domain $\Omega$.
An external basis function admits non-zero values on some part of the boundary
which then needs to be matched with the corresponding
external basis functions of the neighboring elements.
For example, the nodal shape functions in
\eqref{eq:tri_nodal_shape_start}-\eqref{eq:tri_nodal_shape_end}
and \eqref{eq:quad_nodal_shape_start}-\eqref{eq:quad_nodal_shape_end}
are non-zero at one vertex and on two adjacent edges. Similarly,
an edge basis function vanishes on all but one edge.
As a consequence, the supports of the basis functions of the space
$S$ span at most four elements, which simplifies the construction
of the stiffness matrix $K$ and makes it sparse.

We assumed earlier that the finite element space $S$ is a subspace of
an arbitrary Sobolev space $W^{1,q}(\Omega)$ for some $1 \leq q < \infty$ and,
in particular, of $H^1(\Omega)$ so that the stiffness matrix $K$
is guaranteed to be non-singular.
This assumption is now indeed true.
\begin{theorem}
    \label{thm:fem_space_is_sobolev}
    Let the space $S$ be defined by \eqref{eq:fem_space}.
    Then $S \subset W^{1,q}(\Omega)$ for all $1 \leq q < \infty$.
\end{theorem}
\begin{proof}
    Let $u \in S$ and $1 \leq q < \infty$.
    Obviously, $u \circ F_i \in W^{1,q}(\widehat{E_i})$ for all $i=1,2,\dotsc,N$.
    The mappings $F_i$ and their inverses $F_i^{-1}$ are smooth with bounded
    partial derivatives of arbitrary order in $\widehat{E_i}$ and $E_i$,
    respectively. Now by \cite[Theorem 1 on p.\ 13]{mazya2011},
    $v_i = u|_{E_i} \in W^{1,q}(E_i)$ for all $i=1,2,\dotsc,N$,
    i.e.\ the change of variables via $F_i$ preserves the Sobolev spaces.
    
    Let us show that for both $j=1$ and $j=2$ the weak partial derivative
    $D_j u$ is given by $(D_j u)|_{E_i} = D_j v_i$ for all $i=1,2,\dotsc,N$.
    The edges of the elements have zero $2$-dimensional Lebesgue measure
    so the values of $D_j u$ on the edges can be defined arbitrarily.

    Let $N_e$ denote the number of interior edges in the mesh $\mathcal{M}$,
    and denote the individual interior edges by $\gamma_k$ for
    $k = 1,2,\dotsc,N_e$. As previously, the boundary edges are
    denoted by $\Gamma_k$ for $k = 1,2,\dotsc,J$.
    Let $N_{e,i}$ denote the number of edges in the element $E_i$,
    and denote the individual edges by
    $\gamma_{k,i}$ for $k=1,2,\dotsc,N_{e,i}$.
    Let $\varphi \in C_0^{\infty}(\Omega)$. Now
    \begin{align*}
        \int_{\Omega} u D_j \varphi \diff x
        &= \sum_{i=1}^{N} \int_{E_i} v_i D_j \varphi \diff x \\
        &= \sum_{i=1}^{N} \left(
                - \int_{E_i} D_j v_i \varphi \diff x    
                + \sum_{k=1}^{N_{e,i}}
                    \int_{\gamma_{k,i}} v_i \varphi n_j \diff S
            \right) \\
        &= - \sum_{i=1}^{N} \int_{E_i} D_j v_i \varphi \diff x
            + \sum_{k=1}^{J} \int_{\Gamma_k} u \varphi n_j \diff S
            + \sum_{k=1}^{N_e} \int_{\gamma_k} u \varphi (n_j - n_j) \diff S \\
        &= - \sum_{i=1}^{N} \int_{E_i} D_j v_i \varphi \diff x \\
        &= - \int_{\Omega} D_j u \varphi \diff x.
    \end{align*}
    We used above the observation that for each interior edge there exist two
    corresponding boundary integrals and the function $u$ is continuous
    over each edge so the two boundary integrals cancel each other out.
    We also used the fact that $\varphi$ vanishes on each boundary segment
    $\Gamma_k$.

    The integrability condition in $W^{1,q}(\Omega)$ is easy to prove:
    \begin{equation*}
        \norm{u}_{W^{1,q}(\Omega)}^q
        = \sum_{i=1}^{N} \norm{u}_{W^{1,q}(E_i)}^q
        = \sum_{i=1}^{N} \norm{v_i}_{W^{1,q}(E_i)}^q
        < \infty.
    \end{equation*}
    Thus, $u \in W^{1,q}(\Omega)$.
\end{proof}

The following definition summarizes what we mean by a finite element
solution to the problem \eqref{eq:fem_departure}.
\begin{definition}
    \label{def:fem_solution}
    Let the space $S$ be defined by \eqref{eq:fem_space}.
    We say that $u_S \in S$ is a finite element solution to the
    elliptic second-order boundary value problem \eqref{eq:fem_departure}
    if it satisfies
    \begin{equation*}
        a(u_S,v) = \varphi(v)
    \end{equation*}
    for all $v \in S$.
\end{definition}

The difference between the exact solution $u \in U$
and the finite element solution $u_S \in S$ is measured
in a suitable Sobolev norm, a suitable Lebesgue norm
or the $L^{\infty}(\Omega)$-norm.
There are three commonly used strategies in controlling the error
of the approximate solutions: making the mesh more refined,
increasing the degree $p$ of the polynomials,
or using a combination of both of these strategies.
In the common FEM nomenclature,
these three strategies are called the $h$-, $p$- and $hp$-version
of the finite element method, respectively.

The parameter $h$ is usually defined as
\begin{equation*}
    h = \max_{E \in \mathcal{M}} h_E,
\end{equation*}
where $h_E$ is the diameter of the smallest sphere that contains the element $E$.
By making the mesh more refined, the largest diameter $h$
becomes smaller and, hopefully, the quality of the finite element solution
is improved. Convergence analysis of the $h$-version attempts to
describe how the error behaves as $h \to 0$.
To make this analysis feasible, the refinements of the mesh are usually
assumed to satisfy some regularity condition. For example, letting
$\rho_E$ denote the diameter of the largest sphere contained in the element $E$,
a collection of meshes $\{ \mathcal{M}_h \}_{h > 0}$
is said to be shape-regular if there exists
a constant $\tau > 0$ independent of $h$ such that
\begin{equation*}
    \frac{h_E}{\rho_E} \leq \tau
\end{equation*}
for every element $E \in \mathcal{M}_h$
and every mesh $\mathcal{M}_h \in \{ \mathcal{M}_h \}_{h > 0}$.
It is also common to use polynomials that have a low degree, e.g.\ $p=1$ or $p=2$.
The $h$-version is the classical version of the finite element method,
and it is the main topic of several standard text books,
see e.g.\ \cite{ciarlet2002}, \cite{braess2007}, \cite{scottbrenner2007}.

In the $p$-version, the quality of the approximation is improved
by increasing the degree $p$ of the polynomials while the mesh is kept fixed.
The error should near zero as $p \to \infty$.
The $hp$-version refines the mesh and increases the degree of the polynomials
at the same time, which can boost the rate of convergence.
The mathematical foundations of the $p$- and $hp$-versions
were developed after the $h$-version.
For references on the $p$-version, see e.g.\
\cite{babuskaszabokatz1981}, \cite{dorr1984}, \cite{babuskasuri1987},
\cite{szabo2004}.
For references on the $hp$-version, see e.g.\
\cite{babuskadorr1981}, \cite{guo1986}, \cite{babuskasuri1987hp},
\cite{babuskasuri1994}.
For a text book on both the $p$- and $hp$-versions, see \cite{schwab1998}.

There exist several extensions to the finite element method.
Instead of elliptic second-order boundary value problems,
one could consider other types of boundary value problems.
Instead of two-dimensional polygonal domains,
one could consider e.g.\ three-dimensional curved domains with curvilinear elements.
Instead of using the same degree $p$ in every element, one could choose them
on an element-by-element basis if the approximation needs to be more accurate
in some specific subdomain only. Some of these generalizations
are discussed in \cite{szabobabuska2011},
but we shall not consider them any further.

\subsection{Convergence of the \texorpdfstring{$p$}{p}-Version of the Finite Element Method}
\label{subsec:convergence_properties_of_the_p_version}

We recall that
the main goal of this thesis is to study the convergence of the $p$-version
of the finite element method when applied to Poisson's equation with
the Dirac delta load. As in Section~\ref{sec:poissons_equation_in_a_polygon}
regarding the solvability of the weak problems, we carry out the convergence
analysis in two phases. In the first phase, we consider the more common case of
an elliptic boundary value problem with an $L^2(\Omega)$ load term, i.e.\
the Hilbert space formulation in $H^1(\Omega)$.
In the second phase, the convergence results of the first phase
are then applied to the Dirac delta problem via a clever duality
argument by Casas \cite{casas1985}.
The rest of this section is concerned with the first phase only,
and it is purely theoretical.
The second phase is covered in the next section
alongside the numerical analysis.

\subsubsection{Céa's Lemma}
\label{subsubsec:ceas_lemma}

We have seen that the finite element method is a rather complicated
process with a lot of varying factors such as the mesh and the degree $p$
of the polynomials. Trying to measure the error between the exact solution
and the finite element solution directly is unwieldy and difficult.
It does, however, seem reasonable that the error should be related to the space $S$
in how well $S$ approximates the full ambient space.
When the elliptic weak problem is set in a Hilbert space,
this is indeed the case, and it can be stated precisely via
Céa's lemma by Jean Céa \cite{cea1964}.
\begin{theorem}[Céa's lemma]
    \label{thm:ceas_lemma}
    Let $V$ be a Hilbert space,
    $a: V \times V \to \mathbb{R}$ an elliptic bounded bilinear mapping
    and $\varphi \in V'$.
    Let $u \in V$ be the unique vector that satisfies
    \begin{equation*}
        a(u,v) = \varphi(v)
    \end{equation*}
    for all $v \in V$.
    Let $S$ be a non-empty closed subspace of $V$,
    and let $u_S \in S$ be the unique vector that satisfies
    \begin{equation*}
        a(u_S,v) = \varphi(v)
    \end{equation*}
    for all $v \in S$.
    Then there exists a constant $C > 0$ dependent only on the bilinear mapping
    such that
    \begin{equation*}
        \norm{u - u_S}_V \leq C \inf_{v \in S} \norm{u - v}_V.
    \end{equation*}
\end{theorem}
\begin{proof}
    We begin by observing that for all $v \in S$ it holds that
    \begin{equation*}
        a(u-u_S,v) = a(u,v) - a(u_S,v) = \varphi(v) - \varphi(v) = 0.
    \end{equation*}
    This property is commonly called Galerkin orthogonality.

    Let $v \in S$.
    By the ellipticity of $a$, the Galerkin orthogonality property
    and the boundedness of $a$, we get that
    \begin{align*}
        \norm{u-u_S}_V^2
        &\leq \frac{1}{\alpha} a(u-u_S,u-u_S) \\
        &= \frac{1}{\alpha} a(u-u_S,u-v) \\
        &\leq \frac{C}{\alpha} \norm{u-u_S}_V \norm{u-v}_V.
    \end{align*}
    Dividing both sides by $\norm{u-u_S}_V$
    and taking the infimum over all $v \in S$,
    the claim follows.
\end{proof}

Substituting above for example $V = H_0^1(\Omega)$,
Céa's lemma now states that the error between the exact solution
and the finite element solution in the $H^1(\Omega)$-norm
is comparable to the general approximation properties of
the finite element space $S$. For the $p$-version,
this corresponds to the general approximation properties of polynomials
with respect to the degree $p$.

\subsubsection{Approximation Properties of Polynomials}
\label{subsubsec:approximation_properties_of_polynomials}

We begin with the approximation properties of polynomials in one dimension,
after which we consider the two-dimensional setting.
The one-dimensional analysis is based on the Legendre series
for which we refer to \cite{schwab1998} and \cite{andrews1998}.

Let $I = (-1,1) \subset \mathbb{R}$ and $u \in L^2(I)$.
The Legendre series of $u$ is given by
\begin{equation}
    \label{eq:legendre_series}
    u(x) = \sum_{i=0}^{\infty} a_i P_i(x),
\end{equation}
where $P_i$ is the Legendre polynomial of degree $i$.
The Legendre polynomials can be defined via the recursive formula
\begin{equation*}
    P_{i+1}(x) = \frac{2i+1}{i+1} x P_i(x) - \frac{i}{i+1} P_{i-1}(x),
\end{equation*}
where $P_0(x)=1$ and $P_1(x)=x$. Clearly, $P_i \in \mathcal{P}_i(I)$.

The Legendre polynomials satisfy a useful orthogonality property:
\begin{equation*}
    \int_{-1}^{1} P_i(x) P_j(x) \diff x =
    \begin{cases}
        \frac{2}{2i+1}, & \text{if } i = j \\
        0, & \text{otherwise}.
    \end{cases}
\end{equation*}
Multiplying \eqref{eq:legendre_series} by $P_j$ and integrating
both sides over $I$, the orthogonality implies that
the coefficients of the series are given by
\begin{equation*}
    a_i = \frac{2i+1}{2} \int_{-1}^{1} u(x) P_i(x) \diff x.
\end{equation*}

Convergence of the series \eqref{eq:legendre_series} can always be understood
in the sense of $L^2$. That is, it holds that
\begin{equation*}
    \lim_{n \to \infty} \norm{u - \sum_{i=0}^{n} a_i P_i}_{L^2(I)} = 0.
\end{equation*}
This implies that the series convergences pointwise
almost everywhere in $I$. If $u$ has a continuous derivative,
then pointwise convergence holds everywhere in $I$.

When $u \in H^2(I)$, we have the following polynomial approximation theorem.
The same result can be found in \cite[Lemma 3.3]{babuskasuri1987},
except for the estimate in $L^{\infty}(I)$.
\begin{theorem}
    \label{thm:polynomial_approximation_1d}
    Let $u \in H^2(I)$ and $p \in \mathbb{N}$.
    Then there exists a $u_p \in \mathcal{P}_p(I)$ such that
    \begin{equation}
        \label{eq:polynomial_approximation_1d_endpoint_equality}
        u(\pm 1) = u_p(\pm 1)
    \end{equation}
    and
    \begin{align}
        \label{eq:polynomial_approximation_1d_res1}
        &\norm{u-u_p}_{L^2(I)} \leq C p^{-2} A(u), \\[0.5em]
        \label{eq:polynomial_approximation_1d_res2}
        &\norm{u-u_p}_{H^1(I)} \leq C p^{-1} A(u), \\[0.5em]
        \label{eq:polynomial_approximation_1d_res3}
        &\norm{u-u_p}_{L^{\infty}(I)} \leq C p^{-1} A(u),
    \end{align}
    where
    \begin{equation*}
        A(u) = \left(
            \int_{-1}^{1} \abs{u''(x)}^2 (1-x^2) \diff x
            \right)^{\frac{1}{2}}.
    \end{equation*}
    The constant $C > 0$ is independent of $u$ and $p$.
\end{theorem}
\begin{proof}
    Let $u_p' \in \mathcal{P}_{p-1}(I)$ be the truncated Legendre series
    of $u'$, i.e.\
    \begin{equation*}
        u_p'(x) = \sum_{i=0}^{p-1} b_i P_i(x),
    \end{equation*}
    where
    \begin{equation*}
        b_i = \frac{2i+1}{2} \int_{-1}^{1} u'(x) P_i(x) \diff x.
    \end{equation*}
    By \cite[Theorem 3.10 on p.\ 71]{schwab1998},
    $A(u)$ and the coefficients $b_i$ are related by
    \begin{equation}
        \label{eq:eq:polynomial_approximation_1d_A}
        A(u)^2
        = \int_{-1}^{1} \abs{u''(x)}^2 (1-x^2) \diff x
        = \sum_{i=1}^{\infty} \frac{2}{2i+1} \frac{(i+1)!}{(i-1)!} \abs{b_i}^2.
    \end{equation}
    
    Define $u_p \in \mathcal{P}_p(I)$ by
    \begin{equation*}
        u_p(x) = \int_{-1}^{x} u_p'(y) \diff y + u(-1).
    \end{equation*}
    By \cite[Theorem 3.14 on p.\ 73]{schwab1998},
    $u_p$ satisfies \eqref{eq:polynomial_approximation_1d_endpoint_equality} and
    \begin{align*}
        \norm{u-u_p}_{L^2(I)}^2
            &\leq \sum_{i=p}^{\infty} \frac{2}{i(i+1)(2i+1)} \abs{b_i}^2, \\[0.5em]
        \abs{u-u_p}_{H^1(I)}^2
            &= \sum_{i=p}^{\infty} \frac{2}{2i+1} \abs{b_i}^2.
    \end{align*}

    Let us estimate $\abs{u-u_p}_{H^1(I)}^2$.
    \begin{align*}
        \abs{u-u_p}_{H^1(I)}^2
        &= \sum_{i=p}^{\infty} \frac{2}{2i+1} \abs{b_i}^2 \\
        &= \sum_{i=p}^{\infty} \frac{2}{2i+1}
            \frac{(i-1)!}{(i+1)!} \frac{(i+1)!}{(i-1)!}
            \abs{b_i}^2 \\
        &\leq p^{-2} \sum_{i=p}^{\infty} \frac{2}{2i+1}
            \frac{(i+1)!}{(i-1)!} \abs{b_i}^2 \\
        &= p^{-2} A(u)^2.
    \end{align*}
    The estimate follows from \eqref{eq:eq:polynomial_approximation_1d_A}
    and the inequality
    \begin{equation*}
        \frac{(i-1)!}{(i+1)!}
        = \frac{1}{(i+1)i}
        \leq p^{-2}
    \end{equation*}
    for $i \geq p$. Now quite similarly, we get the following estimate
    for $\norm{u-u_p}_{L^2(I)}^2$.
    \begin{align*}
        \norm{u-u_p}_{L^2(I)}^2
        &\leq \sum_{i=p}^{\infty} \frac{2}{i(i+1)(2i+1)} \abs{b_i}^2 \\
        &\leq p^{-2} \sum_{i=p}^{\infty} \frac{2}{2i+1} \abs{b_i}^2 \\
        &\leq p^{-4} A(u)^2.
    \end{align*}
    This proves \eqref{eq:polynomial_approximation_1d_res1}.
    By combining the above two estimates, we get that
    \begin{align*}
        \norm{u-u_p}_{H^1(I)}^2
        &= \norm{u-u_p}_{L^2(I)}^2 + \abs{u-u_p}_{H^1(I)}^2 \\
        &\leq p^{-4} A(u)^2 + p^{-2} A(u)^2 \\
        &\leq 2 p^{-2} A(u)^2,
    \end{align*}
    which proves \eqref{eq:polynomial_approximation_1d_res2}.

    It remains to prove \eqref{eq:polynomial_approximation_1d_res3}.
    Let $x \in I$. By the fundamental theorem of calculus
    and the definition of $u_p'$, we get that
    \begin{align}
        u(x) - u_p(x)
        &= \int_{-1}^{x} u'(y) - u_p'(y) \diff y \nonumber \\
        &= \int_{-1}^{x} \sum_{i=p}^{\infty} b_i P_i(y) \diff y \nonumber \\
        \label{eq:polynomial_approximation_1d_pointwise_intmed1}
        &= \sum_{i=p}^{\infty} b_i \int_{-1}^{x} P_i(y) \diff y.
    \end{align}
    By \cite[p. 151]{andrews1998}, the Legendre polynomials satisfy
    \begin{equation*}
        P_i(y) = \frac{1}{2i+1} (P_{i+1}'(y) - P_{i-1}'(y))
    \end{equation*}
    for all $i=1,2,\dotsc$. We may thus compute the integral in
    \eqref{eq:polynomial_approximation_1d_pointwise_intmed1} as
    \begin{align}
        \int_{-1}^{x} P_i(y) \diff y
        &= \frac{1}{2i+1} \int_{-1}^{x} P_{i+1}'(y) - P_{i-1}'(y) \diff y \nonumber \\
        \label{eq:polynomial_approximation_1d_pointwise_intmed2}
        &= \frac{1}{2i+1} (P_{i+1}(x) - P_{i-1}(x)),
    \end{align}
    where we also used the property of the Legendre polynomials that
    $P_i(-1) = (-1)^i$ for all $i=0,1,\dotsc$.
    The Legendre polynomials satisfy $\abs{P_i(x)} \leq 1$ for all $x \in I$
    and $i=0,1,\dotsc$, which now implies together with
    \eqref{eq:polynomial_approximation_1d_pointwise_intmed1}
    and \eqref{eq:polynomial_approximation_1d_pointwise_intmed2}
    the pointwise estimate
    \begin{align*}
        \abs{u(x) - u_p(x)}
        &\leq \sum_{i=p}^{\infty} \abs{b_i} \frac{1}{2i+1}
            (\abs{P_{i+1}(x)} + \abs{P_{i-1}(x)}) \\
        &\leq \sum_{i=p}^{\infty} \frac{2}{2i+1} \abs{b_i} \\
        &= \sum_{i=p}^{\infty}
            \left(
                \left( \frac{2}{2i+1} \right)^{\frac{1}{2}}
                \left( \frac{(i-1)!}{(i+1)!} \right)^{\frac{1}{2}}
            \right)
            \left(
                \left( \frac{2}{2i+1} \right)^{\frac{1}{2}}
                \left( \frac{(i+1)!}{(i-1)!} \right)^{\frac{1}{2}}
                \abs{b_i}
            \right).
    \end{align*}
    Hölder's inequality and the definition of $A(u)$ imply that
    \begin{align}
        \abs{u(x) - u_p(x)}^2
        &\leq \left( \sum_{i=p}^{\infty} \frac{2}{2i+1} \frac{(i-1)!}{(i+1)!}
            \right)
            \left( \sum_{i=p}^{\infty} \frac{2}{2i+1} \frac{(i+1)!}{(i-1)!} 
            \abs{b_i}^2 \right) \nonumber \\
        &\leq \left( \sum_{i=p}^{\infty} \frac{2}{2i+1} \frac{(i-1)!}{(i+1)!}
            \right)
            \left( \sum_{i=1}^{\infty} \frac{2}{2i+1} \frac{(i+1)!}{(i-1)!} 
            \abs{b_i}^2 \right) \nonumber \\
        \label{eq:polynomial_approximation_1d_pointwise_intmed3}
        &= \left( \sum_{i=p}^{\infty} \frac{2}{2i+1} \frac{(i-1)!}{(i+1)!}
            \right) A(u)^2.
    \end{align}
    The remaining series has the following bound.
    \begin{align*}
        \sum_{i=p}^{\infty} \frac{2}{2i+1} \frac{(i-1)!}{(i+1)!}
        &= \sum_{i=p}^{\infty} \frac{2}{(2i+1)(i+1)i} \\
        &\leq \sum_{i=p}^{\infty} i^{-3} \\
        &\leq p^{-3} + \int_{p}^{\infty} t^{-3} \diff t \\
        &= p^{-3} + \frac{1}{2} p^{-2} \\
        &\leq \frac{3}{2} p^{-2}.
    \end{align*}
    This implies with \eqref{eq:polynomial_approximation_1d_pointwise_intmed3} that
    \begin{equation*}
        \abs{u(x) - u_p(x)}^2
        \leq \frac{3}{2} p^{-2} A(u)^2
    \end{equation*}
    for all $x \in I$, which then finally implies 
    \eqref{eq:polynomial_approximation_1d_res3}.
\end{proof}

Theorem~\ref{thm:polynomial_approximation_1d}
has a two-dimensional counterpart for the reference quadrilateral
and the reference triangle.
The polynomial space is assumed to be the product space for the quadrilateral
and the trunk space for the triangle. This assumption will be relaxed later.
\begin{theorem}
    \label{thm:polynomial_approximation_2d}
    Let $\widehat{E} = \widehat{Q}$ (resp.\ $\widehat{E} = \widehat{T}$).
    Let $u \in H^2(\widehat{E})$ and $p \in \mathbb{N}$.
    Then there exists a $u_p \in \mathcal{P}_p^{(pr)}(\widehat{Q})$
    (resp.\ $u_p \in \mathcal{P}_p^{(tr)}(\widehat{T})$) such that
    \begin{align}
        \label{eq:polynomial_approximation_2d_res1}
        \norm{u-u_p}_{H^1(\widehat{E})}
        &\leq C p^{-1} \norm{u}_{H^2(\widehat{E})}, \\[0.5em]
        \label{eq:polynomial_approximation_2d_res2}
        \norm{u-u_p}_{L^{\infty}(\widehat{E})}
        &\leq C p^{-1} \norm{u}_{H^2(\widehat{E})}, \\[0.5em]
        \label{eq:polynomial_approximation_2d_res3}
        \norm{u-u_p}_{L^2(\gamma)}
        &\leq C p^{-3/2} \norm{u}_{H^2(\widehat{E})}, \\[0.5em]
        \label{eq:polynomial_approximation_2d_res4}
        \norm{u-u_p}_{H^1(\gamma)}
        &\leq C p^{-1/2} \norm{u}_{H^2(\widehat{E})},
    \end{align}
    where $\gamma$ is any edge of $\widehat{E}$
    and the constant $C > 0$ is independent of $u$ and $p$.
\end{theorem}
\begin{proof}
    The proof for the case $\widehat{E} = \widehat{Q}$
    can be found in \cite[Lemma 3.1]{babuskasuri1987},
    where the result follows from the approximation properties
    of truncated Fourier series.

    Let us use the result for the quadrilateral
    and extend it to the case $\widehat{E} = \widehat{T}$.
    We do this by
    dividing the quadrilateral $\widehat{Q}$ into two triangles
    along the diagonal line $x_2 = x_1$.
    Let $\widetilde{T}$ denote the resulting bottom triangle,
    and let $F: \widehat{T} \to \widetilde{T}$ be a bijective affine mapping
    between the reference triangle and the bottom triangle.
    
    Define $\tilde{u} = u \circ F^{-1} \in H^2(\widetilde{T})$.
    By \cite[Theorem 5 on p.\ 181]{stein1970},
    there exists an extension $\tilde{U} \in H^2(\widehat{Q})$ of $\tilde{u}$
    such that $\tilde{U}|_{\widetilde{T}} = \tilde{u}$ and
    \begin{equation}
        \label{eq:polynomial_approximation_2d_extension_continuity}
        \norm{\tilde{U}}_{H^2(\widehat{Q})}
        \leq C_1 \norm{\tilde{u}}_{H^2(\widetilde{T})},
    \end{equation}
    where the constant $C_1$ is independent of $\tilde{u}$ (and of $u$ and $p$).

    Assume for now that $p \geq 2$.
    If $p$ is even, let $q = p/2 \in \mathbb{N}$,
    and if $p$ is odd, let $q = (p-1)/2 \in \mathbb{N}$.
    Now there exists a $\tilde{U}_q \in \mathcal{P}_q^{(pr)}(\widehat{Q})
    \subset \mathcal{P}_p^{(tr)}(\widehat{Q})$
    such that $\tilde{U}$ and $\tilde{U}_q$ satisfy
    \eqref{eq:polynomial_approximation_2d_res1}-\eqref{eq:polynomial_approximation_2d_res4}.
    
    Let $\tilde{u}_p \in \mathcal{P}_p^{(tr)}(\widetilde{T})$
    be the restriction of $\tilde{U}_q$ to $\widetilde{T}$.
    Using \eqref{eq:polynomial_approximation_2d_extension_continuity},
    we may now prove
    \eqref{eq:polynomial_approximation_2d_res1}-\eqref{eq:polynomial_approximation_2d_res4}
    for $\tilde{u}$ and $\tilde{u}_p$ in the triangle $\widetilde{T}$.
    For example,
    \begin{align*}
        \norm{\tilde{u}-\tilde{u}_p}_{H^1(\widetilde{T})}
        &\leq \norm{\tilde{U}-\tilde{U}_q}_{H^1(\widehat{Q})} \\
        &\leq C q^{-1} \norm{\tilde{U}}_{H^2(\widehat{Q})} \\
        &\leq 4C p^{-1} \norm{\tilde{U}}_{H^2(\widehat{Q})} \\
        &\leq 4C C_1 p^{-1} \norm{\tilde{u}}_{H^2(\widetilde{T})}.
    \end{align*}
    The other estimates follow more or less analogously.
    Regarding the edge of $\widetilde{T}$
    corresponding to the diagonal line $x_2=x_1$,
    it is shown in \cite[Lemma 3.1]{babuskasuri1987} that
    \eqref{eq:polynomial_approximation_2d_res3}
    and \eqref{eq:polynomial_approximation_2d_res4}
    hold for it as well when $\widehat{E} = \widehat{Q}$.

    The result for the case $\widehat{E} = \widehat{T}$
    now follows by applying the affine coordinate transformation $F$
    to $\tilde{u}$ and $\tilde{u}_p$.
    The resulting approximation $u_p = \tilde{u}_p \circ F$
    belongs to the trunk polynomial space $\mathcal{P}_p^{(tr)}(\widehat{T})$
    because an affine mapping preserves polynomials.

    If $p=1$, we can simply choose
    $u_p = 0 \in \mathcal{P}_{1}^{(tr)}(\widehat{T})$, and the estimates
    \eqref{eq:polynomial_approximation_2d_res1}-\eqref{eq:polynomial_approximation_2d_res4}
    follow from the Sobolev imbedding theorems and the trace theorem.
\end{proof}

Notice that the approximations $u_p \in \mathcal{P}_{p}^{(tr)}(\widehat{T})$
in Theorem~\ref{thm:polynomial_approximation_2d} were constructed
so that the constant $C$ is not necessarily the most optimal one.
For the case $p=1$, we even set $u_p = 0$, which is most often useless
in practice. Theorem~\ref{thm:polynomial_approximation_2d}
does not provide precise error bounds, but it enables us to consider
whether the approximations converge as $p \to \infty$.

\subsubsection{Approximation Properties of the Finite Element Space}
\label{subsubsec:approximation_properties_of_the_finite_element_space}

We defined the finite element space by
\begin{align*}
    S
    &= S(\Omega, \mathcal{M}, p) \\
    &= \{
        u \in C(\overline{\Omega})
            : u \circ F_i \in \mathcal{P}_p(\widehat{E_i}),
                \text{ } i=1,2,\dotsc,N(\mathcal{M}),
                    \text{ } Bu = 0
    \},
\end{align*}
where $\mathcal{P}_p(\widehat{E_i})$ is either the product space or the trunk space.

With the aid of the approximation results above,
our next objective is to show that for any $u \in H^2(\Omega)$
that satisfies the boundary condition $Bu=0$
there exists a $u_p \in S$ such that
\begin{equation}
    \label{eq:fem_conv_goal1}
    \norm{u-u_p}_{H^1(\Omega)}
    \leq C p^{-1} \norm{u}_{H^2(\Omega)},
\end{equation}
where the constant $C > 0$ is independent of $u$ and $p$.
Then Céa's lemma immediately implies the same error estimate
for the $p$-version of the finite element method given that
the exact solution of the elliptic second-order boundary value problem
belongs to $H^2(\Omega)$. The same estimate can be found in
e.g.\ \cite{babuskasuri1987} and \cite{babuskasuri1987hp}.

We also prove the estimate
\begin{equation}
    \label{eq:fem_conv_goal2}
    \norm{u-u_p}_{L^{\infty}(\Omega)}
    \leq C p^{-1} \norm{u}_{H^2(\Omega)}
\end{equation}
which enables us to prove convergence in the $L^{\infty}(\Omega)$-norm.

To construct a $u_p \in S$ such that \eqref{eq:fem_conv_goal1}
and \eqref{eq:fem_conv_goal2} hold, we employ the same approach that
is used in \cite{babuskasuri1987}. The idea is to first use
Theorem~\ref{thm:polynomial_approximation_2d} element-wise,
but the resulting approximation is not necessarily continuous.
In other words, it does not yet necessarily belong to the space $S$.
The element-wise approximations need to be stitched together
over the edges of the elements. This is achieved by adding
suitable auxiliary functions to each element-wise approximation.
Even if the mesh consists of only one element,
possible Dirichlet boundary conditions need to be fixed as well,
which can be achieved with the same strategy.
We consider these auxiliary functions first.

There are two main types of auxiliary functions.
The first is used to fix the values at the vertices of the mesh,
and the second is used to fix the values at the edges
after the vertices have been fixed.
There is also a third auxiliary function type that is used
in the construction of the main auxiliary functions,
and it is given by the following theorem.
The original constructions can be found in \cite{babuskasuri1987},
and we consider them mostly without modifications. One addition is that
we also consider the $L^{\infty}$-norms of the functions.
\begin{theorem}
    \label{thm:auxiliary_auxiliary_function}
    Let $I=(-1,1) \subset \mathbb{R}$ and $p \in \mathbb{N}$.
    Then there exists a $\psi_p \in \mathcal{P}_p(I)$ such that
    \begin{equation}
        \label{eq:auxiliary_auxiliary_function_endpoints}
        \psi_p(-1)=1 \quad \text{and} \quad \psi_p(1)=0
    \end{equation}
    and
    \begin{align}
        \label{eq:auxiliary_auxiliary_function_res1}
        &\norm{\psi_p}_{L^2(I)} \leq C p^{-1/2}, \\[0.5em]
        \label{eq:auxiliary_auxiliary_function_res2}
        &\norm{\psi_p}_{H^1(I)} \leq C p^{1/2}, \\[0.5em]
        \label{eq:auxiliary_auxiliary_function_res3}
        &\norm{\psi_p}_{L^{\infty}(I)} \leq C,
    \end{align}
    where the constant $C > 0$ is independent of $p$.
\end{theorem}
\begin{proof}
    Let
    \begin{equation*}
        \phi_p(x) = \frac{e^{-p(x+1)} - e^{-2p}}{1 - e^{-2p}}.
    \end{equation*}
    Clearly, $\phi_p(-1)=1$ and $\phi_p(1)=0$.
    Let us estimate the norms $\norm{\phi_p}_{L^2(I)}$,
    $\norm{\phi_p}_{H^1(I)}$ and $\norm{\phi_p}_{L^{\infty}(I)}$.

    For all $x \in I$, it holds that
    \begin{equation*}
       \abs{\phi_p(x)} \leq 2 e^{-p(x+1)}.
    \end{equation*}
    Now
    \begin{align*}
        \norm{\phi_p}_{L^2(I)}^2
        &\leq 4 \int_{-1}^{1} e^{-2p(x+1)} \diff x \\
        &= 2 p^{-1} (1 - e^{-4p}) \\
        &\leq 2 p^{-1}.
    \end{align*}
    That is, 
    \begin{equation}
        \label{eq:phi_p_L2}
        \norm{\phi_p}_{L^2(I)} \leq \sqrt{2} p^{-1/2}.
    \end{equation}

    The derivative of $\phi_p$ is given by
    \begin{equation*}
        \phi_p'(x) = \frac{-p e^{-p(x+1)}}{1 - e^{-2p}},
    \end{equation*}
    and it satisfies
    \begin{equation*}
        \abs{\phi_p'(x)} \leq 2 p e^{-p(x+1)}
    \end{equation*}
    for all $x \in I$. Now
    \begin{equation}
        \label{eq:phi_p_H1_semi}
        \abs{\phi_p}_{H^1(I)}^2
        \leq 4p^2 \int_{-1}^{1} e^{-2p(x+1)} \diff x
        \leq 2p,
    \end{equation}
    where the last inequality follows similarly as above.
    Combining \eqref{eq:phi_p_H1_semi} with \eqref{eq:phi_p_L2} yields
    \begin{equation}
        \label{eq:phi_p_H1}
        \norm{\phi_p}_{H^1(I)} \leq 2p^{1/2}.
    \end{equation}
    The function $\phi_p$ is strictly decreasing in $I$, which implies that
    \begin{equation}
        \label{eq:phi_p_Linfty}
        \norm{\phi_p}_{L^{\infty}(I)} \leq 1.
    \end{equation}

    By Theorem~\ref{thm:polynomial_approximation_1d},
    there exists a $\psi_p \in \mathcal{P}_p(I)$ such that
    \begin{equation*}
        \psi_p(-1) = \phi_p(-1) = 1
        \quad \text{and} \quad
        \psi_p(1) = \phi_p(1) = 0,
    \end{equation*}
    i.e.\ \eqref{eq:auxiliary_auxiliary_function_endpoints} holds, and
    \begin{align}
        \label{eq:phi_psi_L2}
        &\norm{\phi_p-\psi_p}_{L^2(I)} \leq C p^{-2} A(\phi_p), \\[0.5em]
        \label{eq:phi_psi_H1}
        &\norm{\phi_p-\psi_p}_{H^1(I)} \leq C p^{-1} A(\phi_p), \\[0.5em]
        \label{eq:phi_psi_Linfty}
        &\norm{\phi_p-\psi_p}_{L^{\infty}(I)} \leq C p^{-1} A(\phi_p),
    \end{align}
    where
    \begin{equation*}
        A(\phi_p) = \left(
            \int_{-1}^{1} \abs{\phi_p''(x)}^2 (1-x^2) \diff x
            \right)^{\frac{1}{2}}.
    \end{equation*}
    
    Let us estimate the term $A(\phi_p)$.
    The second derivative of $\phi_p$ is given by
    \begin{equation*}
        \phi_p''(x) = \frac{p^2 e^{-p(x+1)}}{1 - e^{-2p}},
    \end{equation*}
    and it satisfies
    \begin{equation*}
        \abs{\phi_p''(x)} \leq 2 p^2 e^{-p(x+1)}
    \end{equation*}
    for all $x \in I$. Now
    \begin{align*}
        A(\phi_p)^2
        &= 4 \int_{-1}^{1} p^4 e^{-2p(x+1)} (1-x^2) \diff x \\
        &\leq 4 \int_{-1}^{1} p^4 e^{-2p(x+1)} 2 (x+1) \diff x \\
        &= 8 p^4 \int_{0}^{2} e^{-2py} y \diff y \\
        &= 2 p^2 (1 - 4pe^{-4p} - e^{-4p}) \\
        &\leq 2p^2.
    \end{align*}
    That is, $A(\phi_p) \leq \sqrt{2} p$, and
    \eqref{eq:phi_psi_L2}-\eqref{eq:phi_psi_Linfty} become
    \begin{align}
        \label{eq:phi_psi_L2_new}
        &\norm{\phi_p-\psi_p}_{L^2(I)} \leq C p^{-1}, \\[0.5em]
        \label{eq:phi_psi_H1_new}
        &\norm{\phi_p-\psi_p}_{H^1(I)} \leq C, \\[0.5em]
        \label{eq:phi_psi_Linfty_new}
        &\norm{\phi_p-\psi_p}_{L^{\infty}(I)} \leq C,
    \end{align}
    where the constant $C > 0$ is independent of $p$.

    The estimates \eqref{eq:phi_p_L2} and \eqref{eq:phi_psi_L2_new}
    now imply the estimate \eqref{eq:auxiliary_auxiliary_function_res1}:
    \begin{equation*}
        \norm{\psi_p}_{L^2(I)}
        \leq \norm{\psi_p - \phi_p}_{L^2(I)} + \norm{\phi_p}_{L^2(I)} 
        \leq Cp^{-1} + \sqrt{2} p^{-1/2}
        \leq (C+\sqrt{2}) p^{-1/2}.
    \end{equation*}
    The estimates \eqref{eq:phi_p_H1} and \eqref{eq:phi_psi_H1_new}
    imply the estimate \eqref{eq:auxiliary_auxiliary_function_res2}:
    \begin{equation*}
        \norm{\psi_p}_{H^1(I)}
        \leq \norm{\psi_p - \phi_p}_{H^1(I)} + \norm{\phi_p}_{H^1(I)}
        \leq C + 2p^{1/2}
        \leq (C+2) p^{1/2}.
    \end{equation*}
    And finally,
    the estimates \eqref{eq:phi_p_Linfty} and \eqref{eq:phi_psi_Linfty_new}
    imply the estimate \eqref{eq:auxiliary_auxiliary_function_res3}:
    \begin{equation*}
        \norm{\psi_p}_{L^{\infty}(I)}
        \leq \norm{\psi_p - \phi_p}_{L^{\infty}(I)} + \norm{\phi_p}_{L^{\infty}(I)}
        \leq C + 1.
    \end{equation*}
\end{proof}

The next theorem is used to fix the values at the vertices of the elements.
\begin{theorem}
    \label{thm:auxiliary_vertex}
    Let $\widehat{E} = \widehat{Q}$ (resp.\ $\widehat{E} = \widehat{T}$).
    Let $V_i$ be a vertex of $\widehat{E}$ for some $i \in \{1,2,3,4\}$
    (resp.\ $i \in \{1,2,3\}$). Let $p \in \mathbb{N}$.
    Then there exists a $\nu_p \in \mathcal{P}_p^{(pr)}(\widehat{Q})$
    (resp.\ $\nu_p \in \mathcal{P}_p^{(tr)}(\widehat{T})$) such that
    \begin{equation}
        \label{eq:auxiliary_vertex_vertices}
        \nu_p(V_i) = 1
        \quad \text{and} \quad
        \nu_p(V_j) = 0 \text{ } \text{ for all } j \neq i
    \end{equation}
    and
    \begin{align}
        \label{eq:auxiliary_vertex_res1}
        &\norm{\nu_p}_{H^1(\widehat{E})} \leq C, \\[0.5em]
        \label{eq:auxiliary_vertex_res2}
        &\norm{\nu_p}_{L^{\infty}(\widehat{E})} \leq C, \\[0.5em]
        \label{eq:auxiliary_vertex_res3}
        &\norm{\nu_p}_{L^2(\gamma)} \leq C p^{-1/2}, \\[0.5em]
        \label{eq:auxiliary_vertex_res4}
        &\norm{\nu_p}_{H^1(\gamma)} \leq C p^{1/2},
    \end{align}
    where $\gamma$ is any edge of $\widehat{E}$
    and the constant $C > 0$ is independent of $p$.
\end{theorem}
\begin{proof}
    Let first $\widehat{E} = \widehat{Q}$.
    Assume that $V_i = (-1,-1)$. The other vertices can be handled
    with obvious modifications. Define
    \begin{equation*}
        \nu_p(x) = \psi_p(x_1) \psi_p(x_2) \in \mathcal{P}_p^{(pr)}(\widehat{Q}),
    \end{equation*}
    where $\psi_p \in \mathcal{P}_p(I)$ is given by
    Theorem~\ref{thm:auxiliary_auxiliary_function}.

    Recall that $\psi_p(-1)=1$ and $\psi_p(1)=0$.
    Thus, \eqref{eq:auxiliary_vertex_vertices} is obviously true.
    The estimates \eqref{eq:auxiliary_vertex_res1}
    and \eqref{eq:auxiliary_vertex_res2} also follow from the corresponding
    estimates for $\psi_p$:
    \begin{align*}
        \norm{\nu_p}_{H^1(\widehat{Q})}^2
        &= \norm{\nu_p}_{L^2(\widehat{Q})}^2 + \abs{\nu_p}_{H^1(\widehat{Q})}^2 \\
        &= \norm{\psi_p}_{L^2(I)}^2 \norm{\psi_p}_{L^2(I)}^2
            + \norm{\psi_p'}_{L^2(I)}^2 \norm{\psi_p}_{L^2(I)}^2
            + \norm{\psi_p}_{L^2(I)}^2 \norm{\psi_p'}_{L^2(I)}^2 \\
        &\leq 3 \norm{\psi_p}_{L^2(I)}^2 \norm{\psi_p}_{H^1(I)}^2 \\
        &\leq 3 C p^{-1/2} C p^{1/2} \\
        &= 3 C^2
    \end{align*}
    and
    \begin{equation*}
        \norm{\nu_p}_{L^{\infty}(\widehat{Q})}
        \leq \norm{\psi_p}_{L^{\infty}(I)}^2
        \leq C^2.
    \end{equation*}

    The function $\nu_p$ is identically zero on the edges of $\widehat{Q}$
    that correspond to the lines $x_1 = 1$ and $x_2 = 1$.
    The estimates \eqref{eq:auxiliary_vertex_res3}
    and \eqref{eq:auxiliary_vertex_res4} are obviously true on these
    edges. For the two remaining edges, we compute
    \begin{equation*}
        \norm{\nu_p}_{L^2(\gamma)}
        = \norm{\psi_p}_{L^2(I)}
        \leq C p^{-1/2}
    \end{equation*}
    and
    \begin{equation*}
        \norm{\nu_p}_{H^1(\gamma)}
        = \norm{\psi_p}_{H^1(I)}
        \leq C p^{1/2}.
    \end{equation*}
    Thus, \eqref{eq:auxiliary_vertex_res3}
    and \eqref{eq:auxiliary_vertex_res4} hold for all the edges.

    Assume then that $\widehat{E} = \widehat{T}$.
    Without loss of generality, assume that $V_i = (0,0)$.
    If $p$ is even, let $q = p/2 \in \mathbb{N}$ and define
    \begin{equation*}
        \nu_p(x) = \psi_q(2x_1-1) \psi_q(2x_2-1)
        \in \mathcal{P}_p^{(tr)}(\widehat{T}),
    \end{equation*}
    If $p > 1$ and $p$ is odd, let $q = (p-1)/2 \in \mathbb{N}$ and define
    \begin{equation*}
        \nu_p(x) = \psi_q(2x_1-1) \psi_{q+1}(2x_2-1)
        \in \mathcal{P}_p^{(tr)}(\widehat{T}).
    \end{equation*}
    The function $\psi_q \in \mathcal{P}_q(I)$ is again given by 
    Theorem~\ref{thm:polynomial_approximation_1d}.
    With more or less identical observations and computations as above,
    $\nu_p$ has the desired properties.
    Note that $(p-1)^{-1} \leq 2p^{-1}$ for all $p \geq 2$.

    If $p = 1$, then $v_p$ can be chosen as the nodal shape function
    \begin{equation*}
        \nu_p(x) = 1-x_1-x_2 \in \mathcal{P}_1^{(tr)}(\widehat{T}).
    \end{equation*}
\end{proof}

After Theorem~\ref{thm:auxiliary_vertex} has been applied,
the next theorem is used to fix the values across the edges.
\begin{theorem}
    \label{thm:auxiliary_edge}
    Let $\widehat{E} = \widehat{Q}$ (resp.\ $\widehat{E} = \widehat{T}$).
    Let $\gamma$ be an edge of $\widehat{E}$ with the vertices $V_1$ and $V_2$
    at the endpoints.
    Let $w_p \in \mathcal{P}_p(\gamma) \cong \mathcal{P}_p(I)$,
    $p \in \mathbb{N}$, be such that $w_p(V_1) = w_p(V_2) = 0$.
    Then there exists an extension $\xi_p \in \mathcal{P}_p^{(pr)}(\widehat{Q})$
    (resp.\ $\xi_p \in \mathcal{P}_{2p}^{(tr)}(\widehat{T})$)
    of $w_p$ such that
    \begin{equation}
        \label{eq:auxiliary_edge_boundary}
        \xi_p = w_p \text{ } \text{ on } \gamma
        \quad \text{and} \quad
        \xi_p = 0 \text{ } \text{ on } \partial \widehat{E} \setminus \gamma
    \end{equation}
    and
    \begin{align}
        \label{eq:auxiliary_edge_res1}
        &\norm{\xi_p}_{H^1(\widehat{E})}
        \leq C p^{-1/2} \norm{w_p}_{H^1(\gamma)}
            + C p^{1/2} \norm{w_p}_{L^2(\gamma)}, \\[0.5em]
        \label{eq:auxiliary_edge_res2}
        &\norm{\xi_p}_{L^{\infty}(\widehat{E})}
        \leq C \norm{w_p}_{L^{\infty}(\gamma)},
    \end{align}
    where the constant $C > 0$ is independent of $w_p$ and $p$.
\end{theorem}
\begin{proof}
    Let first $\widehat{E} = \widehat{Q}$.
    Assume that $\gamma$ is the edge corresponding to the
    horizontal line $x_2 = -1$. The other edges can be handled
    with obvious modifications.

    Define $\xi_p$ by
    \begin{equation*}
        \xi_p(x) = w_p(x_1) \psi_p(x_2) \in \mathcal{P}_p^{(pr)}(\widehat{Q}),
    \end{equation*}
    where $\psi_p \in \mathcal{P}_p(I)$ is given by
    Theorem~\ref{thm:auxiliary_auxiliary_function}.
    
    Now \eqref{eq:auxiliary_edge_boundary} is true
    since $\psi_p(-1) = 1$, $\psi_p(1) = 0$ and $w_p(-1) = w_p(1) = 0$.
    Moreover, the corresponding norm estimates for $\psi_p$ imply
    \eqref{eq:auxiliary_edge_res1} and \eqref{eq:auxiliary_edge_res2}:
    \begin{align*}
        \norm{\xi_p}_{H^1(\widehat{Q})}^2
        &= \norm{\xi_p}_{L^2(\widehat{Q})}^2 + \abs{\xi_p}_{H^1(\widehat{Q})}^2 \\
        &= \norm{w_p}_{L^2(I)}^2 \norm{\psi_p}_{L^2(I)}^2
            + \norm{w_p'}_{L^2(I)}^2 \norm{\psi_p}_{L^2(I)}^2
            + \norm{w_p}_{L^2(I)}^2 \norm{\psi_p'}_{L^2(I)}^2 \\
        &= \norm{\psi_p}_{L^2(I)}^2 \norm{w_p}_{H^1(I)}^2
            + \norm{\psi_p'}_{L^2(I)}^2 \norm{w_p}_{L^2(I)}^2 \\
        &\leq C^2 p^{-1} \norm{w_p}_{H^1(I)}^2
            + C^2 p \norm{w_p}_{L^2(I)}^2 \\
        &\leq \left(
            C p^{-1/2} \norm{w_p}_{H^1(\gamma)} + C p^{1/2} \norm{w_p}_{L^2(\gamma)}
        \right)^2
    \end{align*}
    and
    \begin{equation*}
        \norm{\xi_p}_{L^{\infty}(\widehat{Q})}
        \leq \norm{\psi_p}_{L^{\infty}(I)} \norm{w_p}_{L^{\infty}(\gamma)}
        \leq C \norm{w_p}_{L^{\infty}(\gamma)}.
    \end{equation*}

    Assume then that $\widehat{E} = \widehat{T}$.
    Without loss of generality, let $\gamma$ be the edge corresponding
    to the line $x_2=1-x_1$. The edge has the parametrization
    $\gamma(t) = (t,1-t)$ for $t \in [0,1]$, and we write
    $w_p(t)$ to mean $w_p(\gamma(t))$.
    
    Define now $\xi_p$ by
    \begin{equation*}
        \xi_p(x) = \psi_{p-1}(2(1-x_1-x_2)-1) [ x_2 w_p(x_1) + x_1 w_p(1-x_2) ]
        \in \mathcal{P}_{2p}^{(tr)}(\widehat{T})
    \end{equation*}
    where $\psi_{p-1} \in \mathcal{P}_{p-1}(I)$ is again given by
    Theorem~\ref{thm:auxiliary_auxiliary_function}.
    We have not defined $\psi_{p-1}$ for $p=1$, but if $p=1$,
    then $w_p(V_1) = w_p(V_2) = 0$ implies that $w_p = 0$ on $\gamma$
    and then $\xi_p = 0$ obviously has the desired properties.
    We may thus assume that $p \geq 2$.

    For all $x \in \gamma$, it holds that
    \begin{equation*}
        \xi_p(x)
        = \psi_{p-1}(-1) [(1-x_1)w_p(x_1) + x_1 w_p(x_1)]
        = w_p(x),
    \end{equation*}
    and since $w_p(0) = w_p(1) = 0$, it holds that
    $\xi_p(0,x_2) = 0$ and $\xi_p(x_1,0) = 0$ on the edges $x_1=0$ and $x_2=0$.
    Thus, \eqref{eq:auxiliary_edge_boundary} holds.

    Consider next the norm $\norm{\xi_p}_{L^2(\widehat{T})}$.
    By the estimate $(x+y)^2 \leq 2(x^2 + y^2)$, we get
    \begin{align}
        \norm{\xi_p}_{L^2(\widehat{T})}^2
        &\leq 2 \int_{0}^{1} \int_{0}^{1-x_1}
            \abs{\psi_{p-1}(2(1-x_1-x_2)-1) w_p(x_1)}^2 \diff x_2 \diff x_1
            \nonumber \\
        &\hspace{5mm} + 2 \int_{0}^{1} \int_{0}^{1-x_2}
            \abs{\psi_{p-1}(2(1-x_1-x_2)-1) w_p(1-x_2)}^2 \diff x_1 \diff x_2
            \nonumber \\
        &= 2 \int_{0}^{1} \abs{w_p(x_1)}^2 \int_{0}^{1-x_1}
            \abs{\psi_{p-1}(2(1-x_1-x_2)-1)}^2 \diff x_2 \diff x_1
            \nonumber \\
        &\hspace{5mm} + 2 \int_{0}^{1} \abs{w_p(1-x_2)}^2 \int_{0}^{1-x_2}
            \abs{\psi_{p-1}(2(1-x_1-x_2)-1)}^2 \diff x_1 \diff x_2 \nonumber \\
        &\leq 2 \int_{0}^{1} \abs{w_p(x_1)}^2 \int_{0}^{1}
            \abs{\psi_{p-1}(2x_2-1)}^2 \diff x_2 \diff x_1 \nonumber \\
        &\hspace{5mm} + 2 \int_{0}^{1} \abs{w_p(1-x_2)}^2 \int_{0}^{1}
            \abs{\psi_{p-1}(2x_1-1)}^2 \diff x_1 \diff x_2 \nonumber \\
        &= \frac{1}{\sqrt{2}}
            \norm{\psi_{p-1}}_{L^2(I)}^2 \norm{w_p}_{L^2(\gamma)}^2
            + \frac{1}{\sqrt{2}} \norm{\psi_{p-1}}_{L^2(I)}^2   
            \norm{w_p}_{L^2(\gamma)}^2 \nonumber \\
        \label{eq:auxiliary_edge_tri_L2}
        &= \frac{2}{\sqrt{2}} \norm{\psi_{p-1}}_{L^2(I)}^2
            \norm{w_p}_{L^2(\gamma)}^2,
    \end{align}
    where the square root comes from the fact that
    $\norm{\gamma'(t)} = \sqrt{2}$ for all $t \in [0,1]$.

    The partial derivatives of $\xi_p$ are given by
    \begin{align*}
        \frac{\partial \xi_p}{\partial x_1}(x)
        &= -2 \psi_{p-1}'(2(1-x_1-x_2)-1) [x_2 w_p(x_1) + x_1 w_p(1-x_2)] \\
        &\hspace{5mm} + \psi_{p-1}(2(1-x_1-x_2)-1) [x_2 w_p'(x_1) + w_p(1-x_2)]
    \end{align*}
    and
    \begin{align*}
        \frac{\partial \xi_p}{\partial x_2}(x)
        &= -2 \psi_{p-1}'(2(1-x_1-x_2)-1) [x_2 w_p(x_1) + x_1 w_p(1-x_2)] \\
        &\hspace{5mm} + \psi_{p-1}(2(1-x_1-x_2)-1) [w_p(x_1) - x_1 w_p'(1-x_2)].
    \end{align*}
    By similar computations as in the estimation of 
    $\norm{\xi_p}_{L^2(\widehat{T})}^2$, there exists a constant $C_1 > 0$
    independent of $w_p$ and $p$ such that
    \begin{align}
        \abs{\xi_p}_{H^1(\widehat{T})}^2
        \leq C_1 \Bigl(
            \norm{\psi_{p-1}'}_{L^2(I)}^2 \norm{w_p}_{L^2(\gamma)}^2
            &+ \norm{\psi_{p-1}}_{L^2(I)}^2 \norm{w_p'}_{L^2(\gamma)}^2 \nonumber \\
        \label{eq:auxiliary_edge_tri_H1_semi}
        &+ \norm{\psi_{p-1}}_{L^2(I)}^2 \norm{w_p}_{L^2(\gamma)}^2 \Bigr).
    \end{align}

    The estimates \eqref{eq:auxiliary_edge_tri_L2} and 
    \eqref{eq:auxiliary_edge_tri_H1_semi} and the corresponding
    estimates for $\psi_{p-1}$ yield the desired bound for the norm
    $\norm{\xi_p}_{H^1(\widehat{T})}$ just like previously in the case
    $\widehat{E} = \widehat{Q}$:
    \begin{align*}
        \norm{\xi_p}_{H^1(\widehat{T})}^2
        &= \norm{\xi_p}_{L^2(\widehat{T})}^2 + \abs{\xi_p}_{H^1(\widehat{T})}^2 \\
        &\leq C_1 \left( 
                \norm{\psi_{p-1}}_{L^2(I)}^2 \norm{w_p}_{H^1(\gamma)}^2
                + \norm{\psi_{p-1}'}_{L^2(I)}^2 \norm{w_p}_{L^2(\gamma)}^2
            \right) \\
        &\leq \left(
            C p^{-1/2} \norm{w_p}_{H^1(\gamma)} + C p^{1/2} \norm{w_p}_{L^2(\gamma)}
        \right)^2.
    \end{align*}

    Finally, proving the desired estimate for
    $\norm{\xi_p}_{L^{\infty}(\widehat{T})}$ is easy:
    \begin{align*}
        \norm{\xi_p}_{L^{\infty}(\widehat{T})}
        &\leq \norm{\psi_{p-1}}_{L^{\infty}(I)}
            (\norm{w_p}_{L^{\infty}(\gamma)} + \norm{w_p}_{L^{\infty}(\gamma)}) \\
        &\leq C \norm{w_p}_{L^{\infty}(\gamma)}.
    \end{align*}
\end{proof}

We are now ready to take the above auxiliary theorems into use
and consider the approximation properties
of the finite element space $S = S(\Omega, \mathcal{M}, p)$.
We use \cite[Theorem 4.1]{babuskasuri1987} as a basis
and extend it with an error estimate in the $L^{\infty}(\Omega)$-norm.
\begin{theorem}
    \label{thm:approximation_properties_of_S}
    Let $u \in H^2(\Omega)$ be such that it satisfies the boundary condition
    $Bu = 0$. Then there exists a $u_p \in S(\Omega, \mathcal{M}, p)$ such that
    \begin{align}
        \label{eq:approximation_properties_of_S_res1}
        &\norm{u-u_p}_{H^1(\Omega)} \leq C p^{-1} \norm{u}_{H^2(\Omega)}, \\[0.5em]
        \label{eq:approximation_properties_of_S_res2}
        &\norm{u-u_p}_{L^{\infty}(\Omega)} \leq C p^{-1} \norm{u}_{H^2(\Omega)},
    \end{align}
    where the constant $C > 0$ is independent of $u$ and $p$.
\end{theorem}
\begin{proof}
    It suffices to assume that the polynomial space is the trunk space because
    $\mathcal{P}_p^{(tr)}(\widehat{E}) \subset \mathcal{P}_p^{(pr)}(\widehat{E})$.

    Let $i \in \{ 1,2,\dotsc,N(\mathcal{M}) \}$ be the index of an element $E_i$.
    Define the function $\hat{u}^{(i)} = u \circ F_i \in H^2(\widehat{E}_i)$
    on the corresponding reference element.
    If $p$ is even, let $q = p/2 \in \mathbb{N}$.
    If $p$ is odd, let $q = (p-1)/2 \in \mathbb{N}$.
    If $p=1$, let $q=1$.
    Then by Theorem~\ref{thm:polynomial_approximation_2d},
    there exists a $\hat{u}_p^{(i)} \in \mathcal{P}_q^{(pr)}(\widehat{Q})
    \subset \mathcal{P}_p^{(tr)}(\widehat{Q})$ when $\widehat{E}_i = \widehat{Q}$
    or a $\hat{u}_p^{(i)} \in \mathcal{P}_q^{(tr)}(\widehat{T})
    \subset \mathcal{P}_p^{(tr)}(\widehat{T})$ when $\widehat{E}_i = \widehat{T}$
    such that
    \begin{align}
        \label{eq:approximation_properties_of_S_piecewise_res1}
        &\norm{\hat{u}^{(i)}-\hat{u}_p^{(i)}}_{H^1(\widehat{E}_i)}
        \leq C p^{-1} \norm{\hat{u}^{(i)}}_{H^2(\widehat{E}_i)}, \\[0.5em]
        \label{eq:approximation_properties_of_S_piecewise_res2}
        &\norm{\hat{u}^{(i)}-\hat{u}_p^{(i)}}_{L^{\infty}(\widehat{E}_i)}
        \leq C p^{-1} \norm{\hat{u}^{(i)}}_{H^2(\widehat{E}_i)}, \\[0.5em]
        \label{eq:approximation_properties_of_S_piecewise_res3}
        &\norm{\hat{u}^{(i)}-\hat{u}_p^{(i)}}_{L^2(\gamma)}
        \leq C p^{-3/2} \norm{\hat{u}^{(i)}}_{H^2(\widehat{E}_i)}, \\[0.5em]
        \label{eq:approximation_properties_of_S_piecewise_res4}
        &\norm{\hat{u}^{(i)}-\hat{u}_p^{(i)}}_{H^1(\gamma)}
        \leq C p^{-1/2} \norm{\hat{u}^{(i)}}_{H^2(\widehat{E}_i)}.
    \end{align}
    Notice that $q^{-1} \leq 4p^{-1}$.

    Define $u_p^{(i)} = \hat{u}_p^{(i)} \circ F_i^{-1}$ for all $i=1,2,\dotsc,N$.
    We could try to define $u_p$ such that $u_p|_{E_i} = u_p^{(i)}$
    for all $i=1,2,\dotsc,N$, but the resulting function does not necessarily
    satisfy the continuity requirement or the condition that $Bu_p = 0$.
    In other words, $u_p \notin S$. However, if $u_p \in S$ were true,
    then \eqref{eq:approximation_properties_of_S_piecewise_res1}
    and \eqref{eq:approximation_properties_of_S_piecewise_res2} would
    immediately imply \eqref{eq:approximation_properties_of_S_res1}
    and \eqref{eq:approximation_properties_of_S_res2}.
    Thus, our goal is to modify each $\hat{u}_p^{(i)}$ so that $u_p \in S$
    while preserving the estimates
    \eqref{eq:approximation_properties_of_S_piecewise_res1}
    and \eqref{eq:approximation_properties_of_S_piecewise_res2}
    as well as possible.
    The estimates \eqref{eq:approximation_properties_of_S_piecewise_res3}
    and \eqref{eq:approximation_properties_of_S_piecewise_res4}
    are needed in achieving this goal.

    Let us begin with the continuity requirement.
    We first modify each $\hat{u}_p^{(i)}$ so that $u_p^{(i)}(V_j) = u(V_j)$
    for all vertices $V_j$ of the element $E_i$.
    Let $V_j$ be one of the vertices,
    and let $\widehat{V}_j = F_i^{-1}(V_j)$ denote the 
    corresponding vertex in the reference element $\widehat{E}_i$.
    Let $\hat{\nu}_q \in \mathcal{P}_q^{(pr)}(\widehat{Q})$
    or $\hat{\nu}_q \in \mathcal{P}_q^{(tr)}(\widehat{T})$ be the polynomial
    provided by Theorem~\ref{thm:auxiliary_vertex} that satisfies
    $\hat{\nu}_q(\widehat{V}_j) = 1$
    and $\hat{\nu}_q(\widehat{V}_k) = 0$ for all $k \neq j$.
    Now by adding the polynomial $(u - u_p^{(i)})(V_j) \hat{\nu}_q$
    to $\hat{u}_p^{(i)}$, we get that $u_p^{(i)}(V_j) = u(V_j)$.
    Moreover,
    \begin{align*}
        \norm{(u - u_p^{(i)})(V_j) \nu_q}_{H^1(\widehat{E}_i)}
        &= \abs{(\hat{u}^{(i)} - \hat{u}_p^{(i)})(\widehat{V}_j)} 
            \norm{\nu_q}_{H^1(\widehat{E}_i)} \\
        &\leq \norm{\hat{u}^{(i)} - \hat{u}_p^{(i)}}_{L^{\infty}(\widehat{E}_i)}
            \norm{\nu_q}_{H^1(\widehat{E}_i)} \\
        &\leq C p^{-1} \norm{\hat{u}^{(i)}}_{H^2(\widehat{E}_i)},
    \end{align*}
    which means that the resulting polynomial still satisfies
    \eqref{eq:approximation_properties_of_S_piecewise_res1}.
    With identical arguments, one can show that the other estimates
    \eqref{eq:approximation_properties_of_S_piecewise_res2}-\eqref{eq:approximation_properties_of_S_piecewise_res4}
    also still hold. This step is repeated for every vertex in every element,
    which fixes the values at the vertices.
    As previously, let $\hat{u}_p^{(i)}$ denote these refined approximations,
    and note that they still belong to the polynomial space
    $\mathcal{P}_q^{(pr)}(\widehat{Q}) \subset \mathcal{P}_p^{(tr)}(\widehat{Q})$
    or $\mathcal{P}_q^{(tr)}(\widehat{T}) \subset
    \mathcal{P}_p^{(tr)}(\widehat{T})$.

    Next we consider the continuity across the edges.
    Let $E_i$ and $E_j$ be two elements with a common edge $\gamma_{ij}$.
    Notice that $w_q^{(ij)} = u_p^{(j)} - u_p^{(i)} \in \mathcal{P}_q(\gamma_{ij})$
    and $w_q^{(ij)}(V_1) = w_q^{(ij)}(V_2) = 0$, where $V_1$ and $V_2$
    are the endpoints of $\gamma_{ij}$.
    The mapping $F_i$ is linear on the edges, which means that
    $\hat{w}_q^{(ij)} = w_q^{(ij)} \circ F_i \in
    \mathcal{P}_q(\hat{\gamma_{i}})$,
    where $\hat{\gamma_{i}} = F_i^{-1}(\gamma_{ij})$,
    and $\hat{w}_q^{(ij)}(\widehat{V_1}) = \hat{w}_q^{(ij)}(\widehat{V_2}) = 0$.
    Let $\hat{\xi_q} \in \mathcal{P}_q^{(pr)}(\widehat{Q})$
    or $\hat{\xi_q} \in \mathcal{P}_{2q}^{(tr)}(\widehat{T})
    \subset \mathcal{P}_{p}^{(tr)}(\widehat{T})$ be the polynomial
    provided by Theorem~\ref{thm:auxiliary_edge} which satisfies
    $\hat{\xi}_q = \hat{w}_q^{(ij)}$ on $\hat{\gamma_i}$
    and $\hat{\xi}_q = 0$ on $\partial \widehat{E}_i \setminus \hat{\gamma_i}$.
    By adding $\hat{\xi}_q$ to $\hat{u}_p^{(i)}$
    and applying the inverse mapping $F_i^{-1}$,
    we obviously achieve continuity across the edge $\gamma_{ij}$
    while keeping the other edges unmodified. In addition,
    by Theorem~\ref{thm:auxiliary_edge} and the estimates
    \eqref{eq:approximation_properties_of_S_piecewise_res3}
    and \eqref{eq:approximation_properties_of_S_piecewise_res4}, we get that
    \begin{align}
        \norm{\hat{\xi_q}}_{H^1(\widehat{E}_i)}
        &\leq C q^{-1/2} \norm{\hat{w}_q^{(ij)}}_{H^1(\hat{\gamma_i})}
            + C q^{1/2} \norm{\hat{w}_q^{(ij)}}_{L^2(\hat{\gamma_i})} \nonumber \\
        &\leq C p^{-1/2} \norm{w_q^{(ij)}}_{H^1(\gamma_{ij})} 
            + C p^{1/2} \norm{w_q^{(ij)}}_{L^2(\gamma_{ij})} \nonumber \\
        &\leq C p^{-1/2} \left(
            \norm{u - u_p^{(i)}}_{H^1(\gamma_{ij})}
            + \norm{u - u_p^{(j)}}_{H^1(\gamma_{ij})}
        \right) \nonumber \\
        &\hspace{5mm} + Cp^{1/2} \left(
            \norm{u - u_p^{(i)}}_{L^2(\gamma_{ij})}
            + \norm{u - u_p^{(j)}}_{L^2(\gamma_{ij})}
        \right) \nonumber \\
        &\leq C p^{-1/2} \left(
            \norm{\hat{u}^{(i)} - \hat{u}_p^{(i)}}_{H^1(\hat{\gamma_{i}})}
            + \norm{\hat{u}^{(j)} - \hat{u}_p^{(j)}}_{H^1(\hat{\gamma_{j}})}
        \right) \nonumber \\
        &\hspace{5mm} + Cp^{1/2} \left(
            \norm{\hat{u}^{(i)} - \hat{u}_p^{(i)}}_{L^2(\hat{\gamma_{i}})}
            + \norm{\hat{u}^{(j)} - \hat{u}_p^{(j)}}_{L^2(\hat{\gamma_{j}})}
        \right) \nonumber \\
        &\leq C p^{-1/2} \left(
            p^{-1/2} \norm{\hat{u}^{(i)}}_{H^2(\widehat{E}_i)}
            + p^{-1/2} \norm{\hat{u}^{(j)}}_{H^2(\widehat{E}_j)}
        \right) \nonumber \\
        &\hspace{5mm} + Cp^{1/2} \left(
            p^{-3/2} \norm{\hat{u}^{(i)}}_{H^2(\widehat{E}_i)}
            + p^{-3/2} \norm{\hat{u}^{(j)}}_{H^2(\widehat{E}_j)}
        \right) \nonumber \\
        \label{eq:approximation_properties_of_S_piecewise_edge_res1}
        &\leq C p^{-1} \left( \norm{\hat{u}^{(i)}}_{H^2(\widehat{E}_i)}
            + \norm{\hat{u}^{(j)}}_{H^2(\widehat{E}_j)} \right)
    \end{align}
    and quite similarly
    \begin{align}
        \norm{\hat{\xi_q}}_{L^{\infty}(\widehat{E}_i)}
        &\leq C \norm{\hat{w}_q^{(ij)}}_{L^{\infty}(\hat{\gamma_i})} \nonumber \\
        &= C \norm{w_q^{(ij)}}_{L^{\infty}(\gamma_{ij})} \nonumber \\
        &\leq C \left(
            \norm{u - u_p^{(i)}}_{L^{\infty}(\gamma_{ij})}
            + \norm{u - u_p^{(j)}}_{L^{\infty}(\gamma_{ij})}
        \right) \nonumber \\
        &= C \left(
            \norm{\hat{u}^{(i)} - \hat{u}_p^{(i)}}_{L^{\infty}(\hat{\gamma_{i}})}
            + \norm{\hat{u}^{(j)} - \hat{u}_p^{(j)}}_{L^{\infty}(\hat{\gamma_{j}})}
        \right) \nonumber \\
        &\leq C \left(
            \norm{\hat{u}^{(i)} - \hat{u}_p^{(i)}}_{L^{\infty}(\widehat{E}_i)}
            + \norm{\hat{u}^{(j)} - \hat{u}_p^{(j)}}_{L^{\infty}(\widehat{E}_j)}
        \right) \nonumber \\
        \label{eq:approximation_properties_of_S_piecewise_edge_res2}
        &\leq C p^{-1} \left( \norm{\hat{u}^{(i)}}_{H^2(\widehat{E}_i)}
            + \norm{\hat{u}^{(j)}}_{H^2(\widehat{E}_j)} \right),
    \end{align}
    where the last inequality follows from
    \eqref{eq:approximation_properties_of_S_piecewise_res2}.
    For simplicity, the constant $C$ is not necessarily the same in
    each step, but it is always independent of $u$ and $p$.
    The estimates \eqref{eq:approximation_properties_of_S_piecewise_edge_res1}
    and \eqref{eq:approximation_properties_of_S_piecewise_edge_res2}
    imply that $\hat{u}_p^{(i)}$ satisfies slightly weaker forms of the estimates 
    \eqref{eq:approximation_properties_of_S_piecewise_res1}
    and \eqref{eq:approximation_properties_of_S_piecewise_res2}
    with at most four additional
    $\norm{\hat{u}^{(j)}}_{H^2(\widehat{E}_j)}$-terms
    corresponding to the neighboring elements.
    After this step has been repeated for every interior edge in every element,
    the approximation $u_p$ belongs to the space $C(\overline{\Omega})$,
    and it satisfies $u_p \circ F_i \in \mathcal{P}_p^{(tr)}(\widehat{E}_i)$
    for all $i=1,2,\dotsc,N$.

    If the boundary condition $Bu=0$ corresponds to a homogeneous Dirichlet
    boundary condition on a part of the boundary $\partial \Omega$,
    then the condition $Bu_p = 0$ can be satisfied with a similar
    edge repairing strategy as above. Let $\Gamma_i$ be a linear boundary segment
    on which the Dirichlet boundary condition is imposed.
    Then $u - u_p^{(i)} = -u_p^{(i)} \in \mathcal{P}_q(\Gamma_i)$,
    and one can proceed quite analogously as above via
    Theoren~\ref{thm:auxiliary_edge}. After applying this step on all
    the Dirichlet boundary segments, the approximation $u_p$
    belongs to the space $S$. We consider the pure Neumann case shortly.

    By using \eqref{eq:approximation_properties_of_S_piecewise_edge_res1}
    and \eqref{eq:approximation_properties_of_S_piecewise_edge_res2},
    we can now show that $u_p$ satisfies the estimates
    \eqref{eq:approximation_properties_of_S_res1} and
    \eqref{eq:approximation_properties_of_S_res2}.
    The constant $C$ below is again not necessarily the same in each step,
    but it is always independent of $u$ and $p$. Now
    \begin{align*}
        \norm{u - u_p}_{H^1(\Omega)}
        &\leq C \sum_{i=1}^{N} \norm{u - u_p}_{H^1(E_i)} \\
        &\leq C \sum_{i=1}^{N}
            \norm{\hat{u}^{(i)} - \hat{u}_p^{(i)}}_{H^1(\widehat{E}_i)} \\
        &\leq C \sum_{i=1}^{N} p^{-1} \norm{\hat{u}^{(i)}}_{H^2(\widehat{E}_i)} \\
        &\leq C p^{-1} \sum_{i=1}^{N} \norm{u}_{H^2(E_i)} \\
        &\leq C p^{-1} \norm{u}_{H^2(\Omega)}
    \end{align*}
    and
    \begin{align*}
        \norm{u - u_p}_{L^{\infty}(\Omega)}
        &= \max_{i=1,2,\dotsc,N} \norm{u - u_p}_{L^{\infty}(E_i)} \\
        &= \max_{i=1,2,\dotsc,N}
            \norm{\hat{u}^{(i)} - \hat{u}_p^{(i)}}_{L^{\infty}(\widehat{E}_i)} \\
        &\leq \max_{i=1,2,\dotsc,N} C p^{-1}
            \norm{\hat{u}^{(i)}}_{H^2(\widehat{E}_i)} \\
        &\leq C p^{-1} \norm{u}_{H^2(\Omega)}.
    \end{align*}
    This completes the proof when $Bu=0$ corresponds to a homogeneous
    Dirichlet boundary condition.

    Let us finally consider the problem with pure Neumann boundary conditions.
    Now $Bu=0$ corresponds to the condition that
    \begin{equation*}
        \int_{\Omega} u \diff x = 0.
    \end{equation*}
    Obviously, we can modify $u_p$ to satisfy this condition by redefining
    it as $u_p - \overline{u}_p \in S$, where
    \begin{equation*}
        \overline{u}_p = \frac{1}{\abs{\Omega}} \int_{\Omega} u_p \diff x.
    \end{equation*}
    Moreover, by Hölder's inequality and the estimate
    \eqref{eq:approximation_properties_of_S_res1}, we have that
    \begin{align*}
        \abs{\overline{u}_p}
        &= \abs{\overline{u} - \overline{u}_p} \\
        &\leq C \int_{\Omega} \abs{u - u_p} \diff x \\
        &\leq C \norm{u - u_p}_{L^2(\Omega)} \\
        &\leq C \norm{u - u_p}_{H^1(\Omega)} \\
        &\leq C p^{-1} \norm{u}_{H^2(\Omega)},
    \end{align*}
    which implies that the estimates \eqref{eq:approximation_properties_of_S_res1}
    and \eqref{eq:approximation_properties_of_S_res2} still hold
    after the redefinition of $u_p$.
\end{proof}

We may now return to the initial objective of assessing the convergence
of the $p$-version of the finite element method when applied to the
elliptic second-order boundary value problem of finding a
$u \in V \subset H^1(\Omega)$ such that
\begin{equation}
    \label{eq:H1_convergence_thm_problem}
    a(u,v) = \varphi(v)
\end{equation}
for all $v \in V$. When $u \in H^2(\Omega)$, then convergence
in the $H^1(\Omega)$-norm is an immediate corollary of Céa's lemma
and Theorem~\ref{thm:approximation_properties_of_S}.
\begin{theorem}
    \label{thm:H1_convergence_of_p_version}
    Let $u \in V \subset H^1(\Omega)$ be the unique solution of the problem 
    \eqref{eq:H1_convergence_thm_problem}.
    Assume in addition that $u \in H^2(\Omega)$.
    Let $u_S \in S(\Omega, \mathcal{M}, p)$ be the corresponding
    finite element approximation. Then there exists a constant $C > 0$
    independent of $u$ and $p$ such that
    \begin{equation*}
        \norm{u-u_S}_{H^1(\Omega)} \leq C p^{-1} \norm{u}_{H^2(\Omega)}.
    \end{equation*}
\end{theorem}
\begin{proof}
    Let $u_p \in S$ be the approximation of $u$ provided by
    Theorem~\ref{thm:approximation_properties_of_S}.
    Now by Céa's lemma, i.e.\ Theorem~\ref{thm:ceas_lemma}, we get that
    \begin{align*}
        \norm{u - u_S}_{H^1(\Omega)}
        &\leq C \inf_{v \in S} \norm{u - v}_{H^1(\Omega)} \\
        &\leq C \norm{u - u_p}_{H^1(\Omega)} \\
        &\leq C p^{-1} \norm{u}_{H^2(\Omega)},
    \end{align*}
    where the constant $C > 0$ is independent of $u$ and $p$.
\end{proof}

Theorem~\ref{thm:H1_convergence_of_p_version} is the standard
well-known result regarding the convergence of the $p$-version
of the finite element method. In \cite{babuskasuri1987},
it is shown that the rate of convergence $p^{-1}$ is optimal.
The optimal convergence estimate of the $h$-version of the finite element method
(with polynomials of one degree in the standard elements)
is analogous to Theorem~\ref{thm:H1_convergence_of_p_version}
but with $p^{-1}$ replaced by $h$, see e.g.\ \cite{braess2007}.

Continuing with the $h$-version, there also exist pointwise estimates,
i.e.\ estimates in the $L^{\infty}(\Omega)$-norm, of the approximation error.
For example, in \cite{braess2007}, it is shown that
\begin{equation*}
    \norm{u - u_S}_{L^{\infty}(\Omega)} \leq C h \norm{u}_{H^2(\Omega)},
\end{equation*}
and \cite{ciarlet2002} contains an even stronger estimate.

For the $p$-version, however, similar pointwise estimates do not seem to be
as widely discussed. Proving convergence estimates in the $L^{\infty}(\Omega)$-norm
is in general more difficult than in the $H^1(\Omega)$-norm
because Céa's lemma is not directly applicable.
It does, however, turn out that
by using a similar proof strategy as in \cite[p.\ 93]{braess2007},
a pointwise estimate can be proven for the $p$-version as well.
The pointwise estimate in Theorem~\ref{thm:approximation_properties_of_S}
and a certain inverse estimate in \cite{schwab1998} are the main enablers
for this application.
\begin{theorem}
    \label{thm:pointwise_convergence_of_p_version}
    Let $u \in V \subset H^1(\Omega)$ be the unique solution of the problem 
    \eqref{eq:H1_convergence_thm_problem}.
    Assume in addition that $u \in H^2(\Omega)$.
    Let $u_S \in S(\Omega, \mathcal{M}, p)$ be the corresponding
    finite element approximation. Then there exists a constant $C > 0$
    independent of $u$ and $p$ such that
    \begin{equation*}
        \norm{u-u_S}_{L^{\infty}(\Omega)}
        \leq C p^{-1} \sqrt{\log(p+1)} \norm{u}_{H^2(\Omega)}.
    \end{equation*}
\end{theorem}
\begin{proof}
    Let $u_p \in S$ be the approximation of $u$ provided by
    Theorem~\ref{thm:approximation_properties_of_S}.
    We divide the estimation problem into two parts via the triangle inequality:
    \begin{equation*}
        \norm{u-u_S}_{L^{\infty}(\Omega)}
        \leq \norm{u-u_p}_{L^{\infty}(\Omega)}
            + \norm{u_p-u_S}_{L^{\infty}(\Omega)}.
    \end{equation*}
    The first term can immediately be estimated by
    \eqref{eq:approximation_properties_of_S_res2}
    in Theorem~\ref{thm:approximation_properties_of_S}.
    
    For the second term, notice that $u_p - u_S \in S$ and thus
    \begin{equation}
        \label{eq:pointwise_of_p_version_before_inverse}
        \norm{u_p-u_S}_{L^{\infty}(\Omega)}
        = \max_{i=1,\dotsc,N} \norm{u_p - u_S}_{L^{\infty}(E_i)}
        = \max_{i=1,\dotsc,N}
            \norm{\hat{u}_p^{(i)} - \hat{u}_S^{(i)}}_{L^{\infty}(\widehat{E}_i)},
    \end{equation}
    where $\hat{u}_p^{(i)} = u_p \circ F_i \in \mathcal{P}_p(\widehat{E}_i)$
    and $\hat{u}_S^{(i)} = u_S \circ F_i \in \mathcal{P}_p(\widehat{E}_i)$.

    By \cite[Theorem 4.76 on p.\ 208]{schwab1998}
    (covers both quadrilaterals and triangles)
    or \cite[Proposition 3.1]{boillat1997} (covers only triangles),
    $\hat{u}_p^{(i)} - \hat{u}_S^{(i)} \in \mathcal{P}_p(\widehat{E}_i)$
    satisfies the inverse inequality
    \begin{equation}
        \label{eq:pointwise_of_p_version_inverse}
        \norm{\hat{u}_p^{(i)} - \hat{u}_S^{(i)}}_{L^{\infty}(\widehat{E}_i)}
        \leq C \sqrt{\log(p+1)}
            \norm{\hat{u}_p^{(i)} - \hat{u}_S^{(i)}}_{H^1(\widehat{E}_i)},
    \end{equation}
    where the constant $C > 0$ is independent of $u$ and $p$.
    
    Define $\hat{u}^{(i)} = u \circ F_i$.
    Now by the triangle inequality, Theorem~\ref{thm:approximation_properties_of_S}
    and Theorem~\ref{thm:H1_convergence_of_p_version},
    the $H^1$-norm on the right-hand side of 
    \eqref{eq:pointwise_of_p_version_inverse} can be estimated by
    \begin{align}
        \norm{\hat{u}_p^{(i)} - \hat{u}_S^{(i)}}_{H^1(\widehat{E}_i)}
        &\leq \norm{\hat{u}_p^{(i)} - \hat{u}^{(i)}}_{H^1(\widehat{E}_i)}
            + \norm{\hat{u}^{(i)} - \hat{u}_S^{(i)}}_{H^1(\widehat{E}_i)}
            \nonumber \\
        &\leq C \norm{u_p - u}_{H^1(E_i)} + C \norm{u - u_S}_{H^1(E_i)}
            \nonumber \\
        &\leq C \norm{u_p - u}_{H^1(\Omega)} + C \norm{u - u_S}_{H^1(\Omega)}
            \nonumber \\
        &\leq C p^{-1} \norm{u}_{H^2(\Omega)} + C p^{-1} \norm{u}_{H^2(\Omega)}
            \nonumber \\
        \label{eq:pointwise_of_p_version_inverse_refined}
        &= 2C p^{-1} \norm{u}_{H^2(\Omega)}.
    \end{align}

    Plugging \eqref{eq:pointwise_of_p_version_inverse_refined} into
    \eqref{eq:pointwise_of_p_version_inverse} and then
    \eqref{eq:pointwise_of_p_version_inverse} into
    \eqref{eq:pointwise_of_p_version_before_inverse}, the second term becomes
    \begin{align*}
        \norm{u_p-u_S}_{L^{\infty}(\Omega)}
        &\leq \max_{i=1,\dotsc,N} C p^{-1} \sqrt{\log(p+1)} \norm{u}_{H^2(\Omega)} 
            \\
        &=  C p^{-1} \sqrt{\log(p+1)} \norm{u}_{H^2(\Omega)}.
    \end{align*}

    Combining the estimates for the first and the second term,
    we arrive at the desired estimate:
    \begin{align*}
        \norm{u-u_S}_{L^{\infty}(\Omega)}
        &\leq \norm{u-u_p}_{L^{\infty}(\Omega)}
            + \norm{u_p-u_S}_{L^{\infty}(\Omega)} \\
        &\leq C p^{-1} \norm{u}_{H^2(\Omega)}
            + C p^{-1} \sqrt{\log(p+1)} \norm{u}_{H^2(\Omega)} \\
        &\leq C p^{-1} \sqrt{\log(p+1)} \norm{u}_{H^2(\Omega)}.
    \end{align*}
\end{proof}

So far, we have considered an elliptic second-order boundary value
problem in its general form, and we must always have separately assumed that
the exact solution belongs to the space $H^2(\Omega)$.
Thus, for some concreteness,
let us briefly return to the boundary value problem
\begin{equation*}
    \left\{
        \begin{aligned}
            -\Delta u &= f && \text{in } \Omega \\
            u &= g_j && \text{on } \Gamma_j, \quad j \in D \\
            \frac{\partial u}{\partial n} &= g_j && \text{on } \Gamma_j,
            \quad j \in N,
        \end{aligned}
    \right.
\end{equation*}
where $f \in L^2(\Omega)$ and we assume that there exists
a $g_D \in H^2(\Omega)$ such that $g_D|_{\Gamma_j} = g_j$ for all $j \in D$.

As long as the domain $\Omega$ satisfies 
Assumption~\ref{ass:regular_polygonal_domain}, the solution
of the problem belongs to the space $H^2(\Omega)$
by Theorem~\ref{thm:H2_regularity}.
Thus, Theorem~\ref{thm:H1_convergence_of_p_version}
and Theorem~\ref{thm:pointwise_convergence_of_p_version}
imply that the $p$-version of the finite element method converges
when applied to the above problem.
Note that the finite element method can be used to approximate
the shifted solution $u - g_D$ that satisfies a homogeneous
Dirichlet boundary condition.

\clearpage

\section{Finite Element Analysis of Poisson's Equation with a Concentrated Load}
\label{sec:finite_element_solutions_with_a_concentrated_load}

\begin{theorem}
    \label{thm:L2_convergence_of_p_version_dirac_load}
    Let $\Omega \subset \mathbb{R}^2$ be a bounded polygonal domain
    that satisfies Assumption~\ref{ass:regular_polygonal_domain}.
    Consider the boundary value problem
    \begin{equation*}
        \left\{
            \begin{aligned}
                -\Delta u &= \delta_{x_0} && \text{in } \Omega \\
                u &= 0 && \text{on } \Gamma_j, \quad j \in D \\
                \frac{\partial u}{\partial n} &= g_j && \text{on } \Gamma_j,
                \quad j \in N,
            \end{aligned}
        \right.
    \end{equation*}
    where $g_j \in T(H^1(\Omega))$ for $j \in N$.
    Let $u \in W^{1,p}(\Omega)$, $1 < p < 2$, and $u_S \in S(\Omega,\mathcal{M},p)$
    denote the exact solution and the finite element solution of the problem,
    respectively. Then there exists a constant $C > 0$ independent of $p$
    such that
    \begin{equation*}
        \norm{u - u_S}_{L^2(\Omega)} \leq C p^{-1} \sqrt{\log(p+1)}.
    \end{equation*}
\end{theorem}
\begin{proof}
    By the Sobolev imbedding theorem, $u - u_S \in L^2(\Omega)$.
    Thus, consider the dual problem
    \begin{equation*}
        \left\{
            \begin{aligned}
                -\Delta v &= u - u_S && \text{in } \Omega \\
                v &= 0 && \text{on } \Gamma_j, \quad j \in D \\
                \frac{\partial v}{\partial n} &= 0 && \text{on } \Gamma_j,
                \quad j \in N.
            \end{aligned}
        \right.
    \end{equation*}
    By Theorem~\ref{thm:H2_regularity}, the solution $v$ of the dual problem
    belongs to the space $H^2(\Omega)$,
    and by Theorem~\ref{thm:weak_solution_is_strong_solution},
    $-\Delta v = u-u_S$ holds almost everywhere in $\Omega$.
    Moreover, by Theorem~\ref{thm:a_priori_H2_estimate},
    the solution $v$ has the a priori estimate
    \begin{equation}
        \label{eq:dirac_L2_conv_dual_apriori}
        \norm{v}_{H^2(\Omega)} \leq C \norm{u - u_S}_{L^2(\Omega)}.
    \end{equation} 
    Let $v_S \in S$ denote the finite element approximation of $v$.
    The error estimates of the previous section are immediately applicable
    to $v - v_S$.

    Let us now take the first steps in estimating the norm
    $\norm{u - u_S}_{L^2(\Omega)}$. Integration by parts gives
    \begin{align}
        \norm{u - u_S}_{L^2(\Omega)}^2
        &= \int_{\Omega} \abs{u - u_S}^2 \diff x \nonumber \\
        &= -\int_{\Omega} (u - u_S) \Delta v \diff x \nonumber \\
        &= \int_{\Omega} \nabla (u-u_S) \cdot \nabla v \diff x
        - \int_{\partial \Omega} \frac{\partial v}{\partial n} (u - u_S) \diff S
            \nonumber \\
        \label{eq:dirac_L2_first_steps}
        &= \int_{\Omega} \nabla u \cdot \nabla v \diff x
            - \int_{\Omega} \nabla u_S \cdot \nabla v \diff x.
    \end{align}
    
    The Sobolev imbedding theorem implies that $v \in W^{1,q}(\Omega)$,
    where $2 < q < \infty$ is the conjugate exponent of $p$.
    Hence, by the definition of a weak solution,
    the first integral term in \eqref{eq:dirac_L2_first_steps} can be written as
    \begin{equation*}
        \int_{\Omega} \nabla u \cdot \nabla v \diff x
        = v(x_0) + \sum_{j \in N} \int_{\Gamma_j} g_j v \diff S.
    \end{equation*}
    
    Galerkin orthogonality between $v$ and $v_S$
    enables us to write the second integral in \eqref{eq:dirac_L2_first_steps} as
    \begin{align*}
        \int_{\Omega} \nabla u_S \cdot \nabla v \diff x
        &= \int_{\Omega} \nabla u_S \cdot \nabla v_S \diff x \\
        &= v_S(x_0) + \sum_{j \in N} \int_{\Gamma_j} g_j v_S \diff S
    \end{align*}
    
    We may now derive an initial estimate for the norm
    $\norm{u - u_S}_{L^2(\Omega)}$:
    \begin{align*}
        \norm{u - u_S}_{L^2(\Omega)}^2
        &= \int_{\Omega} \nabla u \cdot \nabla v \diff x
            - \int_{\Omega} \nabla u_S \cdot \nabla v_S \diff x \\
        &= v(x_0) + \sum_{j \in N} \int_{\Gamma_j} g_j v \diff S
            - v_S(x_0) - \sum_{j \in N} \int_{\Gamma_j} g_j v_S \diff S \\
        &= v(x_0) - v_S(x_0)
            + \sum_{j \in N} \int_{\Gamma_j} g_j (v - v_S) \diff S \\
        &\leq \norm{v - v_S}_{L^{\infty}(\Omega)}
            + \sum_{j \in N} \norm{g_j}_{L^2(\Gamma_j)}
                \norm{v - v_S}_{L^2(\Gamma_j)} \\
        &\leq \norm{v - v_S}_{L^{\infty}(\Omega)}
            + \sum_{j \in N} \norm{g_j}_{L^2(\Gamma_j)}
                \norm{v - v_S}_{H^1(\Omega)}.
    \end{align*}
    The last inequality follows from the Sobolev trace theorem.
    Theorem~\ref{thm:H1_convergence_of_p_version},
    Theorem~\ref{thm:pointwise_convergence_of_p_version}
    and the a priori estimate \eqref{eq:dirac_L2_conv_dual_apriori}
    further imply that
    \begin{align*}
        \norm{u - u_S}_{L^2(\Omega)}^2
        &\leq C p^{-1} \sqrt{\log(p+1)} \norm{v}_{H^2(\Omega)}
            + \sum_{j \in N} \norm{g_j}_{L^2(\Gamma_j)}
                C p^{-1} \norm{v}_{H^2(\Omega)} \\
        &\leq C \left( 1 + \sum_{j \in N} \norm{g_j}_{L^2(\Gamma_j)} \right)
            p^{-1} \sqrt{\log(p+1)} \norm{v}_{H^2(\Omega)} \\
        &\leq C p^{-1} \sqrt{\log(p+1)} \norm{u - u_S}_{L^2(\Omega)}.
    \end{align*}
    Dividing both sides by $\norm{u - u_S}_{L^2(\Omega)}$ completes the proof.
\end{proof}

\clearpage
%% Bibliography/ list of references
%%
\thesisbibliography
\bibliographystyle{ieeetr}
\bibliography{refs}

\end{document}

% pisteet ja pilkut yhtälöihin
% muuta indeksit j -> i
% \left\{ \right\} V_D ja V_N avaruuksissa
% 1,...,n -> 1,2,...,n paitsi esim \max:n alla
% Lähteisiin isot kirjaimet tyyliin {}
% align spacing [0.5em] + pilkut rivien väliin + align alkuun vai &\leq,
%% vai korvataanko align equationilla (tuskin)
% kolmio hierarchical basis ei spanaa full spacea?
% full space -> product space renaming
% yhtenäistä vakioiden C käyttöä estimaateissa
